[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "10_6009711_3", "passage": "Thus, FDCM in this family has a phenotype primarily of heart failure that is variable in age of onset and severity with moderate to high penetrance.\n\n Mutations in cTnT have been established to be the third most common cause of FHCM. 1,15-18 FHCM caused by cTnT mutations usually exhibits mild cardiac hypertrophy but a high incidence of sudden death. 16, 19 A recent surprise finding by Kamisago et al 11 showed that deletion of 1 amino acid from cTnT (\u232c210Lys) caused FDCM in 2 families; notably, both were associated with a high frequency of sudden death. In our family, the clinical features are typical for DCM, namely, depressed contractile function and ventricular dilatation resulting in the symptoms of congestive heart failure. No case of sudden death has been documented in our family. None of the echocardiograms or ECGs showed ventricular hypertrophy. Our family does not represent HCM that has evolved to end-stage dilatation, because several members of the family developed DCM during childhood, and 1 child who died at age 2.5 years was confirmed on autopsy to have had DCM. Furthermore, we screened more than 200 probands with FHCM for the Arg141Trp mutation, and none were identified. Similarly, the mutation \u232c210Lys in cTnT is not associated with FHCM. Thus, these 2 mutations, \u232c210Lys and Arg141Trp, in exon 13 and exon 10, respectively, are not associated with FHCM; furthermore, no mutation responsible for FHCM has ever been identified in either of these exons 11, 16 (Figure 4 ). One conclusion is that the growth response of the heart, whether it is hypertrophy or dilatation, is mutation-specific rather than gene-specific.\n\n It is very perplexing that mutations in the same gene can induce what appear to be 2 apposing phenotypes, namely, Age is the subject's age at diagnosis. LVEF indicates left ventricular ejection fraction; LVEDD, LV end-diastolic dimension; LVSF, LV shortening fraction; LVWT, LV wall thickness; S, cardiac sinus; IRBBB, incomplete right bundle-branch block; MI, myocardial infarction; and ST and T wave abn., ST-segment abnormality and T-wave inversion in the ECG.\n\n hypertrophy or dilatation. The normal compensatory response of the heart to physiological or pathological stimuli is hypertrophy or dilatation or both. 1 We have shown that a cTnT mutation (Arg92Gln) responsible for FHCM expressed in transgenic mice is incorporated into the cardiac sarcomere myofibrils, 20 exhibits myocyte disarray 21 and increased fibrosis, 20 and is associated with upregulation of growth factors such as insulin-like growth factor and transforming growth factor, 22 as is observed in human HCM. 23 Similar upregulation of growth factors is observed in the transgenic rabbit model of human HCM. 22, 24 Most investigators agree that the hypertrophy is a secondary phenotype, which is further confirmed by our recent findings showing reversal of the fibrosis in the mouse model with losartan 25 and reversal of both fibrosis and hypertrophy with simvastatin 26 in the rabbit. In our family with DCM due to the cTnT mutation (Arg141trp), this compensatory growth response is absent. It is expected that cardiac contractility will be impaired, because residue 141 is required for the troponin-tropomyosin complex to bind to actin. 27, 28 The growth factors will most likely be upregulated, but why no growth? A likely reason stems from recent studies showing that the amino terminus (residues 1 to 153) of cTnT is essential for filament and sarcomere assembly. In vitro site-directed mutagenesis of the tail of cTnT showed that increasing elimination of residues 1 to 153 correlated with increasing to virtually complete elimination of the tropomyosin binding to actin. 28 It appears that the amino-terminal tail of cTnT is essential for assembly and anchoring of the troponin-tropomyosin complex onto the thin filament. Thus, despite mitotic and trophic simulation, the autosomal dominant inherited cTnT (Arg141Trp) acts as a poison peptide to inhibit filament assembly, which stymies the growth response. The chronic impaired contractility leads to increasing left ventricular filling pressure and wall stress, resulting in further mechanical dilatation and ultimately cardiac failure and death. These postulates are based on incomplete data at this time, particularly given that a 3D model of TnT is not available. 29 Nevertheless, many of these hypotheses can be addressed in genetic animal models, which could provide insights fundamental to the ultimate goal of modulating cardiac growth. Documentation of mutations in the same gene resulting in dilatation or hypertrophy has intriguing implications. Genetic animal models should provide insight into understanding the fundamental difference between these responses. It is potentially possible to induce FHCM and FDCM in the same animal model with the same gene but with different mutations. Comparison of the growth factors or other genes upregulated during hypertrophy versus dilatation on the same genetic background should provide insight into the mediators of both cardiac growth responses heretofore not possible.", "qa": [["10_6009711_3_1", "What are the clinical features of dilated cardiomyopathy (DCM) in this family?\n", "The clinical features of DCM in this family include depressed contractile function, ventricular dilatation, and symptoms of congestive heart failure. There have been no documented cases of sudden death in this family, and none of the echocardiograms or ECGs showed ventricular hypertrophy. The family does not represent hypertrophic cardiomyopathy (HCM) that has evolved to end-stage dilatation, as several members developed DCM during childhood."], ["10_6009711_3_2", "How do mutations in the cTnT gene contribute to familial hypertrophic cardiomyopathy (FHCM)?\n", "Mutations in the cTnT gene have been established as the third most common cause of FHCM. FHCM caused by cTnT mutations usually exhibits mild cardiac hypertrophy but a high incidence of sudden death. However, a recent finding showed that a deletion of 1 amino acid from cTnT can cause familial dilated cardiomyopathy (FDCM) with a high frequency of sudden death. The growth response of the heart, whether it is hypertrophy or dilatation, is mutation-specific rather than gene-specific."], ["10_6009711_3_3", "What is the role of the amino-terminal tail of cTnT in cardiac growth response?\n", "The amino-terminal tail of cTnT is essential for assembly and anchoring of the troponin-tropomyosin complex onto the thin filament. In the case of the cTnT mutation (Arg141Trp) responsible for DCM in this family, the mutation acts as a poison peptide that inhibits filament assembly, stymying the growth response. The chronic impaired contractility leads to increasing left ventricular filling pressure and wall stress, resulting in further mechanical dilatation and ultimately cardiac failure and death."]]}, {"passage_id": "69_28692981_3", "passage": "Diabetes distress includes frustration with self-care, concerns about diabetes complications and the future, worries about the quality of medical care and the cost of that care, and perceived lack of support from family members and/or friends [81] [82] [83] . Diabetes distress is actually more common than depression in individuals with diabetes with a prevalence of 18-35 % [15, [84] [85] [86] [87] . Similar to depression, diabetes distress is associated with worsening glycemic control [81, 83, 85, 88] , reduced self-care [83, 89] , and increased morbidity [90] . What is not known is whether or not rates of diabetes distress are higher among older adults compared to other populations. Many older adults may feel overwhelmed with the demands of self-care, perceive limited support from health-care providers, or experience confusion regarding conflicting treatment recommendations for multiple health conditions [45, 91] . Lowering diabetes distress in older adults may be all the more important given recent research demonstrating an association between diabetes distress and glycemia [81, 85] . For this reason, an improved understanding of the frequency and seriousness of diabetes distress in older adults is needed.\n\n Effective screening tools, such as the Diabetes Distress Scale [92] or the Problem Areas in Diabetes [12] , may aid providers in recognizing diabetes distress during a medical visit. Improving providers' ability to recognize and respond to older adults' diabetes distress may help gain their trust [93] , which can increase adherence to treatment recommendations and self-care behaviors [94] . While diabetes distress is not a new concept in diabetes care, only a few validated treatments are available. Further, interventions tailored to older adults are needed. Problem-solving interventions specific to diabetes and diabetes self-management education may reduce diabetes distress as well as improve diabetes self-care behaviors [95\u2022] ; however, older adults may have cognitive limitations that interfere with effective use of problem-solving, and this intervention has not been evaluated in an older sample of diabetes patients. More research is needed to establish safe and effective treatments (e.g., exercise, medical nutrition therapy, psychotherapy) for diabetes distress, particularly treatments tailored to the unique needs of the older population.\n\n Many persons with diabetes and depression also have comorbid anxiety disorders, such as generalized anxiety disorder (GAD) or panic disorder [96] . One study found that individuals with diabetes may be particularly vulnerable to comorbid major depressive disorder (MDD) and GAD and that both disorders may increase the likelihood of unhealthy lifestyle behaviors, such as smoking, poor diet, and physical inactivity, which also increase the likelihood of diabetes and disability [97] . Further, patients with diabetes might also worry about the development of diabetes complications, which might result in anxiety and symptoms of GAD [97] .\n\n Diabetes and comorbid anxiety disorders and elevated anxiety symptoms also have been shown to be associated with increased diabetes complications, worsened blood glucose levels, reduced quality of life, increased depression, increased body mass index (BMI), and greater disability [96] . Importantly, anxiety may complicate diabetes management by increasing patients' difficulty distinguishing between feelings of anxiety and symptoms of hypoglycemia, fear of taking insulin injections, or possible needle phobia. Moreover, fear of hypoglycemia can lead some patients to maintain blood glucose levels above target levels. Some research indicates that older adults with diabetes report higher levels of anxiety compared to older adults without diabetes; thus, routine screening for anxiety during medical visits may be warranted [98] .\n\n Treatment recommendations for anxiety disorders in older adults involve conducting a comprehensive assessment that includes collecting collateral information from family members and caretakers, assessing common comorbidities of depression and cognitive impairment, and ruling out delirium, medication-induced anxiety, and medical conditions, including, but not limited to, thyroid disease, B 12 deficiency, cardiac illness, and metabolic changes [99] . Psychoeducation is important to educate patients and families regarding the nature of anxiety disorders, and to dispel stigma, misinformation, and other barriers that may prevent treatment adherence [99] . To further promote learning and managing anxiety, bibliotherapy has been found to be beneficial for the treatment of later life anxiety disorder [100] .\n\n Research has shown that CBT was superior to minimal contact or wait-list comparison conditions in reducing anxiety and coexistent symptoms (depression, sleep) among older adults [101, 102] . Furthermore, telephone-based CBT (CBT-T) with older adults was found to be superior to informationonly in reducing general anxiety, worry, anxiety sensitivity, and insomnia immediately following the intervention, but only the reductions in worry were maintained by the 6-month follow-up assessment [100] .", "qa": [["69_28692981_3_1", "What are some potential factors that contribute to diabetes distress in older adults?\n", "Some potential factors that contribute to diabetes distress in older adults include feeling overwhelmed with the demands of self-care, perceiving limited support from health-care providers, and experiencing confusion regarding conflicting treatment recommendations for multiple health conditions. These factors may lead to increased feelings of distress and anxiety related to managing diabetes."], ["69_28692981_3_2", "How does diabetes distress impact glycemic control and self-care behaviors?\n", "Diabetes distress has been found to be associated with worsening glycemic control and reduced self-care behaviors. Individuals experiencing diabetes distress may struggle with adhering to treatment recommendations and engaging in self-care behaviors, which can lead to poorer management of their diabetes and potentially negative health outcomes."], ["69_28692981_3_3", "Are there any effective treatments available for diabetes distress in older adults?\n", "While there are only a few validated treatments available for diabetes distress, interventions tailored to older adults, such as problem-solving interventions specific to diabetes and diabetes self-management education, may help reduce diabetes distress and improve self-care behaviors. However, it is important to consider the potential cognitive limitations of older adults and evaluate the effectiveness of these interventions specifically in older populations. Further research is needed to establish safe and effective treatments, including exercise, medical nutrition therapy, and psychotherapy, tailored to the unique needs of older adults with diabetes distress."]]}, {"passage_id": "32_2741896_4", "passage": "19 Duodenal exclusion is not generally needed, and is reserved for cases of extensive tissue loss. 41 Proximal bowel decompression by a gastrostomy has also been recommended. 13 A route for nutrition, such as a feeding jejunostomy is also important. 13, 41 Colonic defects are managed differently. They can be repaired with either direct closure, or resection with either primary anastomosis or stoma creation. During surgical exploration, it is crucial to fully mobilize the bowel; despite a normal appearing anterior bowel wall, a posterior wall erosion could be missed. 11, 13 Resection should be performed back to grossly normal colon. 13 In general, primary colonic anastomosis is not advised, although successful outcomes have been also reported with its use. 28 If severe contamination is noted at exploration, or if the patient is malnourished or acutely ill, a temporary colostomy is preferred. 41 Colostomies in the sigmoid (Hartmann's procedure) or transverse colon are thought to allow immediate fistula control with minimal intraperitoneal contamination. The colostomy site should be placed away from the axillofemoral graft and can be left closed, to be opened postoperatively to avoid further intraoperative contamination. 8 Omental interposition is universally advocated. 19, 30, 44 Finally, bowel \n\n Aortic Paraprosthetic-colonic Fistulae repairs are assessed by some with contrast studies prior to restarting oral intake. 43 SAEFs tax the ingenuity of vascular surgeons. Our review showed a wide variety of therapies, including intestinal stomas or primary colonic repair; graft removal with extra-anatomic bypass for revascularization or graft revision (the latter by replacing the involved graft with homograft or with a new prosthetic graft, aided by omental interposition, re-suturing of a previously involved anastomosis, or endovascular placement of a stent-graft). The wide variety of approaches and the small number of patients treated are not sufficient to provide evidence-based recommendations.\n\n Most reports failed to cite follow-up periods (28 papers). For those studies that did so, the time span was very wide (0e72 months; average 8.4). All but three investigators documented follow-up periods of <2 years. The short-term outcomes in patients with aorto-colonic fistulae were generally favorable (22) . In 19 cases the outcome was unknown. Ten patients died of a cause directly related to the SAEF or to its therapy. One patient was reported dead from unrelated causes (not specified). Complications reported after treatment of a PEF include pulmonary embolism, infected pseudoaneurysm, bilateral graft limb thrombosis, above-the-knee amputations, recurrent infection, limb or colon ischemia and renal failure.\n\n SAEF involving the colon is a rare but well-known complication of aortic reconstructive surgery. It is a dreaded one, associated with high morbidity and mortality. High clinical suspicion and prompt therapy are essential in the management of these patients to avoid catastrophic consequences due to a delayed recognition of a highly treatable condition.", "qa": [["32_2741896_4_1", "What are the surgical options for managing colonic defects in cases of aortic paraprosthetic-colonic fistulae?", "Colonic defects in cases of aortic paraprosthetic-colonic fistulae can be repaired through direct closure, resection with primary anastomosis, or stoma creation. The choice of repair method depends on factors such as the extent of tissue loss, contamination, and the patient's overall health. Primary colonic anastomosis is generally not advised, but successful outcomes have been reported. Omental interposition is universally advocated to aid in the repair process."], ["32_2741896_4_2", "What are the short-term outcomes for patients with aorto-colonic fistulae?", "The short-term outcomes for patients with aorto-colonic fistulae are generally favorable. However, the follow-up periods in most studies were not well-documented, and the time span varied widely. The average follow-up period was 8.4 months, with most studies documenting follow-up periods of less than 2 years. It is important to note that some patients died as a result of the fistula or its therapy, and complications such as pulmonary embolism, infected pseudoaneurysm, limb ischemia, and renal failure were reported after treatment."], ["32_2741896_4_3", "Why is high clinical suspicion and prompt therapy important in the management of patients with aortic paraprosthetic-colonic fistulae?", "Aortic paraprosthetic-colonic fistulae are rare but serious complications of aortic reconstructive surgery. They are associated with high morbidity and mortality rates. Prompt therapy is crucial to avoid catastrophic consequences that can arise from a delayed recognition of this highly treatable condition. High clinical suspicion is necessary to identify the presence of a fistula, and early intervention can help prevent further complications and improve patient outcomes."]]}, {"passage_id": "41_12645392_1", "passage": "It took 8 months for the first appointment with the neurologist and it took another 4 months for neurologist's diagnosis observation and reevaluation 8 . Systematic reviews of ALS patients, in the last decade, have shown 9 to 10% of false-positive ALS diagnosis. These, primarily included in the group of ALS at El Escorial Revisited, have unusual developments, with a break of the progression of chronic and progressive motor involvement and the appearance of signs and symptoms uncommon in clinical course, leading to a careful review diagnostic, pointing to other diseases such as multifocal motor neuropathy (MMN) and Kennedy disease 9, 10 . The objective of this study is a critical analysis of the ALS diagnostic criteria based on clinical presentations of patients with atypical presentation of motor neuron disease.\n\n The Motor Neuron Disease Unit at the Neuromuscular Diseases Clinic in UNIFESP-EPM, running regularly since 1999, has sought to follow the development of diagnostic criteria for MND / ALS. The current diagnostic criteria are those defined by the El Escorial Revisited, in which patients are subjected to a memorandum of clinical research in the WFN, previously cited.\n\n The outpatient monitoring is carried out under regular (at least quarterly) periodic consultations encompassing multidisciplinary orientation therapy. To the best characterization of the goals, these patients' medical records were analyzed in retrospect, with an aim at especially identifying the following medical conditions: patients with ALS initial clinical diagnosis, with an illness history longer than two years, classified as probable or defined ALS, with different clinical course from the initial diagnosis, then ruling out MND / ALS diagnosis. Patients characterized, initially, with other neuromuscular diseases, evolving, later on, to classic aspects of MND / ALS.\n\n Of the 540 patients registered in the Clinic, 190 patients met the MND / ALS diagnostic criteria, complemented with laboratory research in compliance with both research protocols and regular monitoring. Thirty of these patients (15.78%) had their diagnosis completely changed, during the clinical observation development period (Table 1) .\n\n On the other hand, three patients with initial symptoms and diagnosis of other neuromuscular diseases developed features typical of MND / ALS during the clinical evolution. They are male, aged between 55 and 58 years old, whose characteristics are described in Table 2 .\n\n The Motor Neuron Disease Unit is a reference service, and last months, has been receiving a great number of patients with defined ALS, which reduces the number of false negative diagnosis in this work. \n\n Despite the recent refinement of the World Federation of Neurology Consensus for ALS diagnosis, erroneous diagnosis is not infrequent.\n\n Even in an experienced ALS diagnostic service at the MND / ALS Clinic at UNIFESP-EPM, thirty patients out of a group of 190 with regular monitoring and laboratory research for complete characterization of ELA, have had their initial diagnosis changed over time. These patients' clinical presentations display features that can help in ALS diagnosis, especially as to what regards a definitive diagnosis of this disease 11 .\n\n The age of onset of first symptoms, usually at less than 30, increases the proportion of the differential MND / ALS diagnosis. The early onset, represented by 5 of the 30 patients with false positive diagnosis, displayed genetic abnormalities, including deficiency of the enzyme hexosaminidase A and B 12 , lack of expression of proteins of the cytoskeleton of cortical spinal tract in hereditary spastic paraplegia 13 , amendment of the suppressor gene expression in the formation of neurinomas in the peripheral nervous system in neurofibromatosis type I, or abnormalities of muscle protein constituents of the cytoskeleton such as disferlina.\n\n Unilateral/Bilateral -MND/ALS has, characteristically, unilateral initial presentation, involving most of the time limb distal regions, where roots C8-T1 and L5-S1 are the most commonly affected, with ipsilateral or contralateral progression to the other roots, in a progressive and cumulative manner.\n\n Forms with peculiar clinical presentation as the monomelic atrophy of Hirayama 14 , attended with atrophy of a limb, predominantly in the upper limbs, in youths, with self-progression or, in some cases, slow progression 15 . In 12 (40%) of the 30 false-positive cases, we found unilateral atrophy, due to the specific motor involvement linked to immunoglobulins, in the associated cases of the multifocal motor neuropathy or monoclonal gammopathies 16 related to autoimmune dyscrasies.", "qa": [["41_12645392_1_1", "What are the diagnostic criteria for Motor Neuron Disease (MND) / Amyotrophic Lateral Sclerosis (ALS) based on the El Escorial Revisited guidelines?\n", "The current diagnostic criteria for MND / ALS are defined by the El Escorial Revisited guidelines. These criteria involve a memorandum of clinical research and are used to classify patients based on their clinical presentation and progression of motor neuron disease."], ["41_12645392_1_2", "How common are false-positive ALS diagnoses and what are some conditions that can mimic ALS symptoms?\n", "Systematic reviews have shown that false-positive ALS diagnoses occur in approximately 9 to 10% of cases. Some conditions that can mimic ALS symptoms include multifocal motor neuropathy (MMN) and Kennedy disease. These conditions may have unusual developments and the appearance of signs and symptoms uncommon in the typical clinical course of ALS."], ["41_12645392_1_3", "How does the Motor Neuron Disease Unit at the Neuromuscular Diseases Clinic in UNIFESP-EPM approach the diagnosis and monitoring of MND / ALS patients?\n", "The Motor Neuron Disease Unit at UNIFESP-EPM follows the development of diagnostic criteria for MND / ALS and conducts regular periodic consultations with patients. These consultations involve multidisciplinary orientation therapy and aim to characterize the goals of each patient's condition. The medical records of patients are analyzed retrospectively to identify those with atypical presentations or changes in diagnosis over time."]]}, {"passage_id": "21_27203911_0", "passage": "In a very large percentage of patients suffering from in flammation of the lung of the lobar type, pneu:mococci are present in the lesion. In isolated instance , other organisms, as , Bacillus inftuenm or B. pne u nwnim, are found in pure culture. It bas not been our purpose to con sider these latter cases, but ou r attention has been given entirely to the group of cases in which Di p lococcus p1iewmonim is pr ent and is apparently the etiological agent. As is well known, cliplococci, which at present cannot be differentiated from the pneumococcus, may be present in pneumonia of the lobular type (in which the clinical course is quite distinct from that in lobar pneumonia); they may also be present in other purely localized lesion s in the body, entirely unassociated with any affection of the lung, and they may even be the organisms concerned in certain cases of septicremia in man without any local lesions whatever. Moreover, organisms with identical characteristics, so :far as yet determined, are found with so great :frequency living on the mucous membranes of the mouth and throat of perfectly healthy individuals that they may be considered normal inhabitants of the mouth and throat cavities. In the face of such facts as these, how can it be maintained that Diplococcus p neitmonim i the primary cause of such a well-characterized acute infectious disease as acute lobar pneumonia? In view of the present general consensus of opinion that this theory is true, one is indeed rash even to suggest the po ibility that there may be another agent con cerned. On the other hand, it is important that uch a possi bility should not be overlooked. Even though it should be shown, however, that pneumococci do not play the pr i mary etiologic role in the natural infection, their association with the lesion and their :frequent invasion of the blood render it evi dent that they play an important part in the process and probably the most important part in the outcome, just as do streptococci in certain diseases, such as smallpox and scarlet fever, of which it is general ly believed that the natural infec tion is due to specific etiologic agents.\n\n Up to within a relatively short time, the most important link in the chain of evidence that pneumococci cause pneumonia, namely the reproduction of the disease in animals, was lacking. Most important studies dealing with the experimental produc tion of acute lobar pneumonia\u00b7 were published in 1904 by Wads worth.1 By carefully balancing the .general resistance of the animal with the virulence of the race of p:p.eumococci employed and by injecting the organisms intratracheally, he was able, in 1 a series of rabbits, to induce a diffuse exudative pneumonia like the acute lobar pneumonia seen .in man;\n\n More recently Lamar and Meltzer,2 and W ollstein and Melt zer 3 have succeeded in regularly producing a diffuse pne11-monia of the lobar type in dogs, by injecting from 10 to 15 c.c. of the fluid culture directly into one bronchus through a rubber tube passed through the trachea, following the injection of the fluid by air blown through the tube, so as to force the infectious material into the fi ner ramifi cations of the bronchi. The pneu monia produced in dogs runs a more rapid course, resolution occurs earlier-in three or four days-and the mortality is much less than in pneumonia in man.\n\n Using a similar technic, these investigators have produced diffuse lesions in the lungs of dogs with other micro-organisms. When streptococci are injected, the lesions tend to resemble more closely those seen in bronchopneumonia in man. 4 \u2022 The observers lay stress on the greater tendency in this case to a leucocytic infi ltrati o n of the lung framework, and to a much lessened formation of fibrin. These differences between the pneumonia produced by the injection of streptococci and that following the injection of pneumococci they ascribe to inherent difference& in the nature of the micro-organisms concerned, and not to relative differences in virulence. By a similar method of intratracheal injection, Winternitz and Hirsch felder 5 haye succeeded in producing pneumonia of a lobar type in rabbits. In these experiment-; also, large amounts 0\u00a3 the culture material ( 4 or 5 c.c.) were injected.\n\n From experiments which I have carried on, using the same method, it is evident that successful results in rabbits depend somewhat on the race of organisms employed.", "qa": [["21_27203911_0_1", "What are the different types of pneumonia and how do they differ clinically?\n", "There are two main types of pneumonia: lobar pneumonia and bronchopneumonia (also known as lobular pneumonia). Lobar pneumonia is characterized by inflammation of an entire lobe of the lung, while bronchopneumonia is characterized by inflammation of smaller areas of the lung, typically around the bronchi. Clinically, lobar pneumonia often presents with a sudden onset of high fever, chest pain, productive cough, and difficulty breathing. It is usually caused by the bacterium Streptococcus pneumoniae. On the other hand, bronchopneumonia tends to have a more gradual onset and is often associated with a pre-existing respiratory infection. It is commonly caused by bacteria such as Streptococcus pyogenes or Staphylococcus aureus. The clinical course and severity of pneumonia can vary depending on the type and causative organism."], ["21_27203911_0_2", "How do researchers study the role of pneumococci in causing pneumonia?\n", "Researchers have conducted experimental studies to investigate the role of pneumococci in causing pneumonia. In these studies, animals such as rabbits and dogs are used as models. The researchers inject pneumococci directly into the animals' lungs through the trachea or bronchi, mimicking the route of infection in humans. By carefully balancing the resistance of the animal and the virulence of the pneumococci, they are able to induce a diffuse exudative pneumonia similar to acute lobar pneumonia seen in humans. These experimental studies provide evidence that pneumococci can cause pneumonia and help understand the pathophysiology of the disease."], ["21_27203911_0_3", "What are the differences between pneumonia caused by pneumococci and pneumonia caused by streptococci?\n", "Pneumonia caused by pneumococci and pneumonia caused by streptococci have some differences in their clinical presentation and pathological features. When pneumococci are injected into animals, they tend to produce a diffuse exudative pneumonia similar to acute lobar pneumonia in humans. This type of pneumonia is characterized by a rapid course, earlier resolution, and lower mortality compared to pneumonia in humans. On the other hand, when streptococci are injected, the resulting pneumonia tends to resemble bronchopneumonia in humans. It is characterized by a greater tendency for leukocytic infiltration of the lung framework and a lesser formation of fibrin. These differences are attributed to inherent differences in the nature of the microorganisms involved, rather than differences in virulence."]]}, {"passage_id": "24_6764257_0", "passage": "In 1988, a task force of the American Medical Association asserted that ''problems with medical malpractice juries include decisions that are not based on a thorough understanding of the medical facts and awards that increase at an alarming rate and in a fashion that seems uniquely to disadvantage physicians as compared with other individuals who have acted negligently'' [19] . In 2003, the AMA claimed that ''[t]he primary cause of the growing liability crisis is the unrestrained escalation in jury awards that are a part of a legal system that in many states is simply out of control'' [1] . In 2008, there were continuing claims of a crisis with calls for a cap on the pain and suffering component of jury awards, presumably because juries are some combination of incompetent, antidoctor, and irresponsible [2, 5, 30] .\n\n Systematic empirical research on the jury system collected over the past several decades yields evidence inconsistent with these claims. This brief article will review some of the findings, but to do so, I will also describe the jury system for context.\n\n It is crucial as a first step to acknowledge medical negligence does occur. Even though the size of the estimates of its incidence vary and are contested, even the lowest estimates conclude that annual death rates across the United States for this cause number at least 100,000 persons and many more suffer serious injuries, some of them grave [27, 36] .\n\n Estimates of the cost of negligent medical injuries must take into account not only past and future medical expenses but also lost income. One study published in 1989 examined the economic costs for serious birth injuries and injuries that occurred in emergency rooms [28] . Adjusted to 2008 dollars, the average loss for birth injuries was $2.5 million and for emergency room incidents it was $2.3 million. For patients who died as a result of negligent emergency room treatment, the economic losses were estimated at $1.1 million in 2007 dollars.\n\n Research from a number of studies yields estimates that only about one in 25 patients with a negligent or preventable medical claim brought a lawsuit against the health The author certifies that he has no commercial associations (eg, consultancies, stock ownership, equity interest, patent/licensing arrangements, etc) that might pose a conflict of interest in connection with the submitted article. N. Vidmar (&) Duke University School of Law, Durham, NC 27708-0360, USA e-mail: vidmar@law.duke.edu provider [4] . There are various reasons why the claiming rates are so low relative to incidence. These include reluctance to sue the doctor who is perceived as trying to help, the tendency to attribute the adverse outcome to the underling illness for which they sought treatment rather than a result of negligence, and the inability to find a lawyer willing to file a lawsuit because of the low probability of success [36] . Nevertheless, the Henry J. Kaiser Foundation reported that in 2006 there were 12,513 paid claims in the United States, resulting in an aggregate total payment of almost $4 billion involving approximately 13 out of 1000 active, nonfederal physicians [16] .\n\n Juries decide only about 7% of medical malpractice lawsuits [40, 42] . In 2001, the latest year for which there are reliable figures, the U.S. Bureau of Justice Statistics estimated that in the nation's 75 largest counties there were over 1100 malpractice cases tried before juries [7, 8] .\n\n Plaintiffs won only 27% of these trials, about one case in four [8] . However, when the plaintiffs did win, the median award was $422,000, a figure well above median awards in torts and other civil lawsuits. And 16% of the time, the award equaled or exceeded $1 million [7] . Punitive damages are rarely awarded in malpractice cases except in cases of gross malfeasance, such as sexual assaults on patients or fraudulent altering of medical records [36] . In 2001, for example, there were only 15 punitive awards out of 1156 medical malpractice trials in the nation's 75 largest counties; the median punitive award in these cases was $187,000; two punitive awards exceeded $1 million [7] .\n\n The fact that plaintiffs won approximately one case in four tried before a jury-or stated in the obverse, doctors won three out of four trials-suggests that juries do not automatically side with patients over doctors. However, the statistics hide something that needs to be recognized. Some of the patients who lost at trial did not come away emptyhanded. In some instances more than one healthcare provider may be named in the lawsuit.", "qa": [["24_6764257_0_1", "How do juries play a role in the medical malpractice system, and what factors contribute to the perception of jury decisions being disadvantageous to physicians?\n", "Juries are involved in only about 7% of medical malpractice lawsuits, with plaintiffs winning approximately one case in four tried before a jury. Despite this, the perception exists that jury decisions are disadvantageous to physicians. Factors contributing to this perception include decisions that may not be based on a thorough understanding of medical facts, escalating jury awards, and claims of juries being incompetent, antidoctor, or irresponsible."], ["24_6764257_0_2", "What are some reasons why the claiming rates for negligent or preventable medical incidents are low relative to their incidence, and how do these reasons impact the likelihood of lawsuits being brought against healthcare providers?\n", "The low claiming rates for negligent or preventable medical incidents can be attributed to various factors, such as patients being reluctant to sue doctors they perceive as trying to help, attributing adverse outcomes to underlying illnesses rather than negligence, and challenges in finding lawyers willing to take on cases with low success probabilities. These factors contribute to the discrepancy between the incidence of medical negligence and the number of lawsuits brought against healthcare providers."], ["24_6764257_0_3", "How do jury decisions in medical malpractice cases compare to other civil lawsuits in terms of plaintiff success rates and award amounts, and what factors influence the outcomes of these cases?\n", "In medical malpractice cases, plaintiffs win approximately one case in four tried before a jury, with the median award being $422,000 and 16% of awards exceeding $1 million. Punitive damages are rarely awarded except in cases of gross malfeasance. Factors influencing case outcomes include the nature of the malpractice, the evidence presented, and the perception of negligence versus underlying illness as the cause of adverse outcomes."]]}, {"passage_id": "36_51708610_4", "passage": "In scenario (b; lower panel), where complete remission was associated with lower risk of mortality, the estimates hazard ratios of complete remission in the TDCM centered around 0.77, which was the true value. In this scenario, the TDCM did well in estimating the effect of complete remission on survival.\n\n Setting (iii): treatment prolongs life after complete remission. The multi-state models in both panels, again, performed well in detecting the treatment effect on all transitions with the hazard ratios centered near the true values (lower left quadrant of Figure 4(b) ). The estimated hazard ratios for the complete remission-todeath transition centered around 0.77 while the hazard ratios for other transitions centered around 1. An interaction term between treatment and complete remission was added to the TDCM in setting (iii) to ensure the model was correctly specified. As a result, the TDCM with the interaction term performed well, with the estimated hazard ratios centered near their true values for both scenarios (a) and (b). It is important to note, however, that without the interaction term (results not shown), the TDCM overestimates the effect of complete remission and underestimates the effect of treatment on survival in this setting. The bias from the TDCM without an interaction term is a consequence of the model picking up the effect of treatment on survival post complete remission as an effect of complete remission itself on survival. The addition of the interaction term allows the TDCM to account for the differential treatment effects before and after complete remission. Although adding the interaction term to the TDCM led to unbiased estimation of the treatment effect post complete remission, as shown in the lower left quadrant of Figure 4(b) , the variance of the estimated treatment effect for this model can be large compared to the variance of the estimated treatment effect from the multi-state model analysis. As a consequence, the power to detect the treatment effect after complete remission was lower (22.2%) in the TDCM compared to the power to detect the treatment effect (73.5%) in the complete remission-to-death transition in the multistate model (third row of Table 3 ). In settings where there is no differential treatment effects by occurrence of complete remission (settings (i), (ii), and (iv)), the variance of the estimated treatment effect in the TDCM without the interaction term was smaller than the variance of the estimated treatment effects from the multi-state models. As suggested by a reviewer, in practice, one could first test for presence of interaction and include the interaction term if needed.\n\n Setting (iv): treatment prolongs life with or without complete remission. Again, the multi-state model performed well with the estimated hazard ratios centered around the true value for all transitions in both panels. However, the power comparing the transition rates from entry to death was relatively low (21.9%, setting (iv) of Table 3 ) (lower right quadrant of Figure 4(b) ). This is due to the low number of patients experienced this transition because the scenario was set up where 80% of patients would achieve complete remission and only 20% would go from entry to death. The TDCM performed well in this setting with the estimated hazard ratios of both complete remission and treatment centered near their true value. Since treatment prolongs life regardless of complete remission status in this setting, improvement in survival occurred in the treatment arm both with and without complete remission. Therefore, the TDCM without the interaction term performed well estimating the effect of complete remission on survival.\n\n Results from these simulated scenarios illustrate the differences between multi-state models and TDCMs. Multi-state models evaluate the effect of treatment on all possible transitions where the end states of the Table 3 . Probability of rejecting the null hypothesis under scenarios where remission has no effect on subsequent survival. transitions are outcomes in the models. Specifically, in the simulated example, complete remission and death were two outcomes in the multi-state models, whereas death was the only outcome in the TDCMs. In this context, multi-state models can help answer the question of whether the treatment can lead to a faster complete remission; whereas, the TDCMs can answer the question of whether having achieved complete remission can improve survival beyond the effect of treatment. It is worth noting that the effect of complete remission on survival cannot be estimated by the multistate model in this setting because complete remission is one of the states rather than a covariate in the multistate models.\n\n \n\n Multiple software packages in R work well in specific cases but have limitation in others. The survival package 21 is capable of seamlessly performing restricted mean time in state analysis, though the implementation of multi-state Cox models can be more difficult for complex multi-state structures.", "qa": [["36_51708610_4_1", "How do multi-state models differ from TDCMs in evaluating the effect of treatment on survival?\n", "Multi-state models evaluate the effect of treatment on all possible transitions, considering different outcomes in the models. In contrast, TDCMs focus on the effect of treatment on a specific outcome, such as death. Multi-state models can assess whether treatment leads to faster complete remission, while TDCMs can determine if achieving complete remission improves survival beyond the effect of treatment."], ["36_51708610_4_2", "What is the advantage of adding an interaction term between treatment and complete remission in the TDCM?\n", "Adding an interaction term allows the TDCM to correctly account for differential treatment effects before and after complete remission. Without the interaction term, the TDCM may overestimate the effect of complete remission and underestimate the effect of treatment on survival. The interaction term ensures unbiased estimation of the treatment effect post complete remission."], ["36_51708610_4_3", "How does the power to detect the treatment effect after complete remission compare between the TDCM and multi-state models?\n", "The power to detect the treatment effect after complete remission is lower in the TDCM compared to the power in the complete remission-to-death transition in the multi-state model. This is because the variance of the estimated treatment effect in the TDCM can be larger compared to the variance in the multi-state model analysis. However, in settings where there is no differential treatment effect by occurrence of complete remission, the TDCM without the interaction term has smaller variance in the estimated treatment effect compared to the multi-state models."]]}, {"passage_id": "64_8284959_8", "passage": "The authors suggest that common hedonic mechanisms may therefore underlie obesity and drug addiction. It is noteworthy that others found selective BDNF depletion in the ventromedial hypothalamus (VMH) of mice resulted in hyperphagic behavior and obesity. Specifically Cordeira et al. [88] found that expression of BDNF and TrkB mRNA in the ventral tegmental area of wild-type mice was influenced by consumption of palatable, high-fat food. Moreover, amperometric recordings in brain slices of mice depleted of central BDNF uncovered marked deficits in evoked release of dopamine in the nucleus accumbens (NAc) shell and dorsal striatum but normal secretion in the NAc core. Moreover Lobo et al [89] recently showed that activation of D2+ neurons, mimicking the loss of TrkB, suppresses cocaine reward, with opposite effects induced by activation of D1+ neurons. These results provide insight into the molecular control of D1+ and D2+ neuronal activity as well as the circuit-level contribution of these cell types to cocaine reward.\n\n The D2 dopamine receptor has been associated with pleasure, and the DRD(2) A1 allele has been referred to as a reward gene [90] . Evidence suggests that there is a tripartite interaction involving dopamine receptor deficiency, a propensity to abuse alcohol, and reduced sensitivity to rewards. This interaction relies heavily on the genetic characteristics of the individual, with certain ethnic groups having a greater tendency toward alcoholism than others. The DRD(2) has been one of the most widely studied in neuropsychiatric disorders in general, and in alcoholism and other addictions in particular. The dopamine D2 gene, and especially its allele TaqI A1 allele may also be involved in comorbid antisocial personality disorder symptoms, high novelty seeking, obesity, gambling and related traits [91] . The mesocorticolimbic dopaminergic pathway system plays an especially important role in mediating reinforcement by abused drugs, and it may be a common denominator for addictions such as alcoholism [92] .\n\n When the mesocorticolimbic dopamine reward system dysfunctions (perhaps caused by certain genetic variants), the end result is Reward Deficiency Syndrome (RDS) and subsequent drug-seeking behaviors. RDS refers to the breakdown of the reward cascade, and resultant aberrant conduct, due to genetic and environmental influences [30] . Alcohol and other drugs of abuse, as well as most positive reinforcers, cause activation and neuronal release of brain dopamine, which can decrease negative feelings and satisfy abnormal cravings. A deficiency or absence of D2 receptors then predisposes individuals to a high risk for multiple addictive, impulsive, and compulsive behaviors. Although other neurotransmitters (e.g., glutamate, gamma-aminobutyric acid (GABA), and serotonin) may be important in determining the rewarding and stimulating effects of ethanol, dopamine may be critical for initiating drug and food craving and for reinstating substance use during protracted abstinence [93] .\n\n Exploration of various treatment approaches for the most part reveal poor outcomes in terms of relapse prevention and continued drug hunger. Pharmacological therapies for drug addiction have had limited success because these powerful agents have focused on maintenance or interference with drug euphoria rather than correcting or compensating for pre-morbid dopamine system deficits. Blum and Gold [66] proposed a paradigm shift in residential, non-residential and aftercare involving the incorporation of genetic testing to identify risk alleles coupled with D2 receptor stimulation using neuroadatogen amino acid precursor enkephlinase -catecholamine -methyltransferase (COMT) inhibition therapy. Such a natural but therapeutic nutraceutical formulation potentially induces DA release could cause the induction of D2-directed mRNA and proliferation of D2 receptors in the human. They further hypothesized that this proliferation of D2 receptors in turn will induce the attenuation of drug-like craving behavior. Finally, these concepts await required neuro-imaging studies for confirmation. Meanwhile very recent studies may shed some new light and potential therapeutic approaches [94] .\n\n Positive outcomes demonstrated by quantitative electroencephalographic (qEEG) imaging in a randomized, triple blind, placebo controlled cross-over study involving oral showed an increase in alpha waves and low beta activity in the parietal brain region. Using t statistics, significant differences observed between placebo vs KB220Z consistently occurred in the frontal regions at week one and then again at week two of analysis (Figure 1) \n\n Comprehensive physical and psychological pre-operative assessments combined with continued medical care and counseling post-operatively are critical for assuring the best possible outcome for patients who undergo bariatric surgery.", "qa": [["64_8284959_8_1", "How does the dysregulation of the mesocorticolimbic dopamine reward system contribute to addictive behaviors?\n", "The dysregulation of the mesocorticolimbic dopamine reward system, possibly caused by certain genetic variants, leads to Reward Deficiency Syndrome (RDS) and subsequent drug-seeking behaviors. RDS refers to the breakdown of the reward cascade due to genetic and environmental influences. When this system dysfunctions, individuals with a deficiency or absence of D2 receptors are predisposed to a high risk for multiple addictive, impulsive, and compulsive behaviors. Dopamine plays a critical role in initiating drug and food craving and reinstating substance use during protracted abstinence."], ["64_8284959_8_2", "How does the D2 dopamine receptor and its genetic variants influence addiction and related traits?\n", "The D2 dopamine receptor, particularly its allele TaqI A1 allele, has been associated with reward deficiency, alcoholism, and other addictions. The DRD(2) A1 allele has been referred to as a reward gene. Certain genetic characteristics, including the DRD(2) gene and its TaqI A1 allele, may also be involved in comorbid antisocial personality disorder symptoms, high novelty seeking, obesity, gambling, and related traits. The mesocorticolimbic dopaminergic pathway system, which involves the D2 dopamine receptor, plays a crucial role in mediating reinforcement by abused drugs and may be a common denominator for addictions such as alcoholism."], ["64_8284959_8_3", "What potential treatment approach is proposed to address pre-morbid dopamine system deficits in drug addiction?\n", "Blum and Gold propose a paradigm shift in the treatment of drug addiction, involving the incorporation of genetic testing to identify risk alleles and D2 receptor stimulation using neuroadatogen amino acid precursor enkephalinase-catecholamine-methyltransferase (COMT) inhibition therapy. This therapeutic nutraceutical formulation potentially induces dopamine release and the proliferation of D2 receptors, which may attenuate drug-like craving behavior. However, these concepts require neuro-imaging studies for confirmation. Additionally, recent studies suggest potential therapeutic approaches, but further research is needed."]]}, {"passage_id": "70_6845822_3", "passage": "In this issue of the JCI, Corbin and colleagues provide new insights into this problem (8) .\n\n Imatinib resistance is distinct from BCR-ABL persistence Importantly, the primary reason for early therapeutic failure of imatinib appears to differ from the probable causes of molecular persistence. Most patients whose leukemia initially responds to imatinib but then soon become resistant show emergence of secondary Ph + clones bearing mutations in BCR-ABL itself (9, 10) . These mutations impair the ability of imatinib to bind to, and thus inhibit, the enzymatic activity of the BCR-ABL kinase. This necessitates therapy with second-generation BCR-ABL inhibitors (e.g., dasatinib and nilotinib) that show more potent activity against native BCR-ABL as well as many of the described imatinib resistance mutations (11) (12) (13) . Interestingly, low levels of these imatinib-resistant subclones can be demonstrated to precede imatinib therapy (10, 14) . Thus, they likely represent clonal diversity of Ph + hematopoiesis at the time of disease diagnosis; and, upon clearance of the major Ph + clone during imatinib therapy, the imatinib-resistant minor clone now exhibits a relative growth advantage and replaces normal hematopoiesis (15) . As would be predicted by this model, the outgrowth of imatinib-binding resistance mutations in BCR-ABL occurs early after the initiation of therapy, and their incidence actually appears to decrease with prolonged TKI therapy (16) . Thus, imatinib resistance mutations do not explain the common finding of stable persistence of BCR-ABL + cells during years of imatinib therapy, raising the question of whether molecular persistence is BCR-ABL dependent or independent and whether its natural history is sinister or benign.\n\n This question has led to a series of investigations of the CML stem cell. It is generally agreed that the leukemia-initiating cell in CML is a BCR-ABL + HSC that, per current knowledge, is immmunophenotypically indistinguishable from normal HSCs and has the phenotype Lin -CD34 + CD38 -. The Holyoake lab was the first to demonstrate that CD34 + cells from the bone marrow of patients with CML are able to survive in the presence of imatinib and other ABL kinase inhibitors (17). Others have confirmed this observation, but there is substantial controversy as to whether TKIs actually inhibit BCR-ABL kinase in the quiescent stem cell fraction of CML", "qa": [["70_6845822_3_1", "What are the primary reasons for early therapeutic failure of imatinib?\n", "The primary reason for early therapeutic failure of imatinib is the emergence of secondary Ph+ clones bearing mutations in BCR-ABL itself. These mutations impair the ability of imatinib to bind to and inhibit the enzymatic activity of the BCR-ABL kinase. This necessitates therapy with second-generation BCR-ABL inhibitors that show more potent activity against native BCR-ABL as well as many of the described imatinib resistance mutations."], ["70_6845822_3_2", "What is the role of CML stem cells in imatinib resistance?\n", "It is generally agreed that the leukemia-initiating cell in chronic myeloid leukemia (CML) is a BCR-ABL+ hematopoietic stem cell (HSC) that is immunophenotypically indistinguishable from normal HSCs. These CD34+ cells from the bone marrow of CML patients are able to survive in the presence of imatinib and other ABL kinase inhibitors. There is controversy regarding whether TKIs actually inhibit BCR-ABL kinase in the quiescent stem cell fraction of CML."], ["70_6845822_3_3", "Does the outgrowth of imatinib-binding resistance mutations in BCR-ABL occur early or late after the initiation of therapy?\n", "The outgrowth of imatinib-binding resistance mutations in BCR-ABL occurs early after the initiation of therapy. However, their incidence appears to decrease with prolonged TKI therapy. This suggests that imatinib resistance mutations do not explain the common finding of stable persistence of BCR-ABL+ cells during years of imatinib therapy, raising questions about the BCR-ABL dependency and natural history of molecular persistence."]]}, {"passage_id": "57_3933765_3", "passage": "For the technologically astute smartphone user, health apps can assist to relief stress from the demands of managing a newly diagnosed or long-standing chronic disease. A useful app will enable better collection, organization, dissemination, and management of information, which brings convenience and helps in the adjustment of lifestyle changes. However, the adoption of a health app is dependent on the perception of the utility of the health apps by patients, clinicians, and app developers. For example, less than a third of the apps assessed in our study provided information on diabetes management, which may imply either a lack of demand Improper information dissemination and use of apps can be detrimental to the user. In fact, miscalculation of insulin doses by an app can potentially be fatal to diabetic patients. 19, 20 It was also observed during the apps screening that many apps provided recommendations or claimed to cure diabetes without any evidence backing, which can mislead the user to act inappropriately. Therefore, elements that would ensure trust in use of apps for diabetes of both patients and clinicians, such as government support in implementation, funding, quality assessment, regulation, and interoperability, should be addressed to improve perceptions on health apps and to drive mHealth adoption.\n\n There is a lack of mHealth regulation regardless of the number of apps in a language. This problem is intensified in countries with a range of health apps for consumers to choose from. Support from an authoritative body and providing clinicians with more guidance on app selection and communication with patients will enhance the incorporation of app use into the clinical pathway. Recommendations should be made based on at least an available, accredited, and clinically relevant app.\n\n App functionalities and content should be assessed to identify potential \"useful\" attributes for diabetes self-management, and this information could be used to create a trusted platform to guide app selection.\n\n For example, the US Food and Drug Administration has issued a consultation on draft guidance for industry and Food and Drug Administration staff, 21 and a digital innovation action plan to commit to the regulation of digital health products. The UK National Health Service launched a beta digital apps library in April 2017 to host approved (from a technical perspective) health care apps that can be trusted by the public. 22 Apps that are listed on the National Health Service platform are assessed using a set of tools to ensure its safety and validity.\n\n The inverse care law, which states that \"the availability of good medical care tends to vary inversely with the need for it in the population served,\" is observed in the use of mHealth. 13, 23 Rural populations and those living in low-and middle-income countries have lower access to medical resources and are more in need of alternative solutions such as health apps. Our study however showed that their needs are not being catered for at present. Although studies have demonstrated the ability of technology to improve access to care, inequality is still high between younger and older and more and less deprived populations. 13 We need apps with elderly friendly features, 24 as the elderly population is capable of adopting mHealth. While e-commerce and m-commerce have grown tremendously in China, mHealth presents more challenges in terms of pricing and regulations. 25 Underdeveloped app markets can focus on creating high-quality apps through partnerships, learning from examples, and translation of high-quality apps to context-specific content and languages for the population of interest. Currently, only 12% of the Indian population speak English. Most of the older and rural Indian population rely on vernacular language for communication, but most Indian apps for diabetes self-management only have an English description, which implies that the app user has to be proficient in English to use an app in a vernacular language. This presents a major gap as future internet and smartphone populations in India will be older, more rural, more gender balanced, and more vernacular. There are a few apps that are translated into various Indian vernacular languages, but no single or a combination of apps covered the full spectrum of diabetes self-management. An example is the \"Humrahi\" app, which educates patients and care givers on diabetes care. Translation of app languages will improve the adoption of apps with larger population coverage.\n\n As diabetes is a complex disease, a stand-alone app is less likely to be effective in helping the patient to achieve good diabetes treatment outcomes. A good app should be tailored to users' requirements and supported by health care-affiliated systems. In addition, governments or insurers can consider reimbursing health apps that have shown to be effective in disease management to better integrate apps into the overall care path.\n\n Moving forward, mHealth in diabetes care should focus more on the safety and effectiveness of apps in diabetes care. Frameworks should be in place to control the quality of apps used for chronic disease management. The reliability of the educational content or advice given by the app is of paramount importance, as such information can potentially elicit behavioural change. 26 For example, diabetes apps can be checked for the advice given on acute complications surrounding blood glucose fluctuations, and the prevention and management of complications and multimorbidities. These frameworks should also be regularly updated as per accepted diabetes guidelines to keep up with the evidence base. We have since developed a tool to systematically assess the content, functionality, and usability of all diabetes apps.\n\n There are some limitations to this study. First, description screening enables the identification of potential apps for diabetes self-management, but not the utility of the app, as the usability and content of the apps were not assessed. Second, the number of apps in the market increases quickly, limiting any precise estimation of app numbers.\n\n Furthermore, studies may lag behind estimates on the number of people with diabetes with constant updates. Third, apps with multiple language versions may be counted more than once. Apps intended for the Indian or Pakistani population may also be described in English, but the screening does not enable the identification of the country of origin of the developer, thus limiting the classification of app by country. Lastly, relevance to diabetes self-management is context specific and dependent on individual needs, but this study covered a larger range of apps to suit different needs.\n\n In conclusion, every patient with diabetes who has a smartphone, speaking one of the above 10 languages, can access an app for diabetes self-management. English and Chinese literate patients with diabetes will have more app choices to self-manage diabetes but may face challenges in selecting the most suitable app. A larger variety of health apps can cater to more diverse user needs, but too many unregulated apps that do not meet users' expectations may lead to app fatigue and erosion of trust in this mode of support for diabetes care. In low-resource settings, one high-quality app for a specific population may suffice to complement diabetes care. While there is an app for everyone, not everyone can have an app. The future of mHealth is rosy with the rise in smartphone ownership and an increase in positive evidence. The onus is on governments and regulators to develop minimum quality standards and quality assurance processes (eg, through curation and certification) to assist the industry, clinicians, and patients alike and to drive mHealth adoption.", "qa": [["57_3933765_3_1", "How do health apps address the challenges associated with managing chronic diseases, particularly diabetes, and what factors influence their adoption and effectiveness?\n", "Health apps offer a technological solution to relieve stress associated with managing chronic diseases by enabling better collection and management of information, aiding in adjusting to lifestyle changes. The adoption and effectiveness of health apps, especially in diabetes management, are contingent on the perception of their utility by patients, clinicians, and app developers. The content and functionality of the apps play a pivotal role in their effectiveness, with factors such as the availability of government support, funding, quality assessment, regulation, and interoperability influencing trust and adoption by both patients and clinicians."], ["57_3933765_3_2", "What challenges and opportunities are associated with the use of health apps for diabetes management in diverse populations, and what steps can be taken to enhance their adoption and safety?\n", "The use of health apps for diabetes management presents various challenges and opportunities in diverse populations, including inequalities in access to medical resources, language barriers, and the need for tailored and accurate content. Opportunities to improve adoption and safety include establishing minimum quality standards, quality assurance processes, and regulatory frameworks to guide app selection and ensure the safety and validity of health care apps. Tailoring app functionalities and content to cater to diverse user needs, particularly in underdeveloped app markets, is essential to enhance adoption and safety."], ["57_3933765_3_3", "What are the critical factors that determine the effectiveness and trustworthiness of health apps in diabetes care, and what measures can be implemented to improve their integration into the overall care path?\n", "The effectiveness and trustworthiness of health apps in diabetes care are influenced by factors such as tailored content, government or insurer reimbursement, and the reliability of educational content. To improve the integration of health apps into the overall care path, governments, regulators, and insurers can consider reimbursing health apps that have shown effectiveness in disease management. Additionally, frameworks should be established to control the quality of apps used for chronic disease management, ensuring the safety, relevance, and regular updating of app content as per accepted diabetes guidelines."]]}, {"passage_id": "70_215054925_9", "passage": "In gliomas, Deng et al., reported that PHF19 is up-regulated and promotes the proliferation and migration of glioblastoma cell lines through direct repression of the promoter of SIAH (seven in absentia homolog 1), an E3-ubiquitin ligase of \u03b2-catenin and thus activation of the Wnt/\u03b2catenin pathway [45] . However, the potential contribution of hPCL3S/PHF19S which is known to be expressed concomitantly with hPCL3L in several glioblastomas cell lines [21] has not been carefully investigated [45] . In a recent study, PHF19L has been clearly identified as a crucial mediator of oncogenesis in multiple myeloma through activation of PRC2 [46] . Several functional assays demonstrated that mechanistically this effect is independent of the small isoform but rely on the www.oncotarget.com interaction of PHF19L with PRC2 components to facilitate the formation of broad H3K27me3-containing genomic domains, possibly through promotion of initial recruitment of PRC2 and subsequent spreading of H3K27me3 [46] .\n\n Regarding the short isoform of hPCL3/PHF19, hPCL3S, it has been shown to be up-regulated in hepatocellular carcinomas (HCC) clinical samples and to promote the growth and migration of HCC in vitro as well as their metastasis in vivo using mouse xenografts models. At the mechanistic level, these effects are totally independent of the PRC2 complexes but rely on the activation of the Wnt/\u03b2catenin pathway [25] . Indeed, the cytoplasmic hPCL3S isoform has no significant effect on \u03b2catenin mRNA transcription but rather interacts directly with cytoplasmic components of the \u03b2catenin destruction complex, notably \u03b2Trp, the E3-ligase for \u03b2catenin. Unfortunately, these authors did not characterize the hPCL3S domain (s) involved in these interactions. Thus, hPCL3S overexpression inhibits the degradation of \u03b2catenin, thereby activating transcription of Wnt/\u03b2catenin target genes such as IL6 which is a well-characterized driver of HCC [25] .\n\n Our study showed several strong similarities with the published study on HCC [25] . Indeed, we demonstrated that hPCL3S positively regulated the proliferation and migration properties of DU145 and PC3 cells and that these effects are also independent of PRC2 activity as shown by the TUDOR W50A point mutant abolishing H3K36me3 which behaves as wildtype hPCL3S. However, we did not detect any significant variation in \u03b2catenin levels upon knock-down of hPCL3S in DU145 cells ( Figure 10C ) nor interaction with \u03b2catenin or the E3-ligase \u03b2Trp (Supplementary Figure 5 ). This apparent discrepancy would suggest that the effects on cell growth and mobility mediated by hPCL3S could rely on the activation of several different cell-specific pathways. Given these results, it would be interesting to identify proteins specifically interacting with the hPCL3 PHD1 domain trough affinity purification and mass spectrometry analyses using our LNCaP hPCL3wt stable clones.\n\n The acquisition of resistance to AR-targeted therapy, mainly through neuroendocrine transdifferentiation is a major clinical problem for prostate cancer since it is associated with poor prognosis. Whereas LNCaP cells which express AR and PSA are similar to prostate adenocarcinomas responsive to AR-depletion therapy, PC3 cells which do not express AR nor PSA but some neuroendocrine markers (NE) are characteristic of prostatic small cell neuroendocrine carcinomas (SCNC) which are aggressive tumors not responding to hormonal therapy [3] . These two cell lines could thus be viewed as models for the neuroendocrine transdifferentiation during tumor progression in prostate cancer [2] . A key finding of our study is that hPCL3S is found overexpressed in hormone-independent (DU145 and PC3) but not in the hormone-dependent cell line, LNCaP.", "qa": [["70_215054925_9_1", "What is the role of PHF19 in gliomas and multiple myeloma?\n", "In gliomas, PHF19 is up-regulated and promotes the proliferation and migration of glioblastoma cell lines through direct repression of the promoter of SIAH, an E3-ubiquitin ligase of \u03b2-catenin, leading to activation of the Wnt/\u03b2-catenin pathway. In multiple myeloma, PHF19L has been identified as a crucial mediator of oncogenesis through activation of PRC2. Mechanistically, this effect is independent of the small isoform but relies on the interaction of PHF19L with PRC2 components to facilitate the formation of broad H3K27me3-containing genomic domains."], ["70_215054925_9_2", "How does hPCL3S contribute to hepatocellular carcinomas (HCC)?\n", "hPCL3S is up-regulated in HCC clinical samples and promotes the growth, migration, and metastasis of HCC. These effects are independent of PRC2 complexes but rely on the activation of the Wnt/\u03b2-catenin pathway. The cytoplasmic hPCL3S isoform interacts directly with cytoplasmic components of the \u03b2-catenin destruction complex, inhibiting the degradation of \u03b2-catenin and activating transcription of Wnt/\u03b2-catenin target genes."], ["70_215054925_9_3", "What is the significance of hPCL3S in hormone-independent prostate cancer?\n", "hPCL3S is found overexpressed in hormone-independent prostate cancer cell lines (DU145 and PC3) but not in hormone-dependent cell lines (LNCaP). This suggests that hPCL3S may play a role in the neuroendocrine transdifferentiation that occurs during tumor progression in prostate cancer, particularly in aggressive tumors that do not respond to hormonal therapy."]]}, {"passage_id": "73_297775_0", "passage": "Leiomyomatosis peritonealis disseminata (LPD) is a rare disease in which multiple smooth muscle or smooth muscle-like nodules develop subperitoneally in any part of the abdominal cavity. These nodules, though histologically benign, cannot be distinguished macroscopically from peritoneal carcinomatosis and gastrointestinal stromal tumors. Only about 140 documented cases were found in the English language literature [1] . However, there are occasional case reports of recurrent LPD. We present here the unique case of LPD in a female who presented over a period of 16 years with benign clinical course and morphology.\n\n A 40-year-old female presented to the gynecology OPD in the year 1997 with history of pain in the abdomen and menorrhagia for the past 6 months. Ultrasound of the pelvis showed multiple intrauterine echogenic lesions suggestive of fibroid uterus. The patient underwent hysterectomy. Histopathologic examination of the resected specimen revealed leiomyomata uterus (Fig. 1) . Five years later, in the year 2002, the patient presented again with history of pain in the abdomen with sudden onset, vomiting, diarrhea, and inability to pass flatus. CT scan of the abdomen showed a well-defined, solid lesion measuring 12.3 9 5.6 9 7.6 cm 3 seen in the pelvis extending below the lower pole of the kidney. A single mass of enhancement was seen over the ileum measuring 1 9 1 cm 2 . Multiple sections from the adnexal mass and peritoneal nodule over the ileum were diagnosed as benign peritoneal leiomyomatosis. No evidence of mitosis or malignancy was seen in the multiple sections studied. The tumor nodules showed positivity for masson trichrome. Immunohistochemistry for desmin, vimentin, ER, and PR was positive in both the adnexal mass and the peritoneal nodule, thereby confirming the diagnosis. Ten years later, in the year 2012, the patient presented again with history of colicky abdominal pain and altered bowel habits. CECT of the abdomen revealed a 6 9 3 cm 2 lesion adherent to the small bowel and ascending colon and numerous peritoneal small nodules. Right hemicolectomy with lymph node dissection was performed. Clinical differential diagnosis of gastrointestinal stromal tumor and LPD was made. Gross examination of the resected specimen revealed a 4 9 2.5 9 1.5 cm 3 gray white mass attached to the serosal aspect of the ileum. Another small nodule measuring 0.5 9 0.3 9 0.2 cm 3 was present on the ascending colon. The wall of the ileum and colon was intact. Microscopically, the tumor consisted of proliferating spindle cells arranged in whorls. No areas of cellular atypia or mitosis were seen. No areas of hemorrhage and necrosis were found within the tumor nodules. An immunohistochemistry panel for desmin, vimentin, ER and PR, and c-kit was put up and nodules showed positivity for desmin (Fig. 2) , vimentin, ER, and PR and negativity for c-kit. A final diagnosis of Leiomyomatosis peritonealis disseminata (LPD) was given.\n\n Discussion LPD is a rare disease and only a relatively small number of cases have been reported so far. Most of the cases are in females, as in our case. Most patients with LPD present without specific symptoms and many documented cases of LPD have been discovered incidentally during surgery (cesarean section, laparotomy, or laparoscopy). The etiology of LPD is unknown, but it is thought to originate from metaplasia of submesothelial, multipotent mesenchymal cells. The developing leiomyomatous nodules probably arise from Muller's epithelium, which is distributed throughout the subperitoneal mesenchyme. In cases of individual predisposition and hormonal stimulation, mullerian derivatives proliferate along lines of myofibrous differentiation [2] .\n\n Diagnosis may be confused with peritoneal carcinomatosis and gastrointestinal stromal tumor. Peritoneal carcinomatosis, however, is often associated with omental cake, ascites, and liver metastases, which have not been reported with LPD. It is important to differentiate diffuse peritoneal leiomyomatosis from gastrointestinal stromal tumor since management in both the cases is different. Gastrointestinal stromal tumor presents with CD117-positive cells; hence, CD117 should be included in the immunohistochemistry panel for LPD along with vimentin, SMA, ER, and PR.\n\n There are no established guidelines regarding the management of LPD. However, therapy needs to be individualized according to the patient's age, hormonal and reproductive status, and symptomatology. Different drugs (gonadotropin-releasing hormone agonist, megestrol acetate, danazol) have been considered in some cases, but with poor results. If intestinal and bladder mass effect symptoms are prominent, a surgical approach is indicated. The management for malignant LPD is more aggressive. Hence, we advise close follow-up of patients with LPD to detect early sarcomatous change.", "qa": [["73_297775_0_1", "What are the symptoms and diagnostic challenges associated with leiomyomatosis peritonealis disseminata (LPD)?\n", "LPD is a rare disease that often presents without specific symptoms. Many cases are discovered incidentally during surgery. However, in some cases, patients may experience abdominal pain, altered bowel habits, and mass effect symptoms. The diagnosis of LPD can be challenging as it can be confused with peritoneal carcinomatosis and gastrointestinal stromal tumors. Peritoneal carcinomatosis is often associated with omental cake, ascites, and liver metastases, which are not typically seen in LPD. Immunohistochemistry panels, including markers such as vimentin, SMA, ER, PR, and CD117, can help differentiate LPD from other conditions."], ["73_297775_0_2", "What is the etiology of leiomyomatosis peritonealis disseminata (LPD)?\n", "The exact cause of LPD is unknown, but it is believed to originate from metaplasia of submesothelial, multipotent mesenchymal cells. The leiomyomatous nodules in LPD are thought to arise from Muller's epithelium, which is distributed throughout the subperitoneal mesenchyme. In cases of individual predisposition and hormonal stimulation, mullerian derivatives proliferate along lines of myofibrous differentiation."], ["73_297775_0_3", "What are the management options for leiomyomatosis peritonealis disseminata (LPD)?\n", "There are no established guidelines for the management of LPD, and therapy needs to be individualized based on factors such as the patient's age, hormonal and reproductive status, and symptomatology. Different drugs, such as gonadotropin-releasing hormone agonists, megestrol acetate, and danazol, have been considered in some cases, but with limited success. Surgical intervention may be necessary if there are significant intestinal and bladder mass effect symptoms. Close follow-up is recommended to detect early sarcomatous changes, as malignant LPD requires more aggressive management."]]}, {"passage_id": "60_51710788_4", "passage": "Moreover, expression of miR-34a-5p was an independent prognostic factor for CRC recurrence [185] miR-106a\n\n qRT-PCR High levels were correlated with OS; low levels were associated with favorable response to 5-FU-based chemotherapy [193] miR-494 qRT-PCR 104 High expressions were significantly associated with shorter DFS and OS. When used as a panel with 5 other miRNAs, the signature can distinguish early relapsed from non-early relapsed CRC. [194] miR-625-3p qRT-PCR 94 High expressions were associated with higher OS, PFS and better response to treatment\n\n The addition of miR-30b to the 2-miRNA signature allowed the prediction of both distant metastasis and hepatic recurrence in patients with stage I-II CRC who did not receive adjuvant chemotherapy [195] A multi-RNA-based classifier (consisting of 12 mRNAs, 1 miRNA (miR-27a) and 1 lnc RNA)\n\n mRNA, miRNA and lncRNA data were retrieved from the TCGA data portal\n\n The classifier can divide patients into high and low risk groups with significantly different OS. Moreover, the classifier is not only independent of clinical features but also with a similar prognostic ability to the wellestablished TNM stage [196] OS: Overall survival ; DFS: Disease free survival; lnc RNA: Long non-coding RNA; TCGA : The Cancer Genome Atlas Project (http://tcga-data.nci.nih.gov/).\n\n detection in stool samples because they are protected in exosomes [72] . Moreover, fecal matter comes into direct contact with the lumen of colon and may include cells exfoliated from cancerous colonocytes. Molecular changes in CRC are more readily detected in the stool rather than in the blood [73] . Although fecal miRNAs were less extensively studied than circulatory miRNAs, the expression of numerous fecal miRNAs have been reported to be dysregulated in patients with CRC or advanced adenomas (Table 3) . Recently, a panel of miRNAs isolated from the stool of CRC patients were found to differentiate not only CRC cases from healthy subjects but also differentiate TNM stages with high sensitivity and specificity [74] . Additionally, miR-135b was found to differentiate among different stages of CRC [75] .\n\n Exosomes are a unique forms of extracellular vesicles, ranging from 30 nm to 100 nm in diameter, which are released into the extracellular space upon the fusion of multivesicular bodies with plasma membranes from diverse cell types. Tumor-derived exosomes are emerging as local and systemic intercellular mediators of oncogenic information through the horizontal transfer of mRNAs, miRNAs, and protein during tumorigenesis [76] . In a recent proteome profiling study of exosomes derived from human primary and metastatic CRC cells, a selective enrichment of metastatic factors and signaling pathway components was observed [77] . High expression of exosomal miR-17-92a cluster was found to be associated with recurrence in late stage CRC patients [78] . Moreover, an elevated exosomal level of miR19a was reported in the sera samples of CRC patients with poor prognosis [78] . Interestingly, a recent report has demonstrated an enrichment of miR-328 from CRC patients' plasma samples collected from colonic veins (i.e., mesenteric veins) when compared to peripheral vein plasma samples and that it was significantly correlated with the development of liver metastasis [79] . Table 4 summarizes a short list of miRNAs of prognostic value identified in exosomes released from CRC cells.\n\n Adjuvant chemotherapy following surgery is adopted as the standard treatment to improve survival in stage III CRC patients [80] . Conversely, in stage II CRC patients, surgical resection of the primary tumor is highly effective without other concomitant treatment. Therefore, the use of adjuvant chemotherapy in all stage II CRC patients is debatable [81] [82] [83] . However, a notable sub-group of stage II CRC patients (~30%) develop tumor recurrence and have poor prognoses. At present, there are a few clinical parameters, including poorly differentiated histology, extramural venous invasion, intestinal obstruction and perforation, that are used as risk factors to identify high-risk patients for adjuvant chemotherapy. Since these clinical parameters are not specific, more reliable biomarkers are needed to identify the high-risk stage II CRC patients and initiate adjuvant chemotherapy to improve their survival. Likewise, other Stage II CRC patients with lower risk can be spared from the toxicity of conventional cytotoxic chemotherapeutic drugs.", "qa": [["60_51710788_4_1", "What are some potential biomarkers that can be used to identify high-risk stage II colorectal cancer patients?\n", "Potential biomarkers that can be used to identify high-risk stage II colorectal cancer patients include poorly differentiated histology, extramural venous invasion, intestinal obstruction, and perforation. However, these clinical parameters are not specific, so more reliable biomarkers are needed to accurately identify high-risk patients and initiate adjuvant chemotherapy to improve their survival."], ["60_51710788_4_2", "How are exosomes involved in the progression and prognosis of colorectal cancer?\n", "Exosomes, which are small extracellular vesicles released by various cell types, including tumor cells, play a role in the progression and prognosis of colorectal cancer. Tumor-derived exosomes contain mRNAs, miRNAs, and proteins that can be transferred to other cells, influencing their behavior and contributing to tumorigenesis. High expression of specific exosomal miRNAs, such as miR-17-92a cluster and miR-19a, has been associated with recurrence and poor prognosis in colorectal cancer patients. Additionally, the enrichment of certain miRNAs, like miR-328, in exosomes collected from colonic veins has been correlated with the development of liver metastasis."], ["60_51710788_4_3", "What is the role of adjuvant chemotherapy in the treatment of stage II colorectal cancer?\n", "Adjuvant chemotherapy following surgery is the standard treatment to improve survival in stage III colorectal cancer patients. However, the use of adjuvant chemotherapy in stage II colorectal cancer patients is debatable. While surgical resection of the primary tumor is highly effective in stage II patients, approximately 30% of them still develop tumor recurrence and have poor prognoses. Currently, clinical parameters such as poorly differentiated histology and extramural venous invasion are used as risk factors to identify high-risk stage II patients for adjuvant chemotherapy. However, more reliable biomarkers are needed to accurately identify high-risk patients and spare lower-risk patients from the toxicity of conventional cytotoxic chemotherapeutic drugs."]]}, {"passage_id": "22_325888_0", "passage": "The burden of asthma and chronic obstructive pulmonary disease (COPD) in Europe Asthma and COPD are common chronic inflammatory respiratory diseases affecting 45 and 23 million people across Europe in 2011, respectively [1] . Respiratory diseases are the third leading cause of death in the European Union (EU) and have a considerable negative impact on patients' physical and psychological wellbeing [2] [3] [4] [5] , imposing a substantial burden on healthcare providers and society as a whole [6] .\n\n Asthma and COPD comprise approximately 78 % of total direct healthcare costs associated with managing respiratory diseases in the EU, amounting to \u20ac42.8 billion in 2011 [7] . The economic burden of asthma and COPD increases markedly when indirect costs -such as those associated with lost productivity and carer timeare considered. In Europe, the annual indirect costs of asthma and COPD are approximately equal to the direct healthcare costs, totalling \u20ac14.4 billion and \u20ac25.1 billion in 2011, respectively [7] .\n\n There are a broad range of options available for the management of asthma and COPD. Controller medicines, such as inhaled corticosteroids (ICS), long-acting muscarinic antagonists (LAMA), long-acting \u03b2 2 agonists (LABA) and anti-immunoglobulin E (anti-IgE), are taken preventatively to manage asthma and COPD -although the effectiveness of anti-IgE has been questioned [8] . In contrast, short-acting muscarinic antagonists (SAMA) and short-acting \u03b2 2 agonists (SABA) are used as rescue medications to provide immediate relief from exacerbations [9, 10] . For patients with persistent asthma and COPD, global clinical guidelines recommend treatment with a fixed-dose combination (FDC) of ICS + LABA, either as a controller medication with as-needed SABA as rescue medication, or as both controller and rescue medication [9, 10] .\n\n Asthma and COPD medicines are commonly administered using either a pressurised metered dose inhaler (pMDI) or a dry powder inhaler (DPI) [9] . pMDIs function by user activation of a pressurised propellant [11] , requiring a degree of dexterity, skill and training to co-ordinate actuation and inhalation in order to deliver the correct dose [9, 12] . DPIs are breath-actuated [11] , with little hand-breath coordination required, making them easier to use than pMDIs [9, 13, 14] , and are typically recommended over pMDIs [15, 16] . Clinicians and guidelines from international bodies recognise that the choice of medicine and inhaler is critical for achieving successful management of asthma and COPD [15] [16] [17] .\n\n Critical inhaler errors -defined as errors which significantly reduce, or prevent entirely, deposition of medicine in the lungs [18] -can be considered a measure of poor inhalation technique. In 2011, Melani and colleagues published results of a three-month, cross-sectional study of 1,664 Italian asthma and COPD patients using DPIs, which found that 44 % of people using budesonide + formoterol (BF) Turbuhaler \u00ae (Symbicort \u00ae Turbuhaler \u00ae ) and 34 % of people using fluticasone + salmeterol (FS) Accuhaler \u00ae (Seretide \u00ae Accuhaler \u00ae ) had poor inhalation technique [19] . Moreover, a systematic review of patients with asthma and COPD found that up to 94 % of DPI users made at least one inhaler error when examined by a healthcare professional (HCP) [20] .\n\n Importantly, HCPs may also demonstrate poor inhalation technique. Independent studies from multiple countries have shown that at least a third of -and in some cases all -HCPs performed at least one critical error with pMDIs and DPIs [21] [22] [23] [24] [25] . Similarly, a review of 20 studies of pMDI and DPI use found that more than three quarters of nurses, and over a third of respiratory specialists, did not perform all stages of inhalation correctly [26] . The frequency with which HCPs can demonstrate poor inhalation technique indicates that commonly prescribed inhalers are difficult to use.", "qa": [["22_325888_0_1", "What are the economic costs associated with managing asthma and COPD in Europe?\n", "The economic burden of asthma and COPD in Europe is substantial. In 2011, the direct healthcare costs for managing these respiratory diseases amounted to \u20ac42.8 billion. When indirect costs, such as lost productivity and carer time, are considered, the annual indirect costs of asthma and COPD in Europe were approximately equal to the direct healthcare costs, totaling \u20ac14.4 billion and \u20ac25.1 billion, respectively."], ["22_325888_0_2", "What are the recommended treatment options for patients with persistent asthma and COPD?\n", "Global clinical guidelines recommend treatment with a fixed-dose combination (FDC) of inhaled corticosteroids (ICS) + long-acting \u03b22 agonists (LABA) for patients with persistent asthma and COPD. This can be used as a controller medication with as-needed short-acting \u03b22 agonists (SABA) as rescue medication, or as both controller and rescue medication."], ["22_325888_0_3", "What are the common inhaler devices used for administering asthma and COPD medications?\n", "Asthma and COPD medicines are commonly administered using either a pressurized metered dose inhaler (pMDI) or a dry powder inhaler (DPI). pMDIs require user activation of a pressurized propellant and coordination of actuation and inhalation. DPIs, on the other hand, are breath-actuated and require less hand-breath coordination, making them easier to use than pMDIs. Clinicians and international guidelines recognize the importance of choosing the right inhaler device for successful management of asthma and COPD."]]}, {"passage_id": "83_22547498_0", "passage": "Recommendations dictate that serum creatinine levels be measured using specific kits calibrated based on international standards using isotope dilution mass spectrometry (IDMS). According to laboratory quality management organizations, the total analytical error associated with the measurement of creatinine levels must be routinely monitored. And last but not least, laboratories should report the glomerular filtration rates (GFR) calculated from established formulas (such as the CKD-EPI) alongside creatinine serum levels. 1 The purpose of these recommendations is to increase the accuracy of GFR estimates based on creatinine levels, the parameter that best describes renal function.\n\n In practical terms, when recommendations are not followed, GFR levels and the ensuing clinical judgment are distorted. For example, various modified test methods based on the Jaffe reaction may underestimate serum creatinine values in individuals with high levels of serum bilirubin or overshoot them by as much as 20% in patients on cephalosporin due to analytical interferences. 2 Possible deleterious consequences such as incorrect diagnosis of renal disease, inadequate dosage of drugs excreted via the kidneys, and delayed referral to nephrology care may occur as a result of improper serum creatinine level measurement. An independent survey carried out with 42 laboratories from all over Brazil revealed that 14 (33%) labs did not use traceable methods or IDMS to measure serum creatinine levels (Alc\u00e2ntara FFP, 2010). One may assume that this ratio is even greater in the Brazilian countryside, considering the widespread availability of kits not adequately calibrated to measure serum creatinine levels. Laboratories not participating in quality assessment programs are believed to have total analytical error levels above recommended thresholds. This is a preoccupying scenario for a number of reasons. First, the GFR estimated from serum creatinine is a cornerstone in the diagnosis and stratification of patients with chronic kidney disease (CKD) and acute kidney injury (AKI). Additionally, GFR is more than an indicator of renal function, as it is directly associated with risk of cardiovascular death and global mortality. provided to patients with CKD. 4 And in it, the diagnosis and stratification of patients with CKD is based on the GFR. Considering that more than 10 million Brazilians have some degree of CKD, the quality of the care provided to this population may be severely affected if serum creatinine levels are inaccurately measured.\n\n Encouraging the standardization of serum creatinine level measurement at a national level may become an important step toward improving the diagnosis and stratification of individuals with CKD and AKI. This measure might have an important role in the prevention and treatment of kidney disease. Additionally, the addition of the estimated GFR level alongside the serum creatinine level in test reports may increase the sensitivity of kidney disease detection.", "qa": [["83_22547498_0_1", "What are the potential consequences of improper serum creatinine level measurement?\n", "Improper serum creatinine level measurement can lead to incorrect diagnosis of renal disease, inadequate dosage of drugs excreted via the kidneys, and delayed referral to nephrology care. This can have detrimental effects on patient outcomes and the quality of care provided to individuals with chronic kidney disease (CKD) and acute kidney injury (AKI)."], ["83_22547498_0_2", "How is glomerular filtration rate (GFR) related to renal function and patient risk?\n", "Glomerular filtration rate (GFR) is a parameter that best describes renal function and is directly associated with the risk of cardiovascular death and global mortality. GFR is used in the diagnosis and stratification of patients with CKD and AKI. It is an important indicator of kidney function and plays a crucial role in determining the appropriate treatment and care for patients with kidney disease."], ["83_22547498_0_3", "How can standardizing serum creatinine level measurement improve the diagnosis and treatment of kidney disease?\n", "Standardizing serum creatinine level measurement at a national level can improve the diagnosis and stratification of individuals with CKD and AKI. It can help prevent improper diagnosis, ensure accurate dosage of drugs excreted via the kidneys, and facilitate timely referral to nephrology care. Additionally, including the estimated GFR level alongside the serum creatinine level in test reports can enhance the sensitivity of kidney disease detection, leading to better prevention and treatment of kidney disease."]]}]