[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "17_28499010_1", "passage": "These include electrocardiography, chest x-ray, laboratory tests (CBC, CMP, BNP, Troponin, ABG), echocardiography, invasive hemodynamic monitoring, and coronary angiogram.\n\n Troponins: Increased levels may result from subendocardial ischemia, myocyte apoptosis, inflammatory mediator activation, and increased myocardial oxygen demand in the setting of fixed coronary disease. It does not necessarily indicate acute coronary syndrome, especially in the absence of typical electrocardiographic findings.\n\n BNP: Initial measurement of BNP supplements clinical judgment. It has been found useful for risk stratification and prognosis, and also monitoring therapy (especially when used with change in weight) [5] , but not to be used to guide therapy. There are no defined targets and values may not necessarily alter use of guideline determined medical therapy (GDMT) [6] .\n\n Invasive hemodynamic monitoring: Routine use is not recommended. The ESCAPE trial showed no improvement in survival with increase in adverse event with use of pulmonary catheter-guided therapy. Indications include hemodynamic uncertainty, persistent symptoms especially with WRF, requirement of parenteral vasoactive agents, and consideration of advanced device therapy or cardiac transplantation. When used, pulmonary capillary wedge pressure (PCWP) \u226518 mmHg favors cardiogenic pulmonary edema but does not exclude non-cardiogenic causes. Table 2 shows the goals of treatment by Heart Failure Society of America 2010 Comprehensive HF Practice Guideline [4] .\n\n \n\n Thorough patient examination, using pulse oximetry and ABG will help to assess requirement for supplemental oxygen, noninvasive positive pressure ventilation (NPPV), or assisted ventilation. \n\n Diuretics: They remain first line although there is lack of safety and efficacy data from randomized clinical trials (RCTs). Patients with increased BUN but stable or mild increase in serum creatinine should continue diuresis with serial monitoring of their BMP. Modest increase in serum creatinine reflecting intravascular volume depletion may require reduced/temporary discontinuation of diuretics, including ACEI/ARB if the patient was on it prior [4] . Adjunctive inotropic therapy may be required. In patients with WRF, use of ultrafiltration, inotropes, or Nesiritide remains controversial, except if refractory to optimal diuretic treatment. Such patients are frequently discharged without adequate decongestion and hence have high rate of short term re-hospitalization. Aggressive decongestion leading to WRF may be associated with improved survival [7] . Diuretics can improve renal function by decreasing renal venous pressure and improving cardiac output which will subsequently improve renal perfusion. Monitoring of treatment involves reevaluation of volume status, evidence of congestion, oxygenation, daily weights, fluid intake and output, watching for and guarding against side effects (WRF, electrolyte abnormalities, metabolic alkalosis), arrhythmia risk, hypoxia, and symptomatic hypotension). Telemetry is usually continued for at least 24 to 48 hours.\n\n When a patient fails to achieve the therapeutic target of decongestion and fluid removal despite large doses of diuretics, usually 0.5-1 kg of weight per day on adequate diuretic therapy in clinical practice, it is referred to as diuretic resistance [8] . Causes include use of sub-therapeutic doses, poor absorption from edematous gut, poor diuretic delivery to its site of action, WRF, high dietary salt intake, braking phenomenon and auto regulation by nephrons to maintain sodium homeostasis, and post diuretic sodium retention (rebound) which occurs when diuretic concentrations in the tubule decline. Strategies to overcome this are shown in Table 3 [9] [10] [11] [12] .\n\n Ultrafiltration: It works by using hydrostatic pressure gradient. Its use in WRF is controversial. PARID CHF trial suggested it may be used as an adjunct therapy to reduce resistance to diuretics, but not alternate therapy. The UN-LOAD trial showed greater control of rate of fluid removal, greater net loss of sodium, less NH activation (isotonic fluid removal), removal of pro-inflammatory cytokines (with potential restoration of responsiveness to diuretics), shortened shorter length of stay (LOS) and readmissions, decreased risk of electrolyte disorder and decreased WRF in diuretic resistant patients [13] . CARRESS-HF trail revealed that stepped diuretic therapy remains superior for preservation of renal function, but non-superior for body weight, although subjects included in the trial were not diuretic resistant. There was also higher rate of adverse events (sepsis, bleeding, WRF) observed in patients that underwent ultrafiltration [14] .", "qa": [["17_28499010_1_1", "What are some of the diagnostic tools and tests used for evaluating patients with heart failure?", "Some of the diagnostic tools and tests used for evaluating patients with heart failure include electrocardiography, chest x-ray, laboratory tests such as CBC, CMP, BNP, Troponin, ABG, echocardiography, invasive hemodynamic monitoring, and coronary angiogram."], ["17_28499010_1_2", "How can troponin levels be altered, and what does an increased level of troponin suggest in the absence of typical electrocardiographic findings?", "Increased troponin levels may result from subendocardial ischemia, myocyte apoptosis, inflammatory mediator activation, and increased myocardial oxygen demand in the setting of fixed coronary disease. However, an increased level of troponin does not necessarily indicate acute coronary syndrome, especially in the absence of typical electrocardiographic findings."], ["17_28499010_1_3", "When should invasive hemodynamic monitoring be considered in the management of heart failure patients, and what does a pulmonary capillary wedge pressure (PCWP) of \u226518 mmHg suggest?", "Invasive hemodynamic monitoring should be considered in cases of hemodynamic uncertainty, persistent symptoms especially with worsening renal function (WRF), requirement of parenteral vasoactive agents, and consideration of advanced device therapy or cardiac transplantation. A pulmonary capillary wedge pressure (PCWP) of \u226518 mmHg favors cardiogenic pulmonary edema but does not exclude non-cardiogenic causes."]]}, {"passage_id": "17_54209026_3", "passage": "In eight animals (8/28), the diagnosis of spinal tumor was presumptive and based on the results of laboratory tests, radiography (5/8), myelography (3/8), chest radiography with pulmonary metastasis (3/8), record of prior skin and/or mammary tumor excision (3/8), and the presence of nodules in the body on clinical examination (4/8) [ Figure 4 ].\n\n The clinical course in relation to the onset of symptoms of neurological dysfunction, until death or euthanasia, ranged from 1-170 days, with an average 42 days of survival. Twenty animals were euthanized, three died, and three underwent palliative treatment, which included rest, nursing care, bladder massage, and use of analgesics and anti-inflammatory medications. Only two dogs survived, one with canine transmissible venereal tumor and one with meningioma, both treated with surgery. \n\n The results differ from previous studies, in which the number of male and female dogs with neoplasms in the CNS was the same [5, 14] , as in the present study female dogs were more affected. Unlike other studies [14, 16] , metastatic spinal tumors predominated. The mean age of the affected dogs was similar to that of the dogs in another study in Brazil [16] . As in other studies, boxers [13, 14] and large dogs [6, 9, 11] were the most affected by spinal tumors, however poodle was a common breed too, probably because of a greater preference for these breed in the region of the country in which this study was conducted.\n\n The neurological syndrome most often encountered was thoracolumbar, as described in other researches [9, 11, 14] . However, out of the 14 cases with thoracolumbar syndrome, neoplasms were found in the cranial thoracic vertebrae in four. Two were meningiomas, one a transmissible venereal tumor, and one a lymphoma. This rostral localization is in agreement with previous information that stated that the thoracolumbar region of the cranial thoracic region is most prone to neoplasms [9] .\n\n The findings observed in plain radiographs were also reported in other studies [9, 11, 15] , who state that bone lysis, bone proliferation, increase in the spinal canal diameter as a result of spinal tumor expansion and pathological fracture in the body or vertebral lamina, are common findings in patients with tumors that affect the vertebrae. These findings were evident in 61% of survey radiographs performed, representing 50% of the cases, so this technique can provide many important diagnostic information.\n\n Although advanced image as magnetic resonance or tomography are superior to myelography for the diagnosis [5] , these tests are not available in the area where the present study was done, therefore myelography was very useful. Myelographic alterations as interruption or deviation of the contrast column indicated localization of the neoplasm [17] in ten out of 11 cases, and the three basic pathologic patterns were recognized, being the frequency of extradural, intradural-extramedullary and intramedullary lesions similar to previous publications [9, 15] , that stated that 50% of tumors are extradural, 35% are intradural-extramedullary, and 15% intramedullary. These findings can be accurate at locating the tumor along the neuraxis, especially when the tumor is a meningioma [15] .\n\n Examination of cerebrospinal fluid may be normal in dogs with spinal neoplasia [17] , as observed in the present study, as most of CSF were normal. Sometimes there is an increase in the protein concentration without an increase in the number of cells, called albuminocytologic dissociation, but this was not observed [17] . The most common tumor associated with neoplastic cells present in the CSF is lymphosarcoma [17] , as observed in the present study, since there was predominance of lymphocytes in two cases however, the morphology of the cells were not evaluated.\n\n Out of the primary neoplasms found, seven were meningiomas, one in the cervical region, two in the cervicothoracic region, three in the thoracolumbar region, and one in the lumbosacral region. Meningioma is the most frequent primary CNS neoplasm affecting the spinal cord in dogs [15] , and in the present study, it was the most common neoplasm after the secondary ones.", "qa": [["17_54209026_3_1", "What are the common diagnostic methods used for spinal tumor in dogs?\n", "The diagnosis of spinal tumor in dogs can be based on laboratory tests, radiography, myelography, chest radiography with pulmonary metastasis, record of prior tumor excision, and clinical examination. These methods can help in presumptive diagnosis and localization of the tumor."], ["17_54209026_3_2", "What is the average survival time for dogs with spinal tumors?\n", "The average survival time for dogs with spinal tumors is 42 days. The clinical course can range from 1-170 days, depending on the onset of symptoms and the progression of neurological dysfunction. Only a small number of dogs survive, with surgical treatment being the most effective option."], ["17_54209026_3_3", "What are the common types of primary neoplasms affecting the spinal cord in dogs?\n", "Meningioma is the most frequent primary CNS neoplasm affecting the spinal cord in dogs. In the present study, seven cases of meningioma were found, with different locations along the spinal cord. Meningioma is followed by secondary neoplasms, such as canine transmissible venereal tumor and lymphoma."]]}, {"passage_id": "50_4443330_0", "passage": "An ophthalmic artery occlusion (OAO) is a partial or complete obstruction of the ophthalmic artery and may lead to severe ischemia of the affected globe and associated ocular tissues. There is central retinal artery occlusion (CRAO) that cause partial or complete obstruction of the central retinal artery; branch retinal artery occlusion (BRAO) that is a partial or complete obstruction of any of the branch tributaries of the central retinal artery; and artertic retinal arterial occlusion (RAO) caused by giant cell arteritis. The recommendations of this Preferred Practice Pattern (PPP) are based on Cochrane-identified reliable systematic reviews. An OAO, CRAO or BRAO can be associated with life-threatening conditions and their incidence increases with age. Risk factors to highlight include cigarette smoking, hypertension, high serum lipid levels, coagulopathy, body mass index, diabetes, and cardiac disease, including atrial fibrillation are all important modifiable risk factors associated with retinal emboli.\n\n A careful systemic evaluation for any underlying disorder(s) should guide therapy. Specifically, causes of vasculitis that represent an ophthalmologic emergency. Acute, symptomatic OAO, CRAO, and BRAO represent urgent ophthalmic conditions and require prompt evaluation. Due to the high risk of ischemic stroke in cases if ocular arterial occlusions, a prompt referral to a stroke center for a medical evaluation is recommended.\n\n Care Process: Patient outcome criteria are to improve or stabilize visual function, reduce the risk of severe consequences (e.g., further vision loss, neovascular glaucoma) or cerebral and myocardial infarction, encourage smoking cessation, controlling chronic systematic diseases (e.g., diabetes, hypertension), brining awareness of the patient's retinal disease to their primary care physician, and maintain or improve quality of life. Thus, an initial examination of a patient starts with a careful medical history, which includes any known systemic disease.\n\n Management recommendations are detailed in this PPP, which includes surgical management and follow-up evaluation. Since diabetes is a common contributor to RAO, the ophthalmologist may wish to become familiar with the Diabetic Retinopathy PPP.\n\n As a service to its members and the public, the American Academy of Ophthalmology has developed a series of Preferred Practice Pattern\u00ae guidelines that identify characteristics and components of quality eye care. Appendix 1 describes the core criteria of quality eye care.\n\n The Preferred Practice Pattern\u00ae guidelines are based on the best available scientific data as interpreted by panels of knowledgeable health professionals. In some instances, such as when results of carefully conducted clinical trials are available, the data are particularly persuasive and provide clear guidance. In other instances, the panels have to rely on their collective judgment and evaluation of available evidence.\n\n These documents provide guidance for the pattern of practice, not for the care of a particular individual. While they should generally meet the needs of most patients, they cannot possibly best meet the needs of all patients. Adherence to these PPPs will not ensure a successful outcome in every situation. These practice patterns should not be deemed inclusive of all proper methods of care or exclusive of other methods of care reasonably directed at obtaining the best results. It may be necessary to approach different patients' needs in different ways. The physician must make the ultimate judgment about the propriety of the care of a particular patient in light of all of the circumstances presented by that patient. The American Academy of Ophthalmology is available to assist members in resolving ethical dilemmas that arise in the course of ophthalmic practice.\n\n Preferred Practice Pattern\u00ae guidelines are not medical standards to be adhered to in all individual situations. The Academy specifically disclaims any and all liability for injury or other damages of any kind, from negligence or otherwise, for any and all claims that may arise out of the use of any recommendations or other information contained herein.\n\n References to certain drugs, instruments, and other products are made for illustrative purposes only and are not intended to constitute an endorsement of such. Such material may include information on applications that are not considered community standard, that reflect indications not included in approved U.S. Food and Drug Administration (FDA) labeling, or that are approved for use only in restricted research settings. The FDA has stated that it is the responsibility of the physician to determine the FDA status of each drug or device he or she wishes to use, and to use them with appropriate patient consent in compliance with applicable law.\n\n Innovation in medicine is essential to ensure the future health of the American public, and the Academy encourages the development of new diagnostic and therapeutic methods that will improve eye care. It is essential to recognize that true medical excellence is achieved only when the patients' needs are the foremost consideration.\n\n All Preferred Practice Pattern\u00ae guidelines are reviewed by their parent panel annually or earlier if developments warrant and updated accordingly.", "qa": [["50_4443330_0_1", "What are the risk factors associated with ophthalmic artery occlusion (OAO), central retinal artery occlusion (CRAO), and branch retinal artery occlusion (BRAO)?\n", "Risk factors associated with OAO, CRAO, and BRAO include cigarette smoking, hypertension, high serum lipid levels, coagulopathy, body mass index, diabetes, and cardiac disease, including atrial fibrillation. These risk factors are important modifiable factors that are associated with the development of retinal emboli and increase the incidence of these ocular arterial occlusions."], ["50_4443330_0_2", "What are the patient outcome criteria for managing ophthalmic artery occlusion (OAO), central retinal artery occlusion (CRAO), and branch retinal artery occlusion (BRAO)?\n", "The patient outcome criteria for managing OAO, CRAO, and BRAO are to improve or stabilize visual function, reduce the risk of severe consequences such as further vision loss or neovascular glaucoma, reduce the risk of cerebral and myocardial infarction, encourage smoking cessation, control chronic systemic diseases such as diabetes and hypertension, bring awareness of the patient's retinal disease to their primary care physician, and maintain or improve quality of life."], ["50_4443330_0_3", "What is the recommended approach for managing ophthalmic artery occlusion (OAO), central retinal artery occlusion (CRAO), and branch retinal artery occlusion (BRAO)?\n", "The recommended approach for managing OAO, CRAO, and BRAO includes a careful systemic evaluation for any underlying disorders, prompt evaluation and referral to a stroke center for medical evaluation due to the high risk of ischemic stroke, surgical management if necessary, and follow-up evaluation. It is also important for ophthalmologists to be familiar with the Diabetic Retinopathy Preferred Practice Pattern (PPP) as diabetes is a common contributor to retinal artery occlusions."]]}, {"passage_id": "57_4967021_0", "passage": "More than 50 years since its discovery [1, 2] , levodopa remains the gold standard in the management of motor symptoms of Parkinson's disease (PD) [3] . Although several systems are affected in PD, including dopaminergic, serotonergic, noradrenergic, cholinergic, glutamatergic, opioid and endocannabinoid systems [4] , it is the loss of dopamine within the nigrostriatal pathway that leads to the emergence of the cardinal motor symptoms of PD [5] . Exogenous levodopa therapy fundamentally restores synaptic dopamine levels in the striatum, which is essential for the correct execution of movements [6] . However, despite its efficacy, long-term levodopa use is complicated by alterations in motor response, such as the development of levodopa-induced dyskinesias (LIDs) [7] . About 30% of PD patients develop LIDs after only 3 years of levodopa use [8] , and approximately 80% of PD patients will develop LIDs over the course of the disease [9, 10] .\n\n The mechanisms underlying LIDs are still unclear. Levodopa induces sharp increases in striatal dopamine levels, which are particularly elevated in PD patients who experience LIDs [11] . However, the notion that LIDs are only due to high exposure to levodopa, which progressively lowers the threshold for dyskinesias until the administered concentration of levodopa needed for its antiparkinsonian action will produce LIDs, making the responses inseparable and causing pronounced motor fluctuations between an 'on' condition with dyskinesia and an 'off' condition with severe parkinsonism [12] , has been questioned This article is part of the Topical Collection on Neuroimaging * Marios Politis marios.politis@kcl.ac.uk recently [13] . In PD patients who experience LIDs, the administration of a high dose of levodopa induces an antiparkinsonian response and dyskinesias at a comparable threshold. This observation indicates that the therapeutic window between the antiparkinsonian response and dyskinesia does not exist, except for the period before the emergence of dyskinesia, and that also other pathways are needed for the development of LIDs [13] .\n\n Another recent study has corroborated this hypothesis [14\u2022] . Elevated putaminal dopamine release was present in de novo PD patients and was associated with an increased risk of later development of LIDs. This suggests that early compensatory changes in striatal dopamine turnover could be a diseaseintrinsic predisposing factor for the development of LIDs, maybe due to changes in non-dopaminergic pathways and not related to the long-term exposure to levodopa [14\u2022] . A large number of studies have demonstrated that LIDs rely on a sequence of events, including abnormalities in corticostriatal neurotransmission, postsynaptic changes in proteins and gene expression, altered neuronal firing and plasticity [15, 16] . Molecular imaging modalities are able to identify minimal alterations at the nanomolecular level, and this is a prerequisite to understand subtle changes in brain activity [17, 18] . Positron emission tomography (PET) molecular probes bind a target, such as a receptor, a transporter or an enzyme, with high specificity and power of resolution [17] . PET molecular imaging has revolutionized the possibilities to gain insight into human brain biology and beyond this to understand the physiology and the pathophysiology of neurological diseases [17, 18] . PET radiotracers have provided invaluable insight into the mechanisms underlying LIDs, and have been used to measure dopaminergic [19] , serotonergic [20] , noradrenergic [21] , cholinergic [22] , glutamatergic [23] , adenosinergic [24] , opioid [25] and cannabinoid systems [24] , phosphodiesterases [26] and other targets [27] .\n\n This review describes the current status of PET molecular imaging of LIDs, and its relation with the underlying mechanisms of PD.\n\n Multiple components of the network between basal nuclei and cortex have been recognized as a substrate for the development of LIDs. At the molecular level, changes in signal transduction and neurotransmission occurring in specific populations of neurons have been linked to the emergence of LIDs [16] .\n\n The main component needed for the development of LIDs is a moderate-to-severe loss of dopaminergic terminals in the dorsal putamen, associated with the incapacity of the terminals to store dopamine. In this condition, the same amount of levodopa administered induces higher release of dopamine in the extracellular space [28] .", "qa": [["57_4967021_0_1", "What are the main systems affected in Parkinson's disease?\n", "Parkinson's disease affects several systems, including the dopaminergic, serotonergic, noradrenergic, cholinergic, glutamatergic, opioid, and endocannabinoid systems."], ["57_4967021_0_2", "What is the relationship between levodopa therapy and the restoration of dopamine levels in Parkinson's disease?\n", "Exogenous levodopa therapy restores synaptic dopamine levels in the striatum, which is essential for the correct execution of movements in Parkinson's disease."], ["57_4967021_0_3", "What are the long-term complications of levodopa use in Parkinson's disease?\n", "Long-term levodopa use in Parkinson's disease can lead to the development of levodopa-induced dyskinesias (LIDs), with approximately 30% of patients developing LIDs after only 3 years of levodopa use and about 80% of patients developing LIDs over the course of the disease."]]}, {"passage_id": "54_12026297_2", "passage": "We repeated these analyses regarding a referral for psychosocial problems by CHPs (no or yes). All independent child variables were dichotomized.\n\n The regression analyses were performed using multilevel techniques because of the hierarchical nature of the data: characteristics of a CHP may have an impact on the assessments of all the children who are seen by the CHP. Multilevel models account for this clustering of individual data by the CHP (n=108). 23, 24 Prevalence estimates presented in the tables and text are weighted by region and age to adjust for differences between the study population and the Dutch population. Test statistics, odds ratios (ORs), and 95% confidence intervals (CIs) were calculated on the basis of the unweighted data.\n\n \n\n In 200 (9.4%) of all 2229 children, the CHP identified 1 or more psychosocial problems. The severity of the problems was rated as mild in 50.8% of these cases, moderate in 39.7%, and severe in 9.5%. At the time of the study, 1.0% of all children were being treated for psychosocial problems by a mental health professional. This group was excluded from all further analyses and 1 child with missing data on CHP-identified problems (the remaining number of nontreated children was 2205).\n\n The CHPs undertook actions in 84% of the nontreated children with identified psychosocial problems. Various management strategies were used: advice or reassurance (72.4%); consultation with day care, colleagues, or official authorities (24.1%); follow-up (23.6%); and referral to another professional (40.7%). Management strategies varied according to the severity of the problems as rated by the CHP ( Table 1) . Follow-up, consultation, and referral were more frequent in those children whose psychosocial problems were rated moderate or severe. Table 2 presents the number of nontreated children with a CBCL total problems score in the normal and clinical range who were identified by CHPs as having psychosocial problems and the management strategies used. Of the nontreated children, 6.1% had a CBCL total problems score in the clinical range (6.4% of all children). The CHPs identified psychosocial problems in 29.4% of the children with a CBCL total problems score in the clinical range (cutoff at 90th percentile). This percentage was 43.6 for those scoring above the 98th percentile of the CBCL total problems score and 47.6 for the children scoring above the 99th percentile. The CHPs identified psychosocial problems in 6.8% of the children with a CBCL total problems score in the normal range. These problems were rated as mild in 60.8% of the cases, moderate in 33.4%, and severe in 5.9%; the CHP rating of children scoring in the clinical range of the CBCL total problems score was 28.0%, 45.8%, and 26.2%, respectively ( 2 =19.03, P\u03fd.001).\n\n No actions were taken in 75.4% of all children with a CBCL total problems score in the clinical range; in 93.8% of these cases this was due to the fact that CHPs had identified no psychosocial problems. Referral to another professional was almost 6 times more likely in children with a CBCL total problems score in the clinical range (15.1%) than in those scoring in the normal range (2.6%). Table 3 presents the association of CBCL problem scales with the identification of and referral for psychosocial problems by CHPs. Identification and referral were 5.4 (95% CI, 3.5-8.5) and 6.5 (95% CI, 3.7-11.5) times more likely in case of an elevated CBCL total problems score, respectively. Looking at CBCL broad-band scales, the ORs were much higher for elevated externalizing scores than for elevated internalizing scores, however, and this was reflected by the associations for the syndrome scales, with ORs being highest for the oppositional and overactive syndromes.\n\n Concerning the sociodemographic variables, Table 4 shows that CHPs identified psychosocial problems relatively frequently in some groups: older children, children of single parents, and children with parents of low educational level. Referral depends on other characteristics, however, being more likely among nonDutch children and children of parents of low educational level. Factors related to pregnancy and delivery had no relation with either identification or referral.", "qa": [["54_12026297_2_1", "How did the CHPs manage the nontreated children with identified psychosocial problems, and did the management strategies vary based on the severity of the problems?\n", "The CHPs undertook various management strategies for nontreated children with identified psychosocial problems, including advice or reassurance, consultation with day care or colleagues, follow-up, and referral to another professional. The management strategies varied depending on the severity of the problems, with follow-up, consultation, and referral being more frequent in children whose psychosocial problems were rated as moderate or severe."], ["54_12026297_2_2", "What percentage of children with a CBCL total problems score in the clinical range were identified by CHPs as having psychosocial problems, and how did the severity of these problems compare to those in the normal range?\n", "Among the nontreated children, 6.1% had a CBCL total problems score in the clinical range, and the CHPs identified psychosocial problems in 29.4% of these children. The severity of the identified problems varied, with 28.0% rated as mild, 45.8% as moderate, and 26.2% as severe. In comparison, the CHPs identified psychosocial problems in 6.8% of the children with a CBCL total problems score in the normal range, with 60.8% rated as mild, 33.4% as moderate, and 5.9% as severe."], ["54_12026297_2_3", "What sociodemographic factors were associated with the identification and referral of psychosocial problems by CHPs?\n", "CHPs identified psychosocial problems relatively frequently in older children, children of single parents, and children with parents of low educational level. Referral, on the other hand, was more likely among non-Dutch children and children of parents with low educational level. Factors related to pregnancy and delivery did not have a significant relation with either identification or referral of psychosocial problems."]]}, {"passage_id": "39_205056066_4", "passage": "37 The findings of a recent meta-analysis of 10 studies with a total of 638 participants indicate that the use of immunosuppressive agents in addition to glucocorticoids did not improve therapeutic efficacy or safety as compared with the use of glucocorticoids alone, 38 raising doubts about whether such adjunctive therapy is appropriate.\n\n Recommendations from the EULAR include the use of methotrexate as a potential adjunct to glucocorticoids in patients with large-vessel vasculitis, 32 but supporting evidence is limited. A meta-analysis of three placebo-controlled randomized trials involving patients with newly diagnosed giant-cell arteritis showed that a regimen of glucocorticoid therapy plus methotrexate as compared with glucocorticoids alone conferred a significant but modest benefit in lowering the relapse rate and in reducing the cumulative dose of glucocorticoids, without reducing the side effects of the glucocorticoids. 39 Data supportive of the adjunctive use of other immunosuppressive agents are even more limited. In a small randomized, controlled trial, the administration of 2 mg of azathioprine per kilogram per day modestly reduced requirements for glucocorticoid therapy in patients with giantcell arteritis and polymyalgia rheumatica. 40 Whereas open-label studies of anti-tumor necrosis factor (TNF) agents initially suggested a benefit, 41 subsequent placebo-controlled, randomized trials have not supported the use of TNF blockers as glucocorticoid-sparing agents in patients with giant-cell arteritis or polymyalgia rheumatica. 42, 43 Therapy targeted at disrupting the function of interleukin-6 is currently undergoing clinical testing. In a series of patients with large-vessel vasculitis, including five patients with giant-cell arteritis, treatment with the interleukin-6 receptor antagonist tocilizumab at a dose of 8 mg per kilogram per month resulted in rapid suppression of systemic inflammation. 44 However, it is not certain whether interleukin-6 blockade is effective for the treatment of vascular inflammation. In one patient with large-vessel vasculitis who had a clinical response to tocilizumab, persistent vasculitis was identified at autopsy. 45 \n\n Aspirin (75 to 150 mg per day), which is used in other high-risk populations to reduce the risk of cardiovascular events, has been suggested as a possible means of reducing the risk of ischemic complications of giant-cell arteritis, but data from randomized trials showing a benefit in this patient population are lacking. If indicated, gastroduodenal mucosal protection should be added whenever aspirin is used. Whereas hydroxymethylglutaryl coenzyme A reductase inhibitors (statins) reduce inflammation, there are no data supporting their use in the management of giant-cell arteritis or polymyalgia rheumatica. Observational data indicate a similar disease course and similar requirements for glucocorticoid therapy in patients who do and those who do not take statins. 46 A r e a s of Uncerta int y Validated diagnostic criteria for giant-cell arteritis and polymyalgia rheumatica are not available. The diagnosis of polymyalgia rheumatica is particularly challenging, since objective and diseasespecific findings are often absent. Randomized trials are needed to determine the best course of treatment for both conditions. The role of imaging studies in diagnosis and follow-up has been insufficiently defined.\n\n Giant-cell arteritis and polymyalgia rheumatica are now recognized as chronic conditions. Often, inflammatory markers remain abnormally elevated, even after a 2-year treatment course. 22 The best way to manage the postacute phase of disease remains to be determined. It is not clear whether more aggressive, longer-term immunosuppression improves outcomes. The coexistence of several vasculogenic immune abnormalities has complicated the development of new, glucocorticoid-sparing therapies. Current therapy offers prompt suppression of some inflammatory pathways, but resistant pathways sustain chronic vascular remodeling.\n\n The American College of Rheumatology (ACR) and the Chapel Hill Consensus Conference have developed criteria to distinguish giant-cell arteritis from other vasculitides (Table 1) . 47 The specificity of these criteria for diagnostic purposes in a general population is undetermined. The EULAR and ACR have suggested provisional classification criteria for polymyalgia rheumatica, 28 but even a score of 5 or more (Table 1) 28 has a sensitivity of only 66% and a specificity of only 81% for the purpose of distinguishing polymyalgia rheumatica from nonpolymyalgic rheumatic conditions. The BSR has published guidelines for the management of giant-cell arteritis 31 and polymyalgia rheumatica, 48 and the EULAR has published guidelines for the management of large-vessel vasculitis. 32 The recommendations in this article are generally consistent with the available guidelines.\n\n The patient in the vignette has biopsy-confirmed giant-cell arteritis, which has responded well to high-dose glucocorticoid therapy and subsequent tapering. As is common in such patients, the patient now presents with symptoms of polymyalgia rheumatica, without evidence of recurrent ischemic manifestations. In this case, the dose of prednisone should be temporarily increased to 10 mg per day to suppress myalgias. Once there are clinical indications of improvement, an attempt should be made to taper the dose again while monitoring the clinical response and levels of inflammatory markers. Additional disease recurrences would raise the possibility of large-vessel involvement, which should be assessed with MRA or CTA. Careful follow-up is required to monitor the patient for any adverse effects of treatment with glucocorticoids.\n\n No potential conflict of interest relevant to this article was reported.\n\n Disclosure forms provided by the authors are available with the full text of this article at NEJM.org. At least one shoulder with subdeltoid bursitis, biceps tenosynovitis, or glenohumeral synovitis, or at least one hip with synovitis or trochanteric bursitis (1 point) Subdeltoid bursitis, biceps tenosynovitis, or glenohumeral synovitis in both shoulders (1 point) * ACR denotes American College of Rheumatology, ESR erythrocyte sedimentation rate, and EULAR European League against Rheumatism. \u2020 According to the provisional ACR-EULAR classification criteria for polymyalgia rheumatica, diagnosis requires that in addition to the mandatory criteria, there must be a score of 4 or more points for additional criteria without ultrasonographic findings (diagnostic sensitivity and specificity, 68% and 78%, respectively) and a score of more than 5 points with ultrasonographic findings (diagnostic sensitivity and specificity, 66% and 81% respectively).", "qa": [["39_205056066_4_1", "What are the current treatment options for giant-cell arteritis and polymyalgia rheumatica?\n", "The current treatment options for giant-cell arteritis and polymyalgia rheumatica include glucocorticoid therapy, methotrexate, azathioprine, and tocilizumab. Glucocorticoids are the mainstay of treatment and are often used alone. Methotrexate has been suggested as a potential adjunct to glucocorticoids in patients with large-vessel vasculitis, but supporting evidence is limited. Azathioprine has shown modest reduction in glucocorticoid requirements in patients with giant-cell arteritis and polymyalgia rheumatica. Tocilizumab, an interleukin-6 receptor antagonist, has shown rapid suppression of systemic inflammation in patients with large-vessel vasculitis, but its effectiveness for vascular inflammation is still uncertain."], ["39_205056066_4_2", "Are there any non-pharmacological interventions or lifestyle changes that can help manage giant-cell arteritis and polymyalgia rheumatica?\n", "Non-pharmacological interventions and lifestyle changes can help manage giant-cell arteritis and polymyalgia rheumatica. Aspirin has been suggested as a possible means of reducing the risk of ischemic complications of giant-cell arteritis, but data from randomized trials showing a benefit are lacking. If indicated, gastroduodenal mucosal protection should be added whenever aspirin is used. While hydroxymethylglutaryl coenzyme A reductase inhibitors (statins) reduce inflammation, there are no data supporting their use in the management of giant-cell arteritis or polymyalgia rheumatica. Observational data indicate a similar disease course and similar requirements for glucocorticoid therapy in patients who do and those who do not take statins. Further research is needed to determine the effectiveness of non-pharmacological interventions and lifestyle changes in managing these conditions."], ["39_205056066_4_3", "What are the challenges in diagnosing and managing giant-cell arteritis and polymyalgia rheumatica?\n", "The challenges in diagnosing and managing giant-cell arteritis and polymyalgia rheumatica include the lack of validated diagnostic criteria and the absence of objective and disease-specific findings in polymyalgia rheumatica. Randomized trials are needed to determine the best course of treatment for both conditions. The role of imaging studies in diagnosis and follow-up has not been sufficiently defined. Additionally, the post-acute phase of disease management and the use of more aggressive, longer-term immunosuppression remain uncertain. The coexistence of several vasculogenic immune abnormalities further complicates the development of new glucocorticoid-sparing therapies."]]}, {"passage_id": "70_15317843_0", "passage": "Wide QRS complex tachycardia (WCT) is a common arrhythmia with important therapeutic and prognostic implications and often presents a diagnostic challenge. WCTs may be ventricular in origin or may be supraventricular, conducted with fixed or functional bundle branch block (BBB) pattern, or supraventricular due to drug or electrolyteinduced changes or pre-excitation. Pre-excited tachycardias (PXT) and drug-and electrolyte-induced WCTs account for only a small minority (1-5%) of causes of WCT. Because most WCTs are either ventricular tachycardia (VT) or supraventricular tachycardia (SVT), conducted with fixed or functional BBB pattern, the clinically relevant problem in the differential diagnosis of WCTs is the differentiation of the latter two. 1 The ECG remains the cornerstone of distinguishing SVT from VT. A bewildering number of ECG criteria have been reported [2] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] for the differential diagnosis of regular WCTs. Using all these traditional ECG criteria, an accurate diagnosis is now possible in about 90% of WCTs. 2, 3, 10 However, many of these criteria are complicated and not consistently present, thus not useful in an urgent setting. Brugada et al. 7 proposed a relatively simple, stepwise, decision tree-like algorithm to differentiate between WCTs due to VT and SVT. However, that algorithm still retained the traditional morphological criteria in its last step. They reported that this algorithm had a sensitivity (98.7%) and specificity (96.5%) superior to those of the currently available criteria. Other authors 1, 10, 18 also found the Brugada criteria useful, though reported a lower sensitivity and specificity. Our aim was to devise another simplified, new algorithm for the differential diagnosis of WCTs by eliminating most of the complicated morphological criteria and compare it with the Brugada criteria.\n\n A different set of patients was used to devise the algorithm from that used to test the already established algorithm. We used retrospectively 103 WCTs available in the database of Indiana University obtained from patients with proven electrophysiological (EP) diagnosis referred to EP study either because of spontaneous WCT or because of other clinical reasons and WCT was induced during the EP study. Then, to test the established algorithm, 453 regular WCT (331 VTs, 105 SVTs, 17 PXTs) tracings recorded from 287 consecutive patients during EP study conducted from June 1998 to November 2004 at Indiana University with proven EP diagnosis were prospectively analysed by two of the authors blinded to the EP diagnosis and the patients' clinical data. An informed consent exemption was obtained from the Indiana University Institutional Review Board for analysis of a deidentified dataset. The observers were given complete 12-lead standard ECGs obtained during tachycardia for analysis. WCT was defined as a rhythm with a rate !100 b.p.m. with a QRS duration !120 ms. Only monomorphic WCTs were analysed using the following criteria: (i) presence of A-V dissociation; (ii) presence of an initial R wave in lead aVR; (iii) whether the morphology of the WCT correspond to BBB or fascicular block [the diagnostic criteria proposed by Willems et al. 19 for intraventricular conduction disturbances were used (see Table 1 )]; (iv) an index of slow conduction at the beginning and at the end of the QRS complex by estimation of initial (v i ) and terminal (v t ) ventricular activation velocity ratio (v i /v t ), obtained by measuring the voltage in millivolts on the ECG tracing the impulse travelled vertically during the initial 40 ms (v i ) and the terminal 40 ms (v t ) of the same bi-or multiphasic QRS complex. The A-V dissociation criterion is identical in both algorithms (first criterion of the new and third of the Brugada algorithms). The v i and v t were measured in an individual QRS complex in any lead having a bi-or multiphasic QRS complex, in which the onset and end of the QRS were clearly visible and the initial ventricular activation was the most rapid (fastest). When either the initial or terminal 40 ms of the QRS complex displayed both positive and negative deflections, the sum of their absolute values (disregarding polarity) were used as the values of v i and v t .", "qa": [["70_15317843_0_1", "What are the common causes of wide QRS complex tachycardia (WCT)?\n", "The common causes of wide QRS complex tachycardia (WCT) include ventricular tachycardia (VT), supraventricular tachycardia (SVT) conducted with fixed or functional bundle branch block (BBB) pattern, pre-excited tachycardias (PXT), and drug- and electrolyte-induced WCTs. However, VT and SVT conducted with fixed or functional BBB pattern are the most clinically relevant differentials in the diagnosis of WCTs."], ["70_15317843_0_2", "How can SVT be differentiated from VT in the diagnosis of wide QRS complex tachycardia (WCT)?\n", "The ECG remains the cornerstone in distinguishing SVT from VT in the diagnosis of wide QRS complex tachycardia (WCT). Various ECG criteria have been reported for this purpose. One relatively simple, stepwise, decision tree-like algorithm proposed by Brugada et al. has shown superior sensitivity and specificity compared to other criteria. However, there is ongoing research to devise new algorithms that eliminate complicated morphological criteria and provide accurate differentiation between SVT and VT."], ["70_15317843_0_3", "What criteria are used to analyze monomorphic WCTs in the diagnosis of wide QRS complex tachycardia (WCT)?\n", "In the analysis of monomorphic WCTs, criteria such as the presence of A-V dissociation, presence of an initial R wave in lead aVR, morphology of the WCT corresponding to bundle branch block (BBB) or fascicular block, and an index of slow conduction at the beginning and end of the QRS complex are used. The measurement of initial (v i ) and terminal (v t ) ventricular activation velocity ratio (v i /v t ) is also performed to assess the conduction velocity. These criteria help in differentiating between SVT and VT in the diagnosis of WCTs."]]}, {"passage_id": "22_21075390_1", "passage": "Maria is one of several archetypic personas [19] that guided the design and development of the Ambient Assisted Living Lab between the participatory user studies. In this article, Maria will guide the reader through the novel components of her technology augmented living room. She is 74 years old, living alone, and as a result of a cardiac infarction which she suffered from a few years ago, she must regularly check some of her bodily functions (i.e., blood pressure, weight) and consult her doctor at certain time intervals. There are additionally some agerelated mild physical impairments, but she is generally in quite good health condition and interested in maintaining her independence in 'the own four walls'.\n\n Two exemplary studies will be subsequently reported to show meaningful health applications for persons in similar situation and with comparable ailments as Maria. In the first study, a health assistive application that is embedded into the living environment and allows to monitor relevant vital parameters is evaluated and the intention to use the health-supporting ambient technology after an interaction with the system is the subject of interest. The second study reports an experimental setup with a more hedonic context: Serious games in the technology augmented habitat. Here, apart from the rendered performance and factors influencing the willingness to play the game, factors influencing the intention to use the ambient technology in the fun context will be presented.\n\n In the first study, it was examined if potential users after a real interaction with the healthsupporting application would be willing to use such assistive system at home in the future. For this purpose, an experimental study with middle-aged and older individuals was performed in the Future Care Lab \u00a9 . The intention was to study persons with chronic heart conditions who have to daily monitor some of their health parameters, and to compare their opinions to individuals without any health ailments.\n\n Getting back to the example of Maria, the main question was if she would intend to use applications which would simplify the measurement of her vital parameters as well as ease the storage of her sensitive health data and the communication with the responsible physician in case of deterioration of the relevant values. In the following, the experimental design and procedure are described.\n\n \n\n As the aim was to get an impression of the real use of the assistive system, this study was designed to examine how persons with chronic heart conditions can effectively monitor their relevant vital functions by means of unobtrusively integrated specific medical devices in a domestic environment.\n\n For this purpose, the participants were asked to perform in the Future Care Lab two for the heart patients' exemplary measurements. The first was the measure of blood pressure (via a standard sphygmomanometer, comprising an inflatable cuff to restrict blood flow and a manometer to measure the pressure), and the second was a weight measurement (via a digital scale integrated in the floor) as both according to experts are reliable parameters for (negative) changes in cardiovascular processes in the human body. Participants were requested to use a health-app of the system (see Figure 2 ) which allowed to initiate the particular measurement and afterwards to appropriately save the data in the system, and to compare the current result with the previous results (imaginary but strongly related to the real one) in a measurement overview. Between the particular trials and after the interaction with the health related application of the system, individuals were asked to assess if they would use such sophisticated technology equipment at home, provided that the framework conditions are acceptable (i.e., transparent financing, technical maintenance, telemedical servicing). In a semi-structured interview as well by the method of a quantitative questionnaire participants answered to questions like e.g., \"Can you imagine to use at your home an eHealth system like this in the future?\"; \"I think, I would like to frequently use such technology system in the future\". The statements in the questionnaire had to be rated on a five-point scale that ranged from \"strongly disagree\" (= 1) to \"strongly agree\" (= 5). In addition, opinions about the system's usability assessed by the System Usability Scale [20] and general perceptions with regard to reliability of the system, data security and personal privacy were collected (for details see [3] ).\n\n The experimental testing was carried out in a period of about two weeks. The sessions were held individually and in German, which was the native language of all participants. Before the experiment started, each participant was interviewed, whether she or he had special needs, any objections or restrictions with respect to the planned study. The experimental trials took on average 20 -30 minutes.\n\n In the first step, the examined person was introduced to the concepts of Ambient Assisted Living and telemedicine to give her an idea of the broad possibilities connected to eHealth technology in domestic environment: monitoring of vital parameters in comfortable way at home and the remembering function to do so, efficient digital transmission of the sensible health data, facilitated the patient-physician communication and exchange with other patients and/or support groups on the Internet.", "qa": [["22_21075390_1_1", "How does the use of ambient technology in a living environment benefit individuals like Maria who have chronic health conditions?", "The use of ambient technology in a living environment can benefit individuals like Maria who have chronic health conditions by allowing them to effectively monitor their vital functions in a comfortable and convenient way at home. It can simplify the measurement of vital parameters, such as blood pressure and weight, and ease the storage of sensitive health data. Additionally, it can facilitate communication with healthcare providers in case of deterioration of relevant values."], ["22_21075390_1_2", "What factors were considered in assessing the participants' willingness to use the health-supporting ambient technology at home?", "In assessing the participants' willingness to use the health-supporting ambient technology at home, factors such as transparent financing, technical maintenance, and telemedical servicing were considered. The participants were asked to rate their agreement with statements about using the technology system in the future on a five-point scale. Opinions about the system's usability, reliability, data security, and personal privacy were also collected."], ["22_21075390_1_3", "How were the participants introduced to the concepts of Ambient Assisted Living and telemedicine in the experimental testing?", "In the experimental testing, the participants were introduced to the concepts of Ambient Assisted Living and telemedicine to give them an idea of the broad possibilities connected to eHealth technology in a domestic environment. They were informed about the monitoring of vital parameters at home, the remembering function to do so, the efficient digital transmission of health data, and the facilitated patient-physician communication. They were also made aware of the potential for exchange with other patients and support groups on the Internet."]]}, {"passage_id": "23_86811914_4", "passage": "where \u03a6 R \u03b5 R \u00f0\u00de d\u03b5 R is the fluence of radiation R with energy between \u03b5 R and \u03b5 R \u00fe d\u03b5 R , k a \u03b5 R \u00f0\u00de is the dose coefficient of air kerma of radiation R with energy \u03b5 R , and h * 10; \u03b5 R \u00f0\u00de is the dose coefficient of ambient dose equivalent of radiation R with energy \u03b5 R .\n\n For irradiation geometry G, one has\n\n where k a \u03b5 R \u00f0\u00de is the dose coefficient of air kerma of radiation R with energy \u03b5 R , h P 10; \u03b5 R \u00f0\u00de G is the dose coefficient of personal dose equivalent of radiation R with energy \u03b5 R and irradiation geometry G, Ad T \u03b5 R \u00f0\u00de G is the dose coefficient of RBEweighted dose in organ T of radiation R with energy \u03b5 R and irradiation geometry G, h T \u03b5 R \u00f0\u00de G is the dose coefficient of equivalent dose in organ T of radiation R with energy \u03b5 R and irradiation geometry G, and e \u03b5 R \u00f0\u00de G is the dose coefficient of effective dose of radiation R with energy \u03b5 R and irradiation geometry G.\n\n For photon radiation, values of Ad T \u03b5 R \u00f0\u00de G and h T \u03b5 R \u00f0\u00de G are numerically equal when the same organ or tissue and irradiation geometry are considered.\n\n The internet resource [25] provides tools for evaluation of absorbed dose in different organs from point or volumetric radioactive sources inside or outside the human body.\n\n The publication [26] provides dose coefficients for exposure to bulk sources that are ground, water body and cloud containing radioactive material. The publication [27] presents a compendium of neutron spectra, which could be used for estimation of protection quantities in accordance with Eqs. (7)- (10) . The estimates show that for fission neutrons scattered from the concrete walls of the facility, soil, or from the air surrounding the facility (skyshine), the value of Ad T \u03b5 R \u00f0\u00de G is numerically equal to 1/5 of h T \u03b5 R \u00f0\u00de G when the same organ or tissue and irradiation geometry are considered. This linkage provide the possibility to use results of operational or routine monitoring of doses in workers for estimation of AD Red marrow in emergency exposure situation as required by GSR Part 7 and presented in Table 4 .\n\n As presented in [7] , dose coefficients mentioned above are proportional to the photon energy in range of (0.1-6) MeV. Therefore, for the same irradiation geometry\n\n where \u03b5 j is any photon energy from range of (0.1-6) MeV. For mentioned range of photon' energy, the exposure is proportional to the kerma free-in-air (air kerma) or exposure. Thus, in the same point of field of photon radiation, exposure or kerma in air for an exposure of 100 R is 0.876 Gy [28] . This linkage provides the possibility to use old devices such as exposure meters (R-meters) in environmental monitoring for estimation of air kerma and protection quantities as given in Eq. (11) .\n\n The protection quantities AD T ,H T and E received from exposure due to external sources can be also estimated from the operational quantities by using the following equations:\n\n E ffi H P 10 \u00f0\u00de :\n\n H Skin ffi H P 0:07 \u00f0\u00de :\n\n H Lense of eye ffi H P 0:07 \u00f0\u00de :\n\n For strongly penetrating radiation, the critical organ for controlling the development of the severe deterministic effects in individual is the red marrow [1, 4] . The ICRU did not recommend depth for controlling the dose in the red marrow. For practical reasons, monitoring of the red marrow through dosimeters calibrated for H P 10\n\n \u00f0\u00de could be acceptable. The RBE-weighted absorbed dose in the red marrow received from exposure due to external sources can be estimated from the operational quantities by using the following equation:\n\n \u00f0\u00de :\n\n For weakly penetrating radiation and in emergency exposure situation, the reference depth for controlling severe deterministic effects due to irradiation of the derma of the skin is 0.4 mm and for controlling the severe deterministic effects due to irradiation of shallow soft tissue is 5 mm [1, 4, 9, 10] . The ICRU did not recommend operational quantity for controlling the dose in the skin derma or shallow soft tissue in emergency exposure situation. For practical reasons, monitoring of the skin derma and shallow soft tissue through dosimeters calibrated for H P 0:07 \u00f0\u00de could be acceptable.", "qa": [["23_86811914_4_1", "What are the recommended depths for controlling severe deterministic effects in the skin and shallow soft tissue in emergency exposure situations?\n", "The recommended depth for controlling severe deterministic effects in the skin is 0.4 mm, while for shallow soft tissue it is 5 mm. These depths are suggested by the International Commission on Radiological Units and Measurements (ICRU) and are used for practical monitoring purposes in emergency exposure situations."], ["23_86811914_4_2", "How can the RBE-weighted absorbed dose in the red marrow be estimated from operational quantities?\n", "The RBE-weighted absorbed dose in the red marrow, which is the critical organ for controlling severe deterministic effects, can be estimated from operational quantities. Specifically, it can be estimated using the equation: RBE-weighted absorbed dose in red marrow = H P 10 * AD Red marrow, where H P 10 is the personal dose equivalent and AD Red marrow is the dose coefficient for the red marrow."], ["23_86811914_4_3", "What are the protection quantities that can be estimated from operational quantities for exposure due to external sources?\n", "The protection quantities that can be estimated from operational quantities for exposure due to external sources include E (effective dose), H T (equivalent dose in organ T), and AD T (RBE-weighted dose in organ T). These quantities can be estimated using specific equations provided by the International Commission on Radiological Units and Measurements (ICRU)."]]}, {"passage_id": "50_6371856_0", "passage": "H ypertension is present in 1% to 3% of children in the United States. [1] [2] [3] This prevalence has been rising over the past decades. Increasingly, cardiovascular sequelae of pediatric hypertension are manifesting, including left ventricular hypertrophy, increased carotid intima-media thickness, and cardiovascular disease in adulthood. [4] [5] [6] Epidemiological studies have examined the national economic burden of hypertension in adults. 7, 8 In 1998, the healthcare cost in hypertensive adults was $46 billion in inpatients and at least $28 billion in outpatients. 8 Of the total expenditures attributed to hypertension in adults, hospitalizations accounted for the largest proportion (42%) of the total cost, followed by physician services, medications, nursing home care, and home care services. 8 Little is known about the economic burden of pediatric hypertension. In a selected population of obesity-related pediatric hypertension, 1 study examined the total Medicaid healthcare cost including outpatient and inpatient services in South Carolina. 9 However, no previous publications have addressed the inpatient healthcare charges for children with hypertension inclusive of all payer types.\n\n We elected to investigate the inpatient healthcare utilization associated with pediatric hypertension using nationally representative inpatient data. 10 Our primary objective was to evaluate the frequency of hypertension discharges and the economic burden of inpatient care for children with hypertension. Our secondary objective was to identify demographic and socioeconomic factors associated with hospitalization charges. Our third objective was to examine the relative contribution of end-stage renal disease (ESRD) to these charges.\n\n Data Source pating states. Data from the years 1997, 2000, 2003, and 2006 were drawn from 22, 27, 36 , and 38 reporting states, respectively. Included in each discharge record were International Classification of Diseases, 9th Revision, Clinical Modification (ICD-9) diagnosis and procedure codes, patient and hospital demographics, length of stay (LOS), and HCUP-generated weighting for hospital charges based on the American Hospital Association universe of hospitals as the standard. 10\n\n The pediatric hypertension subcohort was generated by searching the 1997, 2000, 2003, and 2006 KID cohorts for all discharges with either a primary or secondary diagnosis of hypertension. Hypertension was defined as those with ICD-9 codes 401.xx to 405.xx and 437.2 (Table 1) . ESRD was defined as hospitalizations having an ICD-9 code for ESRD or renal transplant. Demographic and hospitalization data extracted included patient age, race, sex, insurance type (private, public, or other), median income based on patient zip code, hospital teaching status, hospital region (South, Midwest, Northeast, and West), charge per discharge, and LOS. We combined primary and secondary payers for the insurance category. Any patient with a private payer was grouped as private. Any patient with no private payer who had a public payer was grouped as public. All others were grouped in the \"other\" category. In addition, we investigated the most common ICD-9 codes listed as a primary or secondary diagnosis.\n\n Sum and standard deviation were computed for discharges and charges with a primary or secondary diagnosis for hypertension. Means and standard errors were also computed for charges. Frequencies and percentages for demographic variables including age group (2-9 years and 10 -18 years), race, sex, insurance status, median income by zip code, hospital teaching status, hospital region, and survey year were calculated. 2 tests were used to assess differences between groups. Means and standard errors were computed for LOS. To account for inflation in comparison of charges over time, we converted charges from 1997, 2000, and 2003 into 2006 dollars using the Consumer Price Index for All Urban Consumers. 11 All of the results are shown in 2006 dollars. Linear regression models were used, including an interaction term hypertension*time, to assess the trend of fraction of charges attributed to hypertension over time. Population-adjusted rates for number of discharges by cohort year and age group (ages 2-18, 2-9, and 10 -18 years) were computed with the numerator equal to the sum of discharges divided by the year-matched census population by age group. Population-adjusted standard error for number of discharges by year and age group were also computed with the numerator equal to the standard divided by the census population by age group. Linear regression models were used to assess trend of discharges by age group over time.\n\n Logistic regression was used to calculate adjusted odds ratios for hypertension-related discharges. Independent variables included in the model were age group, race, sex, insurance status, median income by zip code, hospital teaching status, hospital region, and survey year.", "qa": [["50_6371856_0_1", "What are some cardiovascular sequelae that can manifest in children with hypertension?\n", "Some cardiovascular sequelae that can manifest in children with hypertension include left ventricular hypertrophy, increased carotid intima-media thickness, and cardiovascular disease in adulthood."], ["50_6371856_0_2", "What is the economic burden of hypertension in adults compared to pediatric hypertension?\n", "In 1998, the healthcare cost in hypertensive adults was $46 billion in inpatients and at least $28 billion in outpatients. Hospitalizations accounted for the largest proportion (42%) of the total cost, followed by physician services, medications, nursing home care, and home care services. Little is known about the economic burden of pediatric hypertension."], ["50_6371856_0_3", "What factors are associated with hospitalization charges for children with hypertension?\n", "Demographic and socioeconomic factors associated with hospitalization charges for children with hypertension include patient age, race, sex, insurance type, median income based on patient zip code, hospital teaching status, hospital region, charge per discharge, and length of stay."]]}, {"passage_id": "50_202550458_5", "passage": "Unexcused absences, excessively late arrival times, and early departures from work are not acceptable practices within Kenya's formal employment sector and the partial-day absences occur despite the clear expectation that all staff should be present from 7:30 am or 8:00 am until 5 pm. This is the first qualitative investigation into healthcare providers' opinions on factors contributing to high rates of absenteeism within Kenya. These findings contextualize previous quantitative studies which report that absenteeism occurs frequently in health facilities and is often characterized by late arrivals or early departures [8, 19] . We found that providers attribute absenteeism to issues primarily at the institutional level and describe weak accountability systems within health facilities. Limited supervision from higher level staff paired with a lack of reliable feedback systems from patients mean that providers can be absent without repercussions. Research from Machakos, Kenya corroborates these results. Muthama et al. found that despite the high levels of provider absenteeism, there were few accounts of healthcare workers being sanctioned or fired for their excessive absences [8] . Studies in low and high income countries indicate that lack of supervision and organizational permissiveness contribute to staff absenteeism [7, 14] .\n\n Providers reported that healthcare workers are sometimes absent because they hold positions at other health facilities. The practice of dual-job holding was described as a method through which providers cope with low wages. Dual-job holding is widespread in low and middle income countries. Providers often use salaries from working in the private sector to supplement their low incomes from working at government facilities [21] . Dual-job holding can have negative impacts on public sector facilities. Providers who engage in this practice may inappropriately use public sector resources (e.g. facilities, equipment, drugs) in their private practice. They might also spend less time in the positions where they are paid least thus extending patient wait times or diverting public-sector patients into private clinics [22] .\n\n Participants disagreed as to where they believed absenteeism was most likely to occur. While most reported that public and rural facilities are more vulnerable to absenteeism, others provided counter narratives from their own experiences. Literature suggests that absenteeism is more likely to occur in public-sector clinics [9] . Some theorize that this pattern occurs because public-sector employees are guaranteed to be paid regardless of their performance [23] . In our study, one provider alluded to this saying,\"\u2026 at the end of it all, you still get your salary\u2026.\" However, both public and private sector providers reported the behavior occurring in their facilities, and a few public-sector staff insisted that there were sanctions for absent providers in their facilities. Further, while participants insisted that absenteeism is more likely to occur in rural as compared to urban facilities, this is the opposite of what was previously found in Kenya [8] . The variation across participants may reflect heterogeneity in how individual facilities are managed. It is also possible that other influential factors may be at play including facility size, staffing, or effectiveness of clinic leadership.\n\n Together, these findings offer a road map for potential interventions to reduce absenteeism. First, increasing frequency and type of provider supervision is a priority. More frequent and unannounced visits by higher level management (i.e. Ministry of Health) may increase attendance. Further, implementing daily monitoring systems can be impactful. A study in India found that giving teachers small incentives to track their attendance through photographs at two agreed upon times during the day led to a 50% decrease in teacher absenteeism [13] . Second, efforts should be made to open up channels for patients to provide feedback to providers. In Uganda, an intervention was conducted wherein communities were encouraged to become involved in the state of healthcare service delivery and to hold providers accountable for their performance. Results showed improvements in health service utilization and child health outcomes [17] . With respect to wages, while increasing provider salaries to reduce dual-job holding could have significant effects on providers' attendance and motivation, such a solution may not be entirely feasible in this context. However, numerous development agencies have encouraged greater use of performance-based financing (PBF). PBF is a means of tying incentives to the performance of service providers. Those providers or facilities that meet targets or achieve high quality service delivery may receive a financial payment, bonus, or other type of incentive. In theory, PBF could create a disincentive for providers to be absent, as high rates of absenteeism among providers would reduce the total number of patients seen and lower the amount of funding available to the provider or the facility. Additional research is needed to better understand the potential impact on absenteeism of a performance pay intervention. Finally, the provision of non-monetary incentives has shown some promising effects on improving provider job performance in low-resource settings, and could be utilized to improve attendance [24] .\n\n The present study had several limitations. Providers were recruited from two large urban centers in Kenya, thus findings may not be transferable to rural locations. The study sample was also primarily composed of nurses and lower level health staff. Previous studies indicate that absenteeism is more likely to occur among higher level healthcare staff [8, 12] . Our findings may underestimate the scope of absenteeism especially as it pertains to provider cadre. Additionally, recruitment by referral can sometimes result in similar viewpoints across participants; however, the diversity of perspectives within our sample regarding the prevalence of absenteeism suggests the recruitment method did not necessarily restrict the sample to those with similar viewpoints. It is also possible that providers were reluctant to discuss negative behaviors out of fear of presenting themselves or their colleagues in a negative light or due to concerns that such reports could be misconstrued as personal admission of being absent. This could result in further underestimation of the scope of absenteeism. Finally, the qualitative study design -which utilized purposeful sampling techniques in order to select information-rich cases -limits statistical generalizability. However the primary findings that absenteeism in Kenya impacts healthcare access and is underpinned by institutionallevel issues such as infrequent supervision and low wages resonates with a larger body of literature on other negative provider behaviors such as informal payments and disrespectful treatment.\n\n Provider absenteeism puts considerable strain on patients, clinic resources, and other staff in already resource-limited settings. We found that provider absence occurs in a variety of health facilities in Kenya, and is linked to institutional-level issues. More research is needed to assess the prevalence of absenteeism on a national or subnational level and more formative research is needed to develop and understand the feasibility and sustainability of promising interventions.", "qa": [["50_202550458_5_1", "What are some potential interventions to reduce absenteeism among healthcare providers in Kenya?\n", "Potential interventions to reduce absenteeism among healthcare providers in Kenya include increasing frequency and type of provider supervision, implementing daily monitoring systems, opening up channels for patients to provide feedback to providers, exploring the use of performance-based financing (PBF), and providing non-monetary incentives to improve attendance. These interventions aim to improve accountability, motivation, and job performance among healthcare providers, ultimately reducing absenteeism and improving healthcare service delivery."], ["50_202550458_5_2", "How does dual-job holding impact public sector healthcare facilities in low and middle income countries?\n", "Dual-job holding, which is widespread in low and middle income countries, can have negative impacts on public sector healthcare facilities. Healthcare providers who engage in dual-job holding often use public sector resources, such as facilities, equipment, and drugs, in their private practice. This can lead to inappropriate use of resources and potentially compromise the quality of care provided in public sector facilities. Additionally, providers who hold positions in both the public and private sectors may spend less time in the positions where they are paid least, which can result in extended patient wait times or the diversion of public-sector patients into private clinics."], ["50_202550458_5_3", "What are some factors contributing to high rates of absenteeism among healthcare providers in Kenya?\n", "Factors contributing to high rates of absenteeism among healthcare providers in Kenya include weak accountability systems within health facilities, limited supervision from higher level staff, lack of reliable feedback systems from patients, and the practice of dual-job holding as a means to cope with low wages. Providers reported that absenteeism is primarily attributed to issues at the institutional level, such as the lack of consequences for excessive absences and the permissiveness of the organizational environment. These factors contribute to a culture of absenteeism among healthcare providers in Kenya."]]}, {"passage_id": "22_17886803_5", "passage": "Hence, the clinical benefit for patients, especially in the palliative setting, where preservation of quality of life (QoL) and evaluation of patient reported outcome (PRO) are crucial, should be based on dedicated assessments and described.\n\n The new RECIST (Response Evaluation Criteria in Solid Tumors) version 1.1 criteria, with some adaptations, have proven a suitable tool for response assessment of superficial tumors 21, 72 , whereas for the setting of treatment of deep-seated tumors (i.e., electrochemotherapy application on liver metastases) the modified RECIST criteria represent the most appropriate and standardized method for the evaluation of tumor response. 73 In general, for standard electrochemotherapy on superficial tumors, the RECIST 1.1 criteria, which are based on one-dimensional measurements, seem even more practical and offer highly concordant response assessment compared with the bidimensional WHO criteria. 74 So far, most of the published papers do not report on any serious treatment related adverse event after electrochemotherapy. Nevertheless, the process surrounding the determination, recording and reporting of adverse events remains moderately challenging especially for the clinician who may not be involved in drug or device-related research. Nevertheless, it is important to understand the basic definitions of adverse events reporting in order to ensure that the proper information is collected in clinical protocols. Moreover, a comprehensive patient observation and a detailed report of all types and grades of toxicities are essential for providing a comprehensive report of treatment outcome, not only in the early, but also in the long-term followup. In this way, only large cohorts of patients will enable in-deep view of long-term toxicity and more detailed analyses of treatment-related adverse events according to different patients subgroup, as demonstrated by a recently published report on electrochemotherapy-related pain. 43 For this purpose, Common Terminology Criteria for Adverse Events (CTCAE v4.0) is widely accepted throughout the oncology community as the standard classification and severity grading scale for adverse events. Unfortunately, most of the studies conducted so far do not report consistently on this crucial aspect. \n\n A clear summary of the trial endpoints is essential. In fact, the field is moving beyond simply reporting on tumor control, as treatment now includes, in some instances, also primary tumors. Here it is important to report and discuss other parameters, such as time to local/systemic progression and, if possible, also the patient survival time and QoL as well. Such data will increase the evidence level of electrochemotherapy effectiveness, and consolidate a role for electrochemotherapy outside the palliative setting and into a confirmed primary treatment modality.\n\n It has been clearly demonstrated that tumor size is the most reliable predictive factor for response in patients who underwent electrochemotherapy. 21, 22, 69 In future, detailed reports including data on previous local therapies (e.g., radiation) as well as on local (within electrochemotherapy field) tissue status (e.g., presence of lymphedema or fibrosis) and concomitant/adjuvant oncologic treatments would allow for the identification of other reliable predictive indicators for response.\n\n \u2022 Summary of trial endpoints \u2022 Additional patient outcome parameters (e.g., QoL, PRO) \u2022 Predictive factors \u2022 Results interpretation \u2022 Future research directions\n\n Electrochemotherapy represents an effective treatment option for an increasing number of cancer patients with superficial tumors. Nevertheless, to further improve its evidence basis, it will be crucial to raise the quality of future reports.\n\n In this study, we have highlighted some relevant aspects of clinical data reporting, with the aim of improving the quality of future studies in the field of electrochemotherapy. Although a large amount of data are published so far, clinical research needs to adopt detailed and accurate reporting as well as moving from small, non-comparative series to well-designed, possibly randomized, clinical trials. Despite the encouraging results indicated, the vast majority of included reports are case series from single institutions. Although there was a wide consensus to use previously published SOP for the treatment protocol, these studies often present a variety of designs and reporting methods, thus limiting the understanding of patient selection, treatment effect, toxicity and overall patient outcome. Of note, published studies often lack sufficient procedural as well as patient data. These shortcomings represent a major hurdle to performing systematic reviews or meta-analysis, which may provide a more robust evaluation of treatment effectiveness and, ultimately, encourage wider acceptance of electrochemotherapy in the clinical practice.\n\n Our study has some limitations. We identified a set of manuscript quality criteria from available literature and we have expanded this list by including additional, procedure-specific criteria that were discussed and agreed among the authors. The list of 47 quality criteria that were used for reviewing published reports represents an arbitrary selection of criteria performed by a relatively small number of authors. There is potential for selection bias in the inclusion of papers for analysis, as the initial screen was based on broad, non-selective inclusion criteria. However, we feel that these were widely inclusive and fitting in order to develop the proposed recommendations. Nevertheless, we believe that our suggestions largely cover the most crucial aspects, which are required to improve the quality of clinical practice and future research: trial design and conduction, definition of study endpoints, patient selection, treatment delivery, patient management and follow-up, standardization of outcome assessment. Our recommendations are open to a broader discussion with the community users of electrochemotherapy and, possibly, to further improvements in line with other interventional oncology procedures. 75, 76 Electrochemotherapy requires standardization of terminology and reporting criteria to facilitate effective communication among researchers and appropriate comparison between different treatment technologies. As such, investigators involved in this field should be familiar with these recommendations and use them for future study design and conduction, treatment application as well as data reporting. We envision that the adoption of these recommendations will further improve the quality of future studies and allow more meaningful comparisons of outcome data of patients treated with electrochemotherapy (Supplementary file).", "qa": [["22_17886803_5_1", "What are the key factors that should be considered when reporting clinical data in electrochemotherapy studies?\n", "When reporting clinical data in electrochemotherapy studies, several key factors should be considered. These include detailed and accurate reporting, adoption of standardized outcome assessment criteria, improving procedural and patient data collection, performing well-designed, possibly randomized, clinical trials, and enhancing the quality of future reports. Moreover, it is essential to include trial endpoints, patient outcome parameters (such as quality of life and patient-reported outcomes), predictive factors for response, and interpretation of results. By addressing these factors, the evidence basis for electrochemotherapy can be improved, allowing for a more comprehensive understanding of its effectiveness and wider acceptance in clinical practice."], ["22_17886803_5_2", "What are the limitations of the current published studies on electrochemotherapy?\n", "The current published studies on electrochemotherapy have several limitations. The majority of included reports are case series from single institutions, limiting the understanding of patient selection, treatment effect, toxicity, and overall patient outcome. These studies often lack sufficient procedural and patient data, which hinders the ability to perform systematic reviews or meta-analyses for a more robust evaluation of treatment effectiveness. Additionally, there is a need for standardization of terminology and reporting criteria to facilitate effective communication among researchers and enable appropriate comparisons between different treatment technologies. To overcome these limitations, it is crucial to improve the quality of future studies by adopting detailed and accurate reporting, conducting well-designed clinical trials, and adhering to recommended guidelines for study design, endpoint definition, patient selection, treatment delivery, and outcome assessment."], ["22_17886803_5_3", "How can the quality of future studies on electrochemotherapy be improved?\n", "The quality of future studies on electrochemotherapy can be improved by considering several recommendations. These include trial design and conduction, definition of study endpoints, patient selection, treatment delivery, patient management, and follow-up, as well as standardization of outcome assessment. The adoption of standardized terminology and reporting criteria is also necessary for effective communication among researchers and comparison between different treatment technologies. By incorporating these recommendations into study design, as well as treatment application and data reporting, the overall quality of future studies on electrochemotherapy can be enhanced."]]}, {"passage_id": "1_3245248_1", "passage": "The BiPAP was set in the spontaneous/ timed mode, with a backup respiratory rate of 15 breaths per minute. The initial IPAP was set at 14 cm H 2 O. IPAP was increased by 2-3 cm H 2 O over 4 hours as tolerated but did not exceed 25 cm H 2 O. EPAP was begun at 4 cm H 2 O and was increased up to 8 cm H 2 O, depending on the requirement of the patient. Oxygen inhalation was adjusted to maintain SpO 2 between 89% and 92%. Arterial blood gas (ABG) samples were obtained from each patient before and after 2 hours of initiation of BiPAP. Subsequently, samples were obtained every 24 hours or as clinically indicated.\n\n The clinical course of the patient during the BiPAP therapy was monitored using GCS score, blood pressure, heart rate, respiratory rate, ABG levels, and sequential organ failure assessment (SOFA) score. Therapy was considered to have failed if at least one of the following occurred: (1) worsening of consciousness within 2 hours of initiating BiPAP; (2) deterioration of ABG, defined as no improvement or deterioration in pH, PaCO 2 , and partial pressure arterial oxygen (PaO 2 )/fraction of inspired oxygen (FiO 2 ) ratio from baseline measurement after 2 and 24 hours of BiPAP administration; (3) respiratory or cardiac arrest; and (4) development of hemodynamic instability. Treatment was considered successful when the patient gained full consciousness and was discharged alive from the hospital.\n\n Short-acting benzodiazepines (midazolam) were advised as and when required in some patients who were restless and agitated. Patients were extubated once their consciousness increased enough to follow complex verbal command irrespective of PaCo 2 , and were thereafter applied with BiPAP via facemask.\n\n Comparison of the monitored parameters between patients who improved and those who failed in the BiPAP therapy was done using Mann-Whitney U test for quantitative variables and submit your manuscript | www.dovepress.com\n\n Fisher's exact test for qualitative variables. Progressive change with time in both the categories of patients was analyzed using the Wilcoxon signed rank test. Kaplan-Meier survival analysis was done using log-rank (Mantel-Cox) test. All analyses were two-tailed, and P , 0.05 was considered significant. Statistical analysis was performed using SPSS Statistics (IBM Corporation, Somers, NY) software, version 16.0.\n\n During the study period, a total of 22 patients fulfilled the inclusion criteria for the study, attendants of four patients declined endotracheal intubation and left the hospital against medical advice. One patient's hypoxic status could not be corrected within 30 minutes with BiPAP administration and had to be shifted to bag valve mask (Ambu bag) resuscitation. Of the 22 patients recruited in the study, two patients were shifted to ICU during the course of BiPAP therapy owing to the subsequent availability of funds, and hence they were excluded from the final analysis. Out of the remaining 20 patients, 17 responded successfully to the treatment and three failed to respond and died.\n\n The baseline characteristics and physiological variables of these patients were comparable in almost all respects, as shown in Table 1 . However, the SOFA score of the successfully treated patients was significantly better than in the nonresponders (P = 0.004).\n\n Analyzing the progressive course of the treated patients, a significant improvement in all the monitored parameters was observed among the favorable responders by the end of the second hour of treatment. However, the systolic blood pressure remained unchanged at the end of 2 hours. Among the nonresponders, no change was observed in any of the monitored parameters at the end of 2 hours. The positive change in all the parameters observed among the responders at the end of 2 hours was maintained throughout the duration of treatment (Table 2) .\n\n Among the patients who responded to the treatment, only one patient developed lobar pneumonia of the right lower lobe, which could be attributed to aspiration pneumonia. Comparing the financial implications of BiPAP therapy and mechanical ventilation, the average charges for the former was calculated to be INR 2800 (US$62.10) per patient. This was based on a daily charge of INR 800 (US$17.74) levied by the hospital for administering BiPAP therapy.", "qa": [["1_3245248_1_1", "What are the key parameters monitored during BiPAP therapy and how do they contribute to assessing the success or failure of the treatment?", "The key parameters monitored during BiPAP therapy include GCS score, blood pressure, heart rate, respiratory rate, ABG levels, and SOFA score. These parameters help evaluate the patient's consciousness, cardiovascular stability, respiratory function, and overall organ function. The success or failure of the treatment is determined based on changes in these parameters, such as improvement or deterioration in ABG levels, worsening of consciousness, respiratory or cardiac arrest, and development of hemodynamic instability."], ["1_3245248_1_2", "How is the BiPAP therapy adjusted and titrated for individual patients, and what are the target ranges for oxygen saturation (SpO2) and arterial blood gas (ABG) levels?", "The BiPAP therapy is adjusted and titrated based on the patient's tolerance and response. The initial IPAP is set at 14 cm H2O and can be increased by 2-3 cm H2O over 4 hours, up to a maximum of 25 cm H2O. The EPAP is started at 4 cm H2O and can be increased up to 8 cm H2O. Oxygen inhalation is adjusted to maintain SpO2 between 89% and 92%. ABG samples are obtained before and after 2 hours of BiPAP initiation, and subsequently every 24 hours or as clinically indicated. The therapy is considered successful if the patient gains full consciousness and is discharged alive from the hospital."], ["1_3245248_1_3", "What are the factors that differentiate the patients who responded successfully to BiPAP therapy from those who failed to respond?", "The SOFA score of the successfully treated patients was significantly better than in the nonresponders. This suggests that the overall organ function and severity of illness play a role in the response to BiPAP therapy. Additionally, the monitored parameters showed a significant improvement among the responders by the end of the second hour of treatment, while no change was observed among the nonresponders. This indicates that the early response to BiPAP therapy may be predictive of treatment success."]]}, {"passage_id": "21_27945247_0", "passage": "Autophagy is a vital biological lysosome-mediated process that maintains cellular homeostasis by degrading abnormal proteins and organelles. Three major types of autophagy have been recognized, including macroautophagy, chaperone-mediated autophagy (CMA), and microautophagy [1, 2] . Macroautophagy (often just called autophagy) is the most common form of autophagy, and during this process, the cell forms a double-membrane sequestering compartment termed the phagophore, which matures into the autophagosome. Following delivery to the vacuole or lysosome, the cargo is degraded and the resulting macromolecules are released back into the cytosol for reuse [3, 4] . CMA is the most selective type of autophagy, and involves the translocation of cytosolic proteins containing a specific degradation signal (the KFERQ sequence motif) to the lysosomal lumen. This motif, found in around 30% of cytosolic proteins, is usually buried in the fully folded protein but can be exposed upon partial unfolding. It is recognized by HSPA8/HSC70 chaperone which, together with other co-chaperones, targets the protein to the CMA adaptor (LAMP2A) localized Table 1 . Examples of autoimmune neurological diseases with autophagy abnormalities, and methods and model systems used for investigating these conditions.\n\n Autophagy Abnormalities Methods\n\n Ref.\n\n Increased Beclin-1 and MAP1LC3B expression levels;\n\n WB; TEM EAN rat (sciatic nerves) [22] Increased MAP1LC3BII/I ratio; Decreased expression of SQSTM1;\n\n \n\n Increased Beclin-1 and MAP1LC3B-II expression levels; TEM; WB EAN rat (sciatic nerves) [ \n\n Decreased expression of SQSTM1\n\n Increased mRNA and protein level of ATG5; qPCR; WB EAE mice (blood) and patient (blood and brain) [23] Decreased expression of ATG16L2 and ATG9A genes; qPCR Patient (blood) [24] Increased expression of ULK1 gene Neuromyelitis optica (NMO) Increased ATG5 variants Mass array system Patient (blood) [25] Abbreviations: ATG, autophagy related-gene; EAE, experimental autoimmune encephalomyelitis; EAN, experimental autoimmune neuritis; MAP1LC3B, microtubule-associated protein light chain 3; PCR, polymerase chain reaction; qPCR, quantitative PCR; RNA, ribonucleic acid; SQSTM1, sequestosome-1; TEM, transmission electron microscopy; ULK1, Unc-51 like-autophagy activating kinase 1; WB, western blotting.\n\n However, it has not been well addressed whether autophagy is affected in inflammatory/autoimmune peripheral neuropathies such as Guillain-Barr\u00e9 syndrome (GBS) and chronic inflammatory demyelinating polyneuropathy (CIDP). GBS and CIDP are, respectively, the human acute and chronic inflammatory demyelinating disorders of the peripheral nervous system (PNS), which are clinically characterized by an involvement of proximal as well as distal limb structures (weakness, paraesthesia). In these pathologies, the disease is presumably caused by damage to the myelin sheath (i.e., a wrap of myelin that surrounds axons) of the peripheral nerves [20, 21] . The most widely used animal model of GBS is the experimental autoimmune neuritis (EAN) and recently, we developed and characterized a new representative rat model for human CIDP, the chronic-EAN [26, 27] . Because the pathophysiology of GBS, and particularly of CIDP, remains poorly understood, these models represent important tools to progress in the knowledge of the pathogenesis of these diseases and for translational drug studies.\n\n The rat sciatic nerve is commonly studied by researchers working on peripheral neuropathies not only for its anatomical features, but also for it length and consequently, the amount of tissue available for immunohistochemical, western blotting, and PCR experiments, for example. Furthermore, it seems that it represents one of the first nerves to be committed in EAN and in chronic-EAN, adding value to this model of choice.\n\n In rats, the sciatic nerve originates from the fusion of spinal segments L4-L6 but principally from L4 and L5 spinal nerves [28] [29] [30] to form the nerve on the lesser pelvis ( Figure 1A ). Only one study demonstrated that the components of sciatic nerve from Sprague Dawley rats vary from L3 to L6 [31] .", "qa": [["21_27945247_0_1", "What are the different types of autophagy and how do they function?\n", "Autophagy is a cellular process that helps maintain cellular homeostasis by degrading abnormal proteins and organelles. There are three major types of autophagy: macroautophagy, chaperone-mediated autophagy (CMA), and microautophagy. Macroautophagy is the most common form and involves the formation of a double-membrane compartment called the phagophore, which matures into the autophagosome. The cargo within the autophagosome is then delivered to the vacuole or lysosome for degradation. CMA is a selective type of autophagy that involves the translocation of specific cytosolic proteins to the lysosomal lumen. These proteins contain a degradation signal called the KFERQ sequence motif, which is recognized by chaperones and targeted to the lysosome. Microautophagy, on the other hand, involves the direct engulfment of cytoplasmic components by the lysosome. Each type of autophagy plays a role in maintaining cellular health and homeostasis."], ["21_27945247_0_2", "How are autophagy abnormalities investigated in autoimmune neurological diseases?\n", "Autophagy abnormalities in autoimmune neurological diseases can be investigated using various methods and model systems. Some of the methods commonly used include western blotting (WB), transmission electron microscopy (TEM), quantitative polymerase chain reaction (qPCR), and ribonucleic acid (RNA) analysis. These techniques allow researchers to measure the expression levels of autophagy-related genes and proteins, as well as observe the ultrastructural changes in cells. Animal models, such as the experimental autoimmune neuritis (EAN) in rats, can also be used to study autophagy abnormalities in autoimmune neurological diseases. By analyzing the autophagy-related changes in these models, researchers can gain insights into the pathophysiology of these diseases and potentially develop new therapeutic approaches."], ["21_27945247_0_3", "How do Guillain-Barr\u00e9 syndrome (GBS) and chronic inflammatory demyelinating polyneuropathy (CIDP) relate to autophagy?\n", "Guillain-Barr\u00e9 syndrome (GBS) and chronic inflammatory demyelinating polyneuropathy (CIDP) are inflammatory/autoimmune peripheral neuropathies that affect the peripheral nervous system. In these conditions, the myelin sheath, which surrounds the axons of peripheral nerves, is damaged. While it has not been well studied, it is unclear whether autophagy is affected in GBS and CIDP. Animal models, such as the experimental autoimmune neuritis (EAN) and chronic-EAN in rats, have been developed to mimic these diseases and provide insights into their pathogenesis. By studying autophagy in these models, researchers can better understand the role of autophagy in GBS and CIDP and potentially identify new therapeutic targets for these conditions."]]}, {"passage_id": "59_145822524_5", "passage": "It should be noted that, because this analysis presents data only for the baseline HbA 1c ranges specified by the inclusion criteria in each study, no conclusions can be drawn regarding the effect of incretin-based therapy in patients with HbA 1c levels outside these ranges.\n\n The current post hoc analysis complements the primary analyses of the AWARD studies. Results indicate that patients treated with dulaglutide 1.5 and 0.75 mg experienced mean reductions in HbA 1c that were greater than those of patients treated with either exenatide twice daily or sitagliptin, and in patients treated with dulaglutide 1.5 mg, HbA 1c was reduced to the same extent as that seen in patients treated with liraglutide 1.8 mg, in all cases irrespective of the patient's baseline HbA 1c value. Since dulaglutide's ability to lower HbA 1c is durable and has been observed across patients with a broad range of HbA 1c levels, these results suggest that dulaglutide may be considered an appropriate option for a wide range of baseline HbA 1c levels, including those indicative of poor glycaemic control.\n\n Medical Writing Assistance. The authors would like to acknowledge Janet Douglas (Rx Communications, Mold, UK) for medical writing assistance with the preparation of this article, funded by Eli Lilly and Company.\n\n Authorship. All named authors meet the International Committee of Medical Journal Editors (ICMJE) criteria for authorship for this article, take responsibility for the integrity of the work as a whole, and have given their approval for this version to be published.\n\n Authorship Contributions. RG and LAV were involved with the conception of the work and interpretation of the data. IR, RB and GS were involved with the interpretation of the data for the work. CN was involved with the conception and design of the work, and the analysis and interpretation of the data.\n\n Disclosures. Irene Romera is a full-time employee and shareholder of Eli Lilly and Company. Claudia Nicolay is a full-time employee and shareholder of Eli Lilly and Company. Luis Alberto V\u00e1zquez was an employee of Eli Lilly and Company during the inception of this study. Raffaella Gentilella was an employee of Eli Lilly and Company during the inception of this study, and now serves as a consultant for Eli Lilly Italy. Raffaella Buzzetti has attended an advisory panel for Eli Lilly and Company, and for Sanofi; has been a board member for Abbott and Takeda; has attended a speakers' bureau for AstraZeneca, Eli Lilly and Company, Medtronic, Novo Nordisk, Sanofi and Takeda. Giorgio Sesti has nothing to disclose.\n\n Compliance with Ethics Guidelines. This article is based on the results of three previously conducted studies, all of which involved human participants. Each of these original studies was conducted in accordance with the Declaration of Helsinki guidelines on good clinical practice. In all cases the protocol was approved by local institutional review boards and all patients provided written informed consent before participation in the trial. The full list of institutional review boards that approved the three studies can be found in the Supplementary Material (Table S1 ).\n\n Data Availability. All data generated or analysed during this study are included in this published article/as supplementary information files.\n\n Open Access. This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 4.0 International License (http://creativecommons.org/licenses/ by-nc/4.0/), which permits any noncommercial use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.", "qa": [["59_145822524_5_1", "What are the potential benefits of dulaglutide in managing HbA1c levels in patients with a broad range of baseline HbA1c levels?", "The post hoc analysis of the AWARD studies suggests that dulaglutide may be an appropriate option for patients with a wide range of baseline HbA1c levels, including those indicative of poor glycemic control. Patients treated with dulaglutide experienced greater mean reductions in HbA1c compared to patients treated with exenatide or sitagliptin, regardless of their baseline HbA1c levels. This suggests that dulaglutide's ability to lower HbA1c is durable and effective across different patient populations."], ["59_145822524_5_2", "How does the post hoc analysis of the AWARD studies contribute to our understanding of the use of incretin-based therapy in patients with varying HbA1c levels?", "The post hoc analysis provides valuable insights into the effectiveness of incretin-based therapy, specifically dulaglutide, in patients with different baseline HbA1c levels. The results indicate that dulaglutide is associated with significant reductions in HbA1c, regardless of the patient's baseline HbA1c value. This suggests that dulaglutide may be a suitable treatment option for a wide range of patients, including those with poor glycemic control."], ["59_145822524_5_3", "What are the implications of the post hoc analysis findings for the management of patients with diabetes and varying HbA1c levels?", "The findings of the post hoc analysis suggest that dulaglutide may be a valuable treatment option for patients with diabetes, regardless of their baseline HbA1c levels. The ability of dulaglutide to effectively lower HbA1c levels across a broad range of patients indicates its potential for improving glycemic control in individuals with varying degrees of disease severity. These findings have important implications for the management of diabetes, as they suggest that dulaglutide can be considered as a treatment option for a wide range of patients, including those with poor glycemic control."]]}]