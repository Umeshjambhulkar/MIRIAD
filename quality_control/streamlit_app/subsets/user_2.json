[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "23_811416_0", "passage": "Clinical practice guidelines (CPGs) are designed to support decision-making processes in patient care and are classically defined as \"systematically developed statements to assist practitioners' and patients' decisions about appropriate healthcare for specific circumstances\" [1] . While there is some evidence that CPGs improve outcomes when they are appropriately implemented, [2, 3] there are numerous factors which influence their acceptability and use by healthcare providers [4] .\n\n Some of the major barriers to guideline adherence can be related to practitioner, patient, organisational or guideline factors, [5] [6] [7] although practitioners appear to be a key factor. Aspects such as knowledge, perceptions of and attitudes toward CPGs in general, are professional-related. Other factors that affect the success of guideline implementation are content or format related, like clarity and presentation of the recommendations or the existence of a quick reference guide or algorithm [8] . The grading system used to classify the quality of the evidence and the strength of recommendations is an important characteristic of guideline format. However, the growing number of different grading systems employed across different institutions [9] could possibly be a source of confusion, impeding the correct comprehension of recommendations and their application in clinical practice.\n\n The evidence on clinicians' knowledge, perceptions and attitudes toward CPGs is growing. The majority of published studies on this topic used quantitative design (surveys or record audits), investigating the association between barriers or facilitators and CPG use. Alternative approaches used by some investigators were qualitative designs, where concepts are collected in focus groups, interviews or through open-ended questions in questionnaires. Finally, some studies considered a mixed-method design including both qualitative and quantitative techniques.\n\n Survey results were systematically reviewed in two publications, [4, 10] concluding that most clinicians were supportive of CPGs, finding them to be useful, educational and likely to improve quality of care. Less frequent findings were that CPGs were impractical, unable to be used for individual patients, limited clinician autonomy, increased the likelihood of litigation or disciplinary action, and were used to cut costs [10] .\n\n A recent systematic review and meta-synthesis of qualitative studies of general practitioners' (GPs') attitudes to and experience with the use of CPGs [11] offers a conceptual framework for their interpretation. Six broad themes were identified in the analysis: questioning the guidelines; GPs' experience; preserving the doctorpatient relationship; professional responsibility; practical issues and guideline format. No systematic pattern in the distribution of these themes was found. However, comparative analysis and synthesis suggested that GPs' reasons for not following the CPGs differed according to whether the guidelines encouraged (prescriptive type) or discouraged (proscriptive type) particular interventions or behaviours [11] .\n\n Some authors suggest that clinicians find guideline contents too complex and confusing, and perceive difficulties in understanding the CPG development process. More specifically, there is very little research on clinicians' perceptions and understanding of the grading systems used to rate the evidence, quality, and strength of recommendations [12, 13] . In our context, a qualitative study about the GRADE system showed important difficulties in understanding it and an important level of disagreement among the participating clinicians, with and without previous experience in CPG development [14] . However, the participants had hardly any experience with the use of this grading system, which requires substantial methodological expertise and practice.\n\n Given this context there is a need for systematically reviewing the evidence on this topic and an assessment of the situation in our context. Additionally, the scarce information about the perceptions and understanding of the grading systems by healthcare professionals in the international literature provide the impetus for an investigation, both qualitative and quantitative, about this important aspect of clinical practice guidelines.\n\n \n\n The main goal of this study is to explore the perceptions and attitudes of Spanish practitioners (GPs and hospitalbased specialists, both with or without previous experience in guideline development) towards clinical practice guidelines and grading systems.\n\n The specific objectives are to:\n\n -Categorize, synthesize, and compare the perceptions of these different groups of healthcare professionals toward CPGs; -Identify and describe the adoption/non-adoption factors specific to each group; -Investigate whether different grading systems are better understood, and the influence of the wording of recommendations on understanding, acceptability and use of CPGs; -Investigate whether different formats of CPGs influence acceptability and use of CPGs; -Explore and compare the level of knowledge and understanding of different grading systems in these groups.\n\n The design of this two-phase project will include qualitative and quantitative research techniques. During Phase I, with a qualitative design, group discussions will be carried out with the participation of GPs and hospital-based specialists, to explore in depth their perceptions and attitudes towards CPG and grading systems. In a posterior quantitative stage, Phase II, we will complement this information by means of a survey.", "qa": [["23_811416_0_1", "What are some of the major barriers to adherence to clinical practice guidelines (CPGs) and how do they impact healthcare providers?\n", "Some of the major barriers to adherence to CPGs include factors related to practitioners, patients, organizations, and the guidelines themselves. Practitioners play a key role, and their knowledge, perceptions, and attitudes toward CPGs can influence adherence. Other factors that affect guideline implementation include the clarity and presentation of recommendations, the existence of quick reference guides or algorithms, and the grading system used to classify the quality of evidence and strength of recommendations. These barriers can impact healthcare providers by potentially impeding their understanding of recommendations and their application in clinical practice."], ["23_811416_0_2", "What are some of the perceptions and attitudes of clinicians toward CPGs, as revealed by survey results and qualitative studies?\n", "Survey results and qualitative studies have shown that most clinicians are supportive of CPGs, finding them useful, educational, and likely to improve the quality of care. However, there are also less frequent findings that CPGs are impractical, unable to be used for individual patients, limit clinician autonomy, increase the likelihood of litigation or disciplinary action, and are used to cut costs. Qualitative studies have identified six broad themes in clinicians' attitudes toward CPGs, including questioning the guidelines, preserving the doctor-patient relationship, professional responsibility, practical issues, and guideline format. The reasons for not following CPGs can differ depending on whether the guidelines encourage or discourage particular interventions or behaviors."], ["23_811416_0_3", "What are some of the challenges clinicians face in understanding and using grading systems used to rate the evidence, quality, and strength of recommendations in CPGs?\n", "Clinicians may find guideline contents too complex and confusing, leading to difficulties in understanding the CPG development process. There is limited research on clinicians' perceptions and understanding of grading systems, such as the GRADE system. A qualitative study on the GRADE system showed important difficulties in understanding it and a significant level of disagreement among participating clinicians, regardless of their previous experience in CPG development. This suggests that understanding and using grading systems require substantial methodological expertise and practice."]]}, {"passage_id": "80_1296061_3", "passage": "For instance, two platinum electrodes immersed in saline solution would yield the following reactions at the cathode and anode respectively:\n\n Since the total redox potential is \u03f32.0 V, no redox reactions occurs at the electrode surface, no transmission of ions occur across the solution, and no current is actually registered through the circuit until this external voltage threshold is reached. These inert electrodes are considered \"polarizable.\"\n\n For a less inert electrode such as silver-silver chloride (Ag/ AgCl) electrodes, the material within the electrode actively participates in the reactions for the transfer of charge from electrode to biologic tissue (and vice versa). For example, two Ag/AgCl electrodes immersed in saline would produce these following reactions at the cathode and anode respectively:\n\n In this instance, even a small voltage would generate an electrode reaction and a current will be registered coursing through the circuit. This property confers a level of immunity to the Ag/AgCl electrode from local polarizing effects and, for this reason, the Ag/AgCl electrode is considered \"nonpolarizable\" and the best electrode for biology and medicine for DC-carrying applications. The biocompatibility of silver, however, is not entirely clear.\n\n Under DC-potential settings where strict-zero current conditions are established, the platinum electrode functions well, as no current is being introduced to produce electrode polarization. Platinum may, in fact, be the preferred electrode for electrical potential measures because of its high level of biocompatibility. For obtaining electrical potential in tissue, one must also be careful to account for the combination of electrodes used for experimentation. Two different electrode materials can generate an electrical potential difference as high as a few hundred millivolts originating from differences in metal-ion equilibrium potentials. 17 In this case, one may mistakenly interpret the measurement as an intrinsic characteristic of biologic tissue. Two identical Ag/AgCl electrodes, however, often generate less than 1 mV in DC potential differences. 7 Identical electrodes with minimal metal/metal ion potentials are the preferred arrangements for DC-potential readings.\n\n A number of choices are available for a contact medium placed between electrode and skin. These choices include dry contact (no intervening medium), wet electrolyte (including paste, creams, and liquids), hydrogels (solid gels\n\n with natural or synthetic hydrocolloids), and insulating materials. Hydrogels are the most common type of contact medium found in medical applications and can be found in most electrocardiograph and electroencephalograph electrodes. The appropriate selection of contact media for electrodermal devices depends on the experimental conditions. Even now, despite the extensive studies performed in the various types of electrodes, no single medium is perfect for all experimental conditions and researchers still debate the merits of each medium type. 23 Nevertheless, several important factors should be considered in assessing the appropriateness of a medium. They include contact area between electrode and medium and between medium and tissue, polarization of the electrode-medium interface, and the moisturizing effects of the medium on the skin. 17 Because the amount of current passing from electrode to tissue is dependent on the cross-sectional area of passage, the contact area should be maintained as constant as possible. For dry electrodes, the irregularity of the skin surface and the associated variable contact area make this requirement difficult to achieve especially in the presence of physical movement. In addition, pressure can increase the effective contact area and thereby reduce the electrical impedance readings. This may explain why applying greater pressure leads certain acupuncture-point locator devices to mistakenly identify nonspecific areas as acupuncture points. Wet electrodes are also prone to contact-area variability when a lateral spread of electrolyte over the skin occurs. Generally, hydrogels are spared from this confounding effect due to their ability to maintain constant contact area with both electrodes and skin.\n\n Contact mediums should minimize the polarization effects seen at the electrode surfaces. This can be achieved through the appropriate selection of electrode and contact medium combinations. Silver/silver chloride electrodes and chloride-containing wet electrolytic solution, for instance, form a good pair for minimizing electrode polarization effects. Wet electrolytes have the advantage of providing the adequate ionic and molecular movement needed for the acceptance and donation of charges from the electrode surface. For dry and insulating electrodes, however, freely mobile ions and molecules do not occupy the space between the electrode and the skin, and ionic currents do not readily occur. Strong polarization effects develop at the surface. For this reason, dry and insulating electrodes are not ideal for low-frequency currents compared to wet mediums (although some studies may dispute this 23 ). At higher frequency stimuli, currents traverse through a different mechanism known as a displacement current, and it may confer dry or insulating electrodes with added advantages over wet electrodes.\n\n The contact medium may also directly influence the skin impedance itself.", "qa": [["80_1296061_3_1", "What are the advantages of using silver/silver chloride electrodes in biomedical applications compared to platinum electrodes?\n", "Silver/silver chloride electrodes are considered \"nonpolarizable\" and are the preferred electrodes for DC-carrying applications in biology and medicine. They actively participate in the reactions for the transfer of charge from electrode to biologic tissue, generating electrode reactions even with small voltages. This property confers a level of immunity to the electrode from local polarizing effects. In contrast, platinum electrodes are considered \"polarizable\" and require a higher external voltage threshold to register a current through the circuit. Silver/silver chloride electrodes also have a higher level of biocompatibility compared to platinum electrodes."], ["80_1296061_3_2", "What factors should be considered when selecting a contact medium for electrodermal devices?\n", "Several factors should be considered when selecting a contact medium for electrodermal devices. These factors include the contact area between the electrode and medium, the contact area between the medium and tissue, the polarization of the electrode-medium interface, and the moisturizing effects of the medium on the skin. The contact area should be maintained as constant as possible to ensure consistent electrical impedance readings. Pressure can increase the effective contact area, while irregularities in the skin surface can make maintaining constant contact area difficult. The contact medium should also minimize polarization effects seen at the electrode surfaces. Wet electrolytes, such as chloride-containing solutions, are advantageous in providing the necessary ionic and molecular movement for charge transfer. Dry and insulating electrodes, on the other hand, are not ideal for low-frequency currents due to strong polarization effects. However, at higher frequency stimuli, dry or insulating electrodes may have advantages over wet electrodes."], ["80_1296061_3_3", "What are the different types of contact mediums used in medical applications for electrodes?\n", "The different types of contact mediums used in medical applications for electrodes include dry contact (no intervening medium), wet electrolyte (including paste, creams, and liquids), hydrogels (solid gels with natural or synthetic hydrocolloids), and insulating materials. Hydrogels are the most common type of contact medium found in medical applications and are often used in electrocardiograph and electroencephalograph electrodes. The selection of the appropriate contact medium depends on the experimental conditions, and there is ongoing debate among researchers regarding the merits of each medium type."]]}, {"passage_id": "77_12084434_6", "passage": "1, 3, 14 With regard to hospitalizations due to influenza or pneumonia, PIV was significantly better than placebo in all meta-analyses, however the summary estimates varied, ranging from 48% 1 to 27%. 3 Besides the more selective inclusion criteria discussed above, both case-control and cohort studies were included by Vu et al., thus their results could not be compared with those from other reviews. Gross et al. used unadjusted estimates, mostly included elderly from nursing homes and also included one RCT. 46 In fact, when the Gross et al. results are compared with those of the stratified meta-analysis of cohort studies in nursing homes by Jefferson et al., using unadjusted estimates, the summary estimates are practically identical (respectively, 48% and 49%, with similar confidence limits). However, eight community cohort studies that were published after the Gross et al. meta-analysis provided adjusted rates of hospitalizations due to influenza and pneumonia, and showed a lower-and probably more reliable-overall effectiveness of vaccination: 27% (95% CI: 21-33%).\n\n Mortality was evaluated by three meta-analyses. 1,3,14 Gross et al. only considered all-cause mortality, while Jefferson et al. and Vu et al. also analyzed mortality due to influenza or pneumonia. Surprisingly, the estimates of vaccine effectiveness in preventing cause-specific mortality were similar to those of all-cause mortality, despite influenza-related mortality accounts for only a modest portion of total mortality. 47 This inconsistency might be due to selection bias, as discussed in more detail below. In any case, given that the estimates of the two outcomes were similar in both reviews we therefore discuss only all-cause mortality. The only RCT that assessed this outcome failed to show a significant protection by vaccination. Notably, however, only four deaths occurred during the season and the sample was clearly underpowered to detect any effect of vaccination. 48 When observational studies were combined, all meta-analyses found that vaccines were able to significantly reduce deaths for all causes, with summary estimates of effectiveness ranging from 68% to 47%. Gross et al. included most studies with unadjusted rates from nursing homes, while Jefferson et al. could also meta-analyze seven cohort studies-all published after Gross et al.-that used adjusted rates and included community-dwelling elderly. Also, Vu et al. results cannot easily be compared with the other metaanalyses, because of different inclusion criteria and the inclusion of both cohort and experimental studies into the analyses. In any case, when the five large data sets (total n = 585,633) that were published after the end of the search by Vu et al. were meta-analyzed separately, the summary vaccine efficacy was 46% (95% CI: 36-55%, Fig. S11 ). This finding suggests that, besides inclusion criteria, the observed differences across meta-analyses might simply be due to the difference in time among meta-analyses. As a matter of fact, currently the estimate for the overall effectiveness of vaccination in preventing deaths in the Cochrane review (47%; 95% CI: 39-54%), which incorporates the above recent studies and is thus based upon a much larger sample, may be the most reliable one. Even this estimate, however, is likely to be grossly inflated due to unaccounted confounding, sponsorship bias, selective reporting and other biases (see further discussion below).\n\n Concerning mild or moderate adverse events, the Cochrane meta-analysis of RCTs showed that PIV was associated with a significantly higher likelihood of local pain than placebo, but failed to show significant differences in the rates of fever and any systemic adverse event. Concerning serious adverse events, Jefferson et al. reported the results of four large data sets from three surveillance studies on the association between vaccination and Guillain-Barr\u00e9 syndrome. When the results of these studies were combined, the overall estimate of risk was not nominally significant (odds ratio: 1.60; 95% CI: 0.47-5.44). The authors concluded that \"safety does not appear to be a particular problem: the public health safety profile of the vaccines is acceptable.\" 3 The impact of immunization is theoretically expected to be higher in the presence of a good antigenic match between the epidemic and the vaccine strain. 49 Osterholm et al. did not quantitatively address this issue, 9 and Vu et al. included only studies with a good matching.\n\n 14 When Gross et al. stratified the analyses by matching, they found a significant effectiveness of vaccination even in seasons in which the circulating strain was a drift variant of the vaccine strain.\n\n 1 Finally, few direct comparisons were possible between matching and non-matching seasons in Jefferson et al., mainly due to the scarce available data from seasons with poor matching.", "qa": [["77_12084434_6_1", "What are the different meta-analyses that have been conducted on the effectiveness of influenza vaccination in preventing hospitalizations and mortality?\n", "Several meta-analyses have been conducted to assess the effectiveness of influenza vaccination in preventing hospitalizations and mortality. These include studies by Vu et al., Gross et al., and Jefferson et al. Each of these meta-analyses used different inclusion criteria and analyzed different outcomes, such as hospitalizations due to influenza or pneumonia and all-cause mortality. The summary estimates of vaccine effectiveness varied across these meta-analyses, ranging from 27% to 68% for hospitalizations and 47% to 68% for mortality. The differences in estimates may be due to variations in study design, inclusion criteria, and the time period of the studies included in the meta-analyses."], ["77_12084434_6_2", "What are the potential biases and limitations in the meta-analyses assessing the effectiveness of influenza vaccination?\n", "The meta-analyses assessing the effectiveness of influenza vaccination may be subject to various biases and limitations. These include selection bias, as some studies included in the meta-analyses focused on specific populations, such as elderly individuals in nursing homes. There may also be confounding factors that were not adequately accounted for in the studies, leading to inflated estimates of vaccine effectiveness. Additionally, there may be sponsorship bias and selective reporting, where studies funded by vaccine manufacturers or with positive results are more likely to be published. These biases and limitations should be considered when interpreting the results of the meta-analyses."], ["77_12084434_6_3", "What adverse events have been associated with influenza vaccination?\n", "Influenza vaccination has been associated with mild or moderate adverse events, such as local pain at the injection site. However, the rates of fever and systemic adverse events did not show significant differences between vaccinated and placebo groups in the meta-analysis of randomized controlled trials. Serious adverse events, such as Guillain-Barr\u00e9 syndrome, have also been investigated in surveillance studies. The overall estimate of risk for Guillain-Barr\u00e9 syndrome was not nominally significant, suggesting that the safety profile of influenza vaccines is acceptable. It is important to note that the impact of immunization may vary depending on the antigenic match between the vaccine strain and the circulating strain of the virus."]]}, {"passage_id": "70_18999098_1", "passage": "The patients in the study group underwent color Doppler sonography before excision of the saphenous vein. Patients in the control group, however, underwent saphenectomy without Doppler sonography. The mean age of the patients in the Doppler group was 61.60 years while that of the control patients was 60.9 years. The two groups were not significantly different regarding age (p=0.716). Also, 26 patients (52%) were male in the Doppler group and 24 patients were female. Moreover, in the non-Doppler group, 35 patients were male while 15 patients were female; thus the two groups were not significantly different with respect to gender (p=0.065). Additionally, 25 patients (50%) in the Doppler group and 14 patients (28%) in the non-Doppler group had diabetes, indicating no statistically significant difference between the two groups (p=0.024). The results of the investigation of hypertension revealed that 30 patients (60%) in the Doppler group and 23 patients (46%) in the non-Doppler group were affected with hypertension showing no significant difference between the two groups in this regard (p=0.161). There was no significant difference between the two groups regarding hyperlipidemia, smoking, and history of peripheral vessels disorder (p>0.05). Moreover, three patients (6%) in the Doppler group and four patients (8%) in the non-Doppler group developed infection following saphenectomy with no statistically significant difference between the two groups in this regard (P=1.000). The results of the study of edema demonstrated that six patients (12%) in the Doppler group and four patients (8%) in the non-Doppler group developed lower extremity edema after saphenectomy. So the two groups were not significantly different with respect to postoperative edema, either (p=0.741). Also, one patient (2%) in the Doppler group and two patients (4%) in the non-Doppler group developed postoperative hematoma after saphenectomy, indicating no significant difference between the two groups with regard to postoperative hematoma (p=1.000). Finally, one patient (2%) in the Doppler group and two patients (4%) in the non-Doppler group developed postoperative DVT after saphenectomy, indicating no significant difference between the two groups with regard to postoperative DVT (p=1.000). The length of incision for saphenous vein excision was 29.20 \u00b1 3.71 cm in the Doppler group and 28.98 \u00b1 3.72 cm in the non-Doppler group, suggesting no significant difference between the two groups in this respect, either (p=0.768) ( Table 1) . \n\n Very few studies similar to ours have been carried out in the world. This study was conducted on 100 candidates of off-pump CABG who were assigned to a study group (50 patients) and a control group (50 patients). The patients in the study group underwent color Doppler sonography before saphenectomy, while those in the control group underwent saphenectomy without Doppler sonography. Our findings indicated that the mean age of patients was 61.60 years in the Doppler group and 60.90 years in the non-Doppler group. Also, there was no significant difference between the two groups in this study with respect to age, gender, diabetes, hypertension, hyperlipidemia, smoking, history of peripheral vessels disease, postoperative infection, postoperative hematoma, postoperative edema, and postoperative DVT. To prepare the patient for saphenectomy, the surgical incision is made in a long course. This brings about many complications for the patient. Incomplete healing of the incision most often leads to a patient's increased hospital stay and costs. Also, some complications of the lower extremity wound at the site of excision of the great saphenous vein have been reported in 2%-24% of cases. The study by Linni et al. (2012) conducted on 130 patients demonstrated that preoperative duplex vein mapping (DVM) decreased the costs of surgical site infections (SSI) in patients undergoing infrainguinal bypass (5). Moreover, Teixeira et al. (2015) concluded that the technique used in saphenectomy for infrainguinal arterial bypass is not correlated with postoperative SSI (6) .", "qa": [["70_18999098_1_1", "What are the potential complications associated with saphenectomy?\n", "Some potential complications of saphenectomy include incomplete healing of the incision, increased hospital stay, increased costs, postoperative infection, postoperative hematoma, postoperative edema, and postoperative deep vein thrombosis (DVT). These complications can occur in 2%-24% of cases and can lead to additional health issues and expenses for the patient."], ["70_18999098_1_2", "How can preoperative duplex vein mapping (DVM) impact surgical site infections (SSI) in patients undergoing infrainguinal bypass?\n", "A study by Linni et al. (2012) found that preoperative duplex vein mapping (DVM) can decrease the costs of surgical site infections (SSI) in patients undergoing infrainguinal bypass. By using DVM before the surgery, healthcare professionals can better plan and prepare for the procedure, reducing the risk of infections and associated complications."], ["70_18999098_1_3", "Is the technique used in saphenectomy for infrainguinal arterial bypass correlated with postoperative surgical site infections (SSI)?\n", "According to a study by Teixeira et al. (2015), the technique used in saphenectomy for infrainguinal arterial bypass is not correlated with postoperative surgical site infections (SSI). This suggests that the choice of technique may not significantly impact the risk of infections in these procedures."]]}, {"passage_id": "80_17066800_2", "passage": "Compared with the first quartile of diabetes duration, the multivariable-adjusted odds of any antidiabetic therapy (oral hypoglycemic agents or insulin) for the second, third and fourth quartiles were 2.17 (95% CI 1.68-2.80, 3.39 (95% CI 2.53-4.54) and 4.99 (95% CI 3.64-6.84), respectively (P for trend <0.001).\n\n The association between the duration of diabetes quartiles and odds of insulin therapy (vs diet therapy or oral medication therapy) is shown in Table 3 . Compared with the first quartile, the odds of insulin therapy were 1.39 (95% CI 1.15-1.69), 2.01 (95% CI 1.63-2.48) and 4.47 (95% CI 3.61-5.54), respectively, for the second to fourth quartiles with a statistically significant trend (P < 0.001). This association was rather slightly intensified after adjusting for age and sex, and other possible confounders, and a significant trend (P < 0.001) was maintained. The association between the linearly increasing duration of diabetes and the odds of any medication therapy showed that the odds of any medication therapy gradually increased with 15-20 years of diabetes duration; however, the slope became dull after 20 years (Figure 1a) . The association between the linearly increasing duration of diabetes and the odds of insulin therapy showed that the odds of insulin therapy starts to increase at approximately 5-10 years of diabetes duration, and it continues to increase linearly thereafter (Figure 1b) .\n\n In the current study, we showed that a longer duration of diabetes is associated with a higher risk of receiving insulin therapy in Japanese patients with type 2 diabetes using large-scale, hospital-based study led by the JDS. Logistic regression analysis with a restricted cubic spline enabled representation of a schematic linear association between the duration of diabetes and the odds of selecting the insulin therapy, possibly representing the pathophysiological progressive nature of type 2 diabetes. The result of the present study is consistent with a previous study. Franch-Nadal et al. 9 showed that the prevalence of oral therapy or insulin therapy increased as the duration of diabetes increased in their study to evaluate the association between cardiovascular risk factors and the duration of type 2 diabetes in Spain (n = 3,130, mean age 68.0 years, mean BMI 30.2 kg/m 2 ). In their study, the prevalence of any medication therapy was 69.9, 82.9, 91.1 and 96.4%, respectively, for 0-5, 6-10, 11-20 and >20 years of diabetes duration; the prevalence of insulin therapy was 10.3, 17.6, 34.2 and 53.0%, respectively, for 0-5, 6-10, 11-20 and >20 years of diabetes duration. Despite the difference in body composition or ethnicity, these figures were very similar to the results of the present study. In addition to the previous study, we have shown the graphical presentation of the association between the linearly increasing duration of diabetes and the odds of insulin therapy in patients with diabetes. The progression from normal glucose tolerance to diabetes is characterized by reductions in b-cell mass that lead to impaired b-cell function [14] [15] [16] [17] , and the resulting glucotoxicity might be a known cause for the promotion of apoptosis, thus resulting in proliferative defects in b-cells 18 . Thus, a longer duration of diabetes, particularly with a poor glycemic control status, might expectedly cause impairment of b-cell function and increase the odds of needing insulin therapy; the present study suggests that the association might be linear. A Diabetes Outcome Progression Trial has shown the association of duration and the risk of monotherapy failure of glyburide, metformin or rosiglitazone monotherapy that were evaluated in that study. Similarly, the present study results also suggest that the odds for all drug therapies appear to increase during 15-20 years of diabetes, and become steady thereafter. Furthermore, the present study data might suggest that a certain percentage of the population diagnosed with diabetes that could endure 15-20 years without any diabetes medication, was less likely to progress thereafter, and thus, constituted the blunted slope of the association between the duration of diabetes and the odds of any medication therapy. In contrast, HbA1c levels were noted to continuously increase with the increase in the duration of diabetes despite a complex antidiabetic regimen.", "qa": [["80_17066800_2_1", "What are the odds of receiving insulin therapy in patients with type 2 diabetes based on the duration of their diabetes?\n", "The odds of receiving insulin therapy in patients with type 2 diabetes increase with the duration of their diabetes. The odds are significantly higher for patients in the second, third, and fourth quartiles of diabetes duration compared to those in the first quartile. The association between the duration of diabetes and the odds of insulin therapy is linear, with the odds starting to increase at approximately 5-10 years of diabetes duration and continuing to increase thereafter."], ["80_17066800_2_2", "How does the duration of diabetes affect the odds of any medication therapy in patients with type 2 diabetes?\n", "The odds of any medication therapy in patients with type 2 diabetes gradually increase with 15-20 years of diabetes duration. However, the slope of the association becomes dull after 20 years. This suggests that a certain percentage of the population diagnosed with diabetes can endure 15-20 years without any diabetes medication and are less likely to progress thereafter. The odds for all drug therapies appear to increase during 15-20 years of diabetes and become steady thereafter."], ["80_17066800_2_3", "What is the relationship between the duration of diabetes and the risk of needing insulin therapy in Japanese patients with type 2 diabetes?\n", "A longer duration of diabetes is associated with a higher risk of needing insulin therapy in Japanese patients with type 2 diabetes. Logistic regression analysis shows a linear association between the duration of diabetes and the odds of selecting insulin therapy, possibly representing the progressive nature of type 2 diabetes. This association is consistent with previous studies that have shown an increase in the prevalence of insulin therapy as the duration of diabetes increases. The progression from normal glucose tolerance to diabetes is characterized by reductions in beta-cell mass and impaired beta-cell function, which can lead to the need for insulin therapy."]]}, {"passage_id": "57_20009317_3", "passage": "The presence and/or absence of heart failure explained a minor additional component (Dr 2 = 0.03; P , 0.001), which suggested that factors related to heart failure beyond the determinants reported had a minor independent impact. Oscillatory amplitude and irregularity were also explained by chemoreflex sensitivity and delays (see the online supplement).\n\n Our study elucidates the mechanism underlying daytime ventilatory oscillations, a key predictor of mortality in patients with heart failure (1-6). We found that reduced stability (increased loop gain)-consequent to increased chemosensitivity, delay, and plant gain-yields stronger oscillations precisely as expected based on the theoretical concept of resonance (Equation 1). Specifically, the chemoreflex feedback system regulating ventilation paradoxically enhances biological noise near the frequency of periodic breathing \n\n to yield overshoot and undershoot ventilatory oscillations. These ventilatory oscillations in heart failure are typically irregular ( Figure 3A ) and conform to a model of feedback resonance in 96% of patients ( Figure 3B ). As loop gain rises toward 1, oscillations become larger and more regular (Figures 2 and 4) , yielding prominent periodic breathing despite being classed as a stable system according to classic criteria (loop gain , 1). In contrast to current understanding, the more extreme conditions of feedback instability are therefore not necessary for ventilatory oscillations to occur in heart failure (7, (13) (14) (15) (16) . Overall, our data are remarkably consistent with chemoreflex resonance as the predominant mechanism responsible. Our work therefore provides the field with a validated framework for interpreting and quantifying the broad range of oscillatory ventilatory behaviors seen commonly in patients with heart failure. \n\n By linking the clinical pattern of ventilatory oscillations to the function of the chemoreflex feedback system that regulates ventilation, we provide a unifying explanation for a host of previous empirical findings. Observational studies consistently demonstrate associations between daytime oscillatory breathing in heart failure and factors that promote a less stable feedback regulation of ventilation, namely, increased chemosensitivity and circulatory delay (7, 8, 12) . Interventions that diminish feedback act to suppress oscillations, which are seen as a reduced variability and the disappearance of a peak in the power spectrum of ventilation (5, 9-11, 13). In healthy individuals and animals breathing spontaneously, experimental studies have demonstrated associations between ventilatory fluctuations and previous swings in ventilation and PCO 2 , which are dependent on intact chemosensitivity (22, 26, 35) . Modeling studies have also suggested that a stronger chemoreflex response or higher loop gain yields quasioscillations in the presence of biological noise (24) , although a quantitative relationship between oscillatory behavior and reduced stability had not been proposed or tested experimentally until now. Taken together with the present study, the available evidence now overwhelmingly implicates chemoreflex feedback regulation in the ventilatory oscillations observed.\n\n Several key insights can be drawn from our work: Based on the concept of resonance, some degree of ventilatory oscillations must occur as a necessary side effect of homeostatic regulation. Specifically, a greater chemoreflex sensitivity will more completely suppress a long-term or steady-state disturbance to ventilation (e.g., a change in respiratory mechanics or metabolic rate), but will yield a greater amplification of biological noise at its characteristic frequency (see Figure 2B ; also see the online supplement). The greater circulatory delay that occurs in heart failure will increase the amplification at the resonance, but it also moves the \n\n resonance to a lower frequency where biological noise is greater.\n\n Oscillations result from chemoreflex feedback across a stability-instability continuum. Individuals with very low loop gain (e.g., 0 , loop gain < 0.25) exhibit a pattern that resembles biological noise. Those with normal loop gain (0.25 , loop gain < 0.5) exhibit weak and irregular oscillations. Patients with elevated loop gain (0.5 , loop gain < 1) manifest stronger and more regular oscillations (Figure 3) . Finally, consistent periodic breathing occurs in the most extreme cases when the threshold for instability is breached (loop gain . 1).\n\n When the loop gain is below 1, the magnitude of biological noise plays a key role in the pathogenesis of oscillatory breathing. For example, in Figures 2 and 3 , patients i and iii have quite similar loop gains, but patient i has twofold larger oscillations due to increased noise. Consequently, ventilatory fluctuations can be larger as a consequence of increased loop gain or increased noise.", "qa": [["57_20009317_3_1", "How do chemoreflex sensitivity and delays contribute to ventilatory oscillations in patients with heart failure?", "Chemoreflex sensitivity and delays play a significant role in the occurrence of ventilatory oscillations in patients with heart failure. Increased chemosensitivity, delay, and plant gain lead to reduced stability (increased loop gain), which results in stronger oscillations. This phenomenon aligns with the theoretical concept of resonance, where the chemoreflex feedback system regulating ventilation enhances biological noise near the frequency of periodic breathing, causing overshoot and undershoot ventilatory oscillations."], ["57_20009317_3_2", "What factors are associated with the occurrence of ventilatory oscillations in heart failure?", "Observational studies have consistently shown associations between daytime oscillatory breathing in heart failure and factors that promote a less stable feedback regulation of ventilation. These factors include increased chemosensitivity and circulatory delay. Interventions that diminish feedback act to suppress oscillations, leading to reduced variability and the disappearance of a peak in the power spectrum of ventilation. Additionally, experimental studies in healthy individuals and animals have demonstrated associations between ventilatory fluctuations and previous swings in ventilation and PCO2, which are dependent on intact chemosensitivity."], ["57_20009317_3_3", "How does loop gain affect the magnitude of ventilatory oscillations in heart failure?", "Loop gain, which represents the strength of the feedback loop regulating ventilation, plays a crucial role in the magnitude of ventilatory oscillations in heart failure. Individuals with very low loop gain exhibit a pattern resembling biological noise, while those with normal loop gain exhibit weak and irregular oscillations. Patients with elevated loop gain manifest stronger and more regular oscillations. When the loop gain exceeds 1, consistent periodic breathing occurs. Additionally, the magnitude of biological noise also influences the pathogenesis of oscillatory breathing, as increased noise can result in larger ventilatory fluctuations even with similar loop gains."]]}, {"passage_id": "78_18225058_0", "passage": "Obesity has been described as a global epidemic increasingly affecting populations in both developed and developing world countries alike [1] . In the United Kingdom it has been estimated that up to 61.3% of adults are overweight or obese. The current cost of treating obesity related health problems is\n\n approximately \u00a35 billion per year, a figure set to double by 2050 [2] . Common health problems related to obesity include a higher risk of developing type 2 diabetes, heart disease and some cancers [1] .\n\n Individuals with serious mental ill health (SMI) such as schizophrenia are even more likely to be overweight or obese than other members of the general population [3] . For example one recent North American study found nearly 80% of a sample of over 10,000 people with diagnoses of schizophrenia, bipolar disorder or depression to be overweight or obese [4] .\n\n The reason for this high prevalence of obesity in people with SMI has been a source of much debate. Some have argued that weight gain in SMI is due to a complex interaction between genetic factors, environment, the mental illness itself and the effects of antipsychotic medication [5] . Whilst others lay the blame for weight gain more firmly on the side effects of antipsychotic medication [6] [7] [8] [9] . This debate is further complicated by the potential effects of the unhealthy lifestyles (e.g., increased rates of smoking and reduced activity levels) that many individuals with SMI lead [10, 11] .\n\n The aim of this paper was to undertake a broad review of the literature which examines issues related to obesity in people with SMI. We reviewed evidence regarding the prevalence of obesity in SMI, its possible causes and its effects on physical health. We then considered literature regarding potentially efficacious interventions to manage weight gain before discussing the implications of the review for future research and clinical practice. In order to advance knowledge beyond the mental health field one of our key aims was to make the paper accessible and relevant to other health professionals who may be involved in the physical health care people with SMI.\n\n A broad search of the literature was conducted up to and including December 2013 using several electronic databases including Medline, PsycINFO and EMBASE. Search terms used included combinations of \"serious mental illness\", \"severe mental illness\", \"psychoses\" or \"psychotic disorder\"; \"weight gain\", \"obesity\", \"metabolic effects\" or \"causes of weight gain\"; \"physical health\", \"medical co-morbidity\", \"mortality\" or \"metabolic syndrome\"; \"antipsychotic medication\", \"neuroleptic medication\" or \"psychotropic medication\"; \"weight management\" or \"lifestyle intervention\".\n\n Consistent with the aims of the review we adopted a broad criteria including papers about weight gain and obesity in SMI, the effects of this weight gain on physical health, causes of weight gain and weight management interventions targeted at people with SMI. Due to translation issues we excluded non English language publications.\n\n In the context of this paper serious mental ill health (SMI) refers to a range mental health disorders such as schizophrenia, schizoaffective disorder, bipolar disorder and psychotic depression.\n\n Symptoms of these disorders include positive psychotic symptoms such as hallucinations (e.g., hearing voices when no one is around), delusions (e.g., strange beliefs or fears which are not in keeping with the person's culture) and/or thought disorder (e.g., disorganized or none intelligible speech patterns) [12, 13] . Such symptoms are often the cause of significant distress and disruption to the lives of those who experience them and may lead them to come into contact with mental health services. People with SMI may also experience negative symptoms which manifest as behavioural deficits such as restricted expression of thoughts and feelings, lack of pleasure in normally enjoyable activities and avolition [12] . The latter often adversely affects self care and quality of life [14] . They may also experience disturbances in mood, including episodes of depression and mania.\n\n Standard treatment for SMI usually includes the prescription of antipsychotic medication either one of the older or first generation drugs or increasingly one of the newer second generation preparations (see Table 1 for an overview of the different types of antipsychotic drugs). First generation drugs were introduced in the 1950s following the development of Chlorpromazine [15] . These drugs were thought to work by blocking the uptake of dopamine by synapses in the brain. Unfortunately they also inhibited the uptake of other neurotransmitters which resulted in a range of adverse effects such as extrapyramidal (muscle stiffness, involuntary movements, etc.) and anticholinergic (dry mouth, blurred vision, etc.) side effects.", "qa": [["78_18225058_0_1", "What are some common health problems related to obesity?\n", "Common health problems related to obesity include a higher risk of developing type 2 diabetes, heart disease, and some cancers."], ["78_18225058_0_2", "What factors contribute to the high prevalence of obesity in individuals with serious mental ill health (SMI)?\n", "The high prevalence of obesity in individuals with SMI is believed to be due to a complex interaction between genetic factors, environment, the mental illness itself, the effects of antipsychotic medication, and unhealthy lifestyles (such as increased rates of smoking and reduced activity levels)."], ["78_18225058_0_3", "What are some symptoms of serious mental ill health (SMI)?\n", "Symptoms of SMI can include positive psychotic symptoms such as hallucinations, delusions, and thought disorder. They can also include negative symptoms such as restricted expression of thoughts and feelings, lack of pleasure in normally enjoyable activities, and avolition. Disturbances in mood, including episodes of depression and mania, can also be experienced."]]}, {"passage_id": "70_209421574_2", "passage": "A review study reported the mean age-adjusted prevalence estimate for dementia among people aged 65 years and older living in developing countries, derived from data published within the past 10 years, was calculated to be 5.3% (17) , but, unfortunately, due to the heterogeneity of studies and the inability to report the prevalence in casecontrol studies, there was no possibility to estimate the prevalence of Alzheimer. On the other hand, most of the elder population at the risk of Alzheimer, which usually die for other reasons, have no chance of progression of AD. Most Alzheimer's patients in the Iranian community are being cared for at home due to family dependency and there is no access to all affected people with AD. Therefore, we were unable to make an accurate estimate of the prevalence of AD in Iran. Other factors affecting the estimation on the prevalence of AD are the presence of sample structure based on regional (26) . So the prevalence in an area is not an appropriate estimate for the entire community. (4) . Another study indicated age as the most important risk factor for AD. Genetic factors, vascular diseases, hypertension, heart disease, cerebrovascular diseases, diabetes, obesity, hyperlipidemia, metabolic syndrome, alcohol, diet, smoking, mental disorder, social economic status, education, physical activity and depression are among of known risk factors for AD (6) . There was a significant relationship between diabetes type2, smoking, overweight and obesity, physical inactivity, hypertension, hypercholesterolemia and AD (27) . Also, depression has been identified as another risk factor for AD. The role of other underlying diseases such as frailty, carotid atherosclerosis, hypertension, low diastolic blood pressure, type 2 diabetes mellitus (in Asian population), Low education level, high body mass index (BMI) in middle aged, current smoking (in western population), light-to-moderate drinking, stress was also investigated in the development of AD in this study (28) . Age, Apo lipoprotein E, family history, mild cognitive impairment, cardiovascular disorders, education, social and cognitive engagement and traumatic brain injury were found as other risk factors (3). Alzheimer's family history in first-degree relatives and a history of head injury with loss of consciousness were also risk factors (29) . The limitation of our study was that there was only few studies regarding epidemiology and risk factors of AD in Iran.\n\n The demographic transition in Iran and an increase in the prevalence of elderly population as a result indicate the importance of increasing the prevalence of diseases associated with aging (including dementia) and its related consequences in this country. AD is one of the main cause of functional dependence and mortality in the elderly people. The multiple mental activities in elderly and lifestyle changes increases the cognitive ability of the elderly, which will prevent direct and indirect costs of Alzheimer's.\n\n Ethical issues (Including plagiarism, informed consent, misconduct, data fabrication and/or falsification, double publication and/or submission, redundancy, etc.) have been completely observed by the authors.", "qa": [["70_209421574_2_1", "What are some known risk factors for Alzheimer's disease?\n", "Some known risk factors for Alzheimer's disease include age, genetic factors, vascular diseases, hypertension, heart disease, cerebrovascular diseases, diabetes, obesity, hyperlipidemia, metabolic syndrome, alcohol consumption, diet, smoking, mental disorders, social economic status, education, physical inactivity, and depression. These factors have been identified through various studies and research."], ["70_209421574_2_2", "How does the prevalence of Alzheimer's disease vary in developing countries?\n", "The prevalence of Alzheimer's disease in developing countries varies due to factors such as heterogeneity of studies, lack of access to affected individuals, and regional differences. A review study reported a mean age-adjusted prevalence estimate of 5.3% for dementia among people aged 65 years and older in developing countries. However, due to the inability to report the prevalence of Alzheimer's specifically, an accurate estimate of its prevalence in developing countries, including Iran, is challenging."], ["70_209421574_2_3", "What are some other risk factors and underlying diseases that have been investigated in the development of Alzheimer's disease?\n", "In addition to the known risk factors mentioned earlier, other risk factors and underlying diseases that have been investigated in the development of Alzheimer's disease include frailty, carotid atherosclerosis, low diastolic blood pressure, type 2 diabetes mellitus (in Asian population), low education level, high body mass index (BMI) in middle-aged individuals, current smoking (in Western population), light-to-moderate drinking, stress, Apo lipoprotein E, family history of Alzheimer's, mild cognitive impairment, cardiovascular disorders, social and cognitive engagement, and traumatic brain injury. These factors have been studied to understand their potential contribution to the development of Alzheimer's disease."]]}, {"passage_id": "37_19644580_3", "passage": "On a national level public wells are associated with very slightly lower arsenic concentrations (Kendall's tau (b) correlation of \u00c00.059 between arsenic concentration and an indicator variable set to 1 for public wells and 0 for domestic wells, Table 3 ). There is a very small national association between arsenic and well depth (Kendall's tau (b) correlation of 0.039) with deeper wells having higher arsenic concentrations compared with shallower wells. There is a significant association between the indicator variable for public wells and depth (Kendall's tau (b) correlation of 0.306) with public wells being deeper than domestic wells. In keeping with the national trend, there is a statistically significant association (Po0.01) between well type and well depth (positive bivariate correlation) in Oklahoma, New Mexico, and New Jersey indicating deeper wells for public supplies than domestic wells. In contrast, associations between arsenic and well depth vary with region. The positive and statistically significant correlation between arsenic and well depth observed for Oklahoma (Table 3 ) results in the deeper public wells in Oklahoma having higher arsenic concentrations compared with shallower domestic wells (Figure 4a ). However, the association between arsenic and well depth was not observed to be statistically significant for New Mexico (Table 3, Figure 4b ) and there is no significant difference between public and domestic well arsenic levels.\n\n For New Jersey, there is no significant association between well depth and arsenic as measured by Kendall's tau (b) (P \u00bc 0.196) (Table 3, Figure 4c ). However, domestic wells have significantly higher arsenic levels (Po0.01). This suggests that factors other than depth account for this difference. A greater selectivity toward low arsenic sources may be found among public supplies as public supplies presumably test more frequently and have a wider range of source water options than domestic well users. This selectivity may be more pronounced in a water-rich area, such as New Jersey, than in regions with more limited water resources, such as Oklahoma or New Mexico. In summary, the differences between public and domestic wells vary by region. In some cases the local geology is such that the deeper strata (and hence public wells) have higher arsenic, whereas in other locations the shallower strata (and hence domestic wells) have higher arsenic. Still, in other locations, there are no significant depth trends and either there are no significant differences between the two well types or other factors, such as selectivity, may contribute to differences between public and domestic supplies.\n\n An important difference between public and domestic wells is that in some cases, public groundwater is treated with processes that remove arsenic (principally, iron oxide/ manganese oxide removal processes, McNeill and Edwards, 1995; Chen et al., 1999; Gurian et al., 2004) , whereas domestic wells are generally untreated. Applying the regional removals for groundwater results in finished water arsenic concentrations (Figure 3 ) that are significantly lower than domestic well arsenic concentrations for four regions (New England, Midwest, North Central, and West), whereas concentrations are comparable between domestic and finished public water in the remaining three (with South Central showing somewhat higher public finished water arsenic concentrations) regions. Although there is no strong overall national trend if one compares the untreated domestic and untreated public groundwater (i.e., in some regions domestic well arsenic levels are higher, but in others public groundwater arsenic levels are higher), when one allows for the removal of arsenic in public treatment systems, then overall national average arsenic concentration is higher in domestic wells (i.e., in some regions domestic wells are higher, whereas in other regions domestic and public groundwater are comparable). Finished public surface water concentrations are comparable with finished public groundwater levels and generally lower than domestic wells. In summary, finished water arsenic levels are somewhat lower in public supplies Finished Public SW (Gurian et al., 2004) . Significance values (2-tailed) shown in parentheses, *Correlation is significant at the 0.01 level (2-tailed).\n\n Arsenic exposure in US Kumar et al.\n\n than in domestic wells, but much of this difference appears to be due to treatment, rather than selection of higher quality water sources. Table 4 shows the total arsenic exposure (i.e., arsenic consumed in g/d) for each source type and region. These values are influenced by the total population in each group. To identify highly exposed groups the percentages of the national population and percentage of national exposure for each group are also provided in Table 4 . For public supplies, arsenic exposure from drinking surface water accounted for 41% of total US exposure, but 58% of the population indicating that per-person exposures are below the national average.", "qa": [["37_19644580_3_1", "How do public wells and domestic wells differ in terms of arsenic concentrations and well depth?\n", "Public wells generally have slightly lower arsenic concentrations compared to domestic wells on a national level. However, deeper wells tend to have higher arsenic concentrations. Public wells are typically deeper than domestic wells."], ["37_19644580_3_2", "What factors contribute to the differences in arsenic levels between public and domestic wells?\n", "The differences in arsenic levels between public and domestic wells vary by region. In some cases, the local geology leads to higher arsenic concentrations in deeper strata, which are typically associated with public wells. In other locations, shallower strata, associated with domestic wells, have higher arsenic levels. Additionally, factors such as selectivity in water sources may contribute to the differences between public and domestic supplies."], ["37_19644580_3_3", "How does the treatment of public groundwater affect arsenic concentrations in finished water?\n", "Public groundwater is often treated to remove arsenic using processes like iron oxide/manganese oxide removal. This treatment results in significantly lower arsenic concentrations in finished water compared to untreated domestic wells. The national average arsenic concentration is higher in domestic wells when comparing untreated water sources, but when considering the removal of arsenic in public treatment systems, the overall national average arsenic concentration is higher in domestic wells."]]}, {"passage_id": "58_2890300_2", "passage": "Likewise, induction of CA increased expression of chemokine (C-X-C motif) ligand 1 (CXCL1) and matrix metalloproteinase (MMP) 8, mediators important for neutrophil recruitment and function, more significantly in WT, but not in myeloperoxidase knockout mice ( Figure 3A) . Furthermore, induction of CA increased expression of cluster of differentiation 68 (CD68), a macrophage marker, in WT but not in myeloperoxidase knockout mice ( Figure 3A) . In contrast, \u03b1-smooth muscle actin, a marker for vascular smooth muscle cells, was reduced in WT mice after induction of CA ( Figure 3A) . myeloperoxidase deficiency attenuated reduction of \u03b1-smooth muscle actin in response to CA induction ( Figure 3A) .\n\n To investigate whether myeloperoxidase exerts effects in the absence of myeloperoxidase-producing cells, human aortic endothelial cells were incubated with human myeloperoxidase (30 nmol/L) in the absence or presence of its inhibitor ABAH for 6 hours. Among >20 genes measured with quantitative reverse transcription polymerase chain reaction, adhesion molecules vascular cell adhesion molecule-1 and intercellular adhesion molecule-1 and oxidative stress marker SOD2 (MnSOD) were increased significantly by myeloperoxidase (P<0.05; Figure 3B ). The increase was eliminated by ABAH, suggesting that the catalytic activity of myeloperoxidase was required for the effects ( Figure 3B ). Interestingly, increased SOD2 and NOX4 (with a trend, P=0.05) may increase hydrogen peroxide, a substrate for myeloperoxidase enzyme.\n\n The number of leukocytes (based on morphology) in cerebral arteries of comparable sizes was decreased in myeloperoxidase knockout mice compared with that in WT mice, after induction of CA (Figure 4 \n\n To our knowledge, this study is the first to demonstrate localized increase of myeloperoxidase concentration in the CA sac of patients, which may be produced by myeloperoxidase-positive cells (neutrophils and macrophages) in CA. The localized myeloperoxidase may contribute to formation, progression, and rupture of CA in at least 4 ways. First, myeloperoxidase may attract neutrophils, and perhaps other leukocytes, to endothelium of cerebral arteries, with negative charges on their surfaces, by physical forces because of strong positive charges on the surface of myeloperoxidase. 18 Our finding of an increase in leukocytes in aneurysm tissue of patients as well as cerebral arteries of mice is consistent with this mechanism. Second, myeloperoxidase may enter into endothelial cells through direct cell-cell contact from neutrophils to cause impairment of endothelial function, 19 which is a common characteristic in an early stage of CA as well as abdominal aortic aneurysms. 20 Third, myeloperoxidase may transcytose through endothelium into the arterial media to catalyze oxidation reactions in the extracellular matrix, 21 thereby reducing tensile strength of the wall of cerebral arteries. Fourth, myeloperoxidase per se may induce inflammation by increasing expression of adhesion molecules in endothelial cells, promoting leukocyte adherence and inflammation. Summary of our findings and interpretations are shown in Figure 6 .\n\n Myeloperoxidase deficiency may protect against CA through profound reduction in expression of tumor necrosis factor-\u03b1 in cerebral arteries of myeloperoxidase knockout compared with WT mice, in response to induction of CA. In cerebral arteries, tumor necrosis factor-\u03b1 may recruit leukocytes and increase inflammatory cytokines and chemokines, injure endothelial cells, produce phenotypic transformation of smooth muscle cells, and upregulate MMPs that deteriorate integrity of cerebral arteries. 22, 23 CXCL1 is an important chemoattractant that recruits neutrophils to endothelium at the site of inflammation.\n\n 24-26 A >10-fold reduction of CXCL1 in cerebral arteries of myeloperoxidase knockout mice compared with WT mice after induction of CA was associated with a 17-fold decrease of MMP8 (collagenase-2), an MMP expressed specifically in neutrophils. 27 Thus, in addition to a reduction in recruited leukocytes, deficiency of myeloperoxidase may inhibit cellular production of proinflammatory molecules.\n\n Both leukocytes and vascular cells express MMPs. 28 MMP9 has been linked to CA, using MMP9 knockout mice.\n\n 14 In this Thus, we speculate that there may be a significant decrease in MMP9 activity. The role of MMP3 and MMP13 has not been studied in CA. Thus, findings in this study provide a rationale for future studies of the role of MMP3 and MMP13 in CA.\n\n Smooth muscle differentiation molecules, including \u03b1-smooth muscle actin, are decreased in cerebral smooth muscle cells in response to tumor necrosis factor-\u03b1 in culture, 29 in aorta of abdominal aortic aneurysms in mice, 30 and after other vascular injuries. 31 Thus, our finding of preserved expression of \u03b1-smooth muscle actin (also positive in myofibroblast) in myeloperoxidase knockout mice after induction of CA suggests that myeloperoxidase deficiency attenuates formation and rupture of CA via a mechanism that involves protection of smooth muscle cells from injury.\n\n A limitation in this study is that mechanistic findings to explain attenuation of CA by myeloperoxidase deficiency are based on quantification of mRNA levels, not by protein or activity levels. This limitation resulted from limited quantities of cerebral arteries in mice. However, quantitative reverse transcription polymerase chain reaction produces the most accurate quantification with limited material.\n\n In summary, in patients with CAs, circulating myeloperoxidase concentrations are increased locally in the CA sac, which is associated with increased neutrophils and other myeloperoxidase-positive cells in aneurysm tissues. In a mouse model of CA, myeloperoxidase deficiency reduced expression in cerebral arteries of proinflammatory molecules, preserved expression of \u03b1-smooth muscle actin, decreased the number of leukocytes, and attenuated formation and rupture of CAs. Myeloperoxidase itself increased expression of adhesion molecules in endothelial cells. These findings suggest that myeloperoxidase, which is increased locally in the CA sac of patients, contributes importantly to the pathophysiology of CA in a mouse model. Because myeloperoxidase deficiency is common in human population, 32, 33 it would be of interest to examine the incidence of CAs in patients with myeloperoxidase deficiency.", "qa": [["58_2890300_2_1", "What are the potential mechanisms by which myeloperoxidase contributes to the formation, progression, and rupture of cerebral aneurysms?\n", "Myeloperoxidase may attract neutrophils and other leukocytes to the endothelium of cerebral arteries, impair endothelial function, transcytose through endothelium into the arterial media to catalyze oxidation reactions, and induce inflammation by increasing expression of adhesion molecules in endothelial cells. These mechanisms can lead to leukocyte adherence, inflammation, reduction in tensile strength of the arterial wall, and deterioration of the integrity of cerebral arteries."], ["58_2890300_2_2", "How does myeloperoxidase deficiency affect the expression of proinflammatory molecules and leukocyte recruitment in cerebral arteries?\n", "Myeloperoxidase deficiency reduces the expression of proinflammatory molecules, such as tumor necrosis factor-\u03b1, in cerebral arteries of mice with cerebral aneurysms. This reduction in proinflammatory molecules is associated with a decrease in leukocyte recruitment to the cerebral arteries. Additionally, myeloperoxidase deficiency may inhibit the cellular production of proinflammatory molecules, including chemokine (C-X-C motif) ligand 1 (CXCL1) and matrix metalloproteinase (MMP) 8, which are important for neutrophil recruitment and function."], ["58_2890300_2_3", "What is the potential role of smooth muscle cells in the formation and rupture of cerebral aneurysms, and how does myeloperoxidase deficiency affect smooth muscle cell injury?\n", "Smooth muscle differentiation molecules, such as \u03b1-smooth muscle actin, are decreased in cerebral smooth muscle cells in response to tumor necrosis factor-\u03b1 and other vascular injuries. However, myeloperoxidase deficiency preserves the expression of \u03b1-smooth muscle actin in cerebral smooth muscle cells after induction of cerebral aneurysms. This suggests that myeloperoxidase deficiency may protect against smooth muscle cell injury and contribute to the attenuation of cerebral aneurysm formation and rupture."]]}, {"passage_id": "70_951823_2", "passage": "35 The SCS has been found to be associated with body dissatisfaction in bulimia nervosa 36 and obesity 37 and has been found to be higher in obese binge eaters than obese nonbinge eaters. 37 \n\n Sixty-four of the 98 participants (65%) who reported that dieting preceded binge eating (DIET\u00aerst group) were compared to the 34 participants (35%) who reported that binge eating preceded their \u00aerst diet (BINGE\u00aerst group). The DIET\u00aerst and BINGE\u00aerst groups did not differ in current age (41.1 y vs 42.7 y; F(1, 97) 0.57, ns) or gender (81% female vs 82% female; chi-square (1) 0.02, ns).\n\n The two study groups were characterized by similar axis I psychiatric and axis II personality disorder frequencies. The two study groups did not differ in the distribution of major depression (w 21 (1) 1.56, ns) personality disorder diagnoses. Table 1 summarizes the developmental variables, current eating disturbance, and current psychological functioning \u00aendings for the two study groups. Also shown in Table 1 are the statistical tests for signi\u00aecant differences (ANOVAs for continuous data). The DIET\u00aerst and BINGE\u00aerst groups did not differ in age of \u00aerst diet; however, the BINGE\u00aerst group was signi\u00aecantly younger when \u00aerst overweight, at onset of binge eating, and at onset of BED diagnosis. The BINGE\u00aerst group reported a higher frequency of being teased about their weight and size while growing up (PARTS). The two groups were similar in current body mass index (BMI) and highest lifetime BMI, current binge eating frequency (objective and subjective binge eating frequency on the EDE-Q), associated eatingrelated psychopathology (EDE-Q and TFEQ), body image dissatisfaction (BSQ), and current psychological functioning (BDI, RSE, DAST and SCS).\n\n We re-analyzed all of the data separately for females only (note that gender was not differentially distributed by onset of d\u00f5 \u00c2et or binge eating as indicated above). When restricted to females (n 80), all of the overall nonsigni\u00aecant \u00aendings remained nonsigni\u00aecant. In the case of signi\u00aecant \u00aendings observed for the overall group, all of the comparison remained signi\u00aecant for females only. For females only, the BINGE\u00aerst group was signi\u00aecantly younger when \u00aerst overweight (M 11. \n\n This study rigorously assessed a consecutive series of patients with BED at a university-based outpatient eating disorder program. Sixty-\u00aeve percent of patients reported that dieting preceded their binge eating and 35% reported that binge eating preceded their \u00aerst diet. Age of onset of binge eating and of BED differed signi\u00aecantly depending on whether dieting or binge eating began \u00aerst. Patients who began binge eating \u00aerst reported earlier onset of overweight, higher frequency of being teased about their weight and shape, and an earlier onset of BED diagnosis than those patients who reported dieting prior to their \u00aerst binge.\n\n No signi\u00aecant differences between the two study groups were observed in demography or gender, current BMI or highest BMI, weight cycling, eating behavior disturbances (binge eating frequency, overeating frequency, hunger, restraint, disinhibition), overvalued ideas regarding weight and shape, body image dissatisfaction, associated psychological domains (depression, self-esteem, drug problems, or self-consciousness), or in the distribution of DSM-IV psychiatric or personality disorders.\n\n Roughly one-third of BED patients reported regular binge eating prior to regular dieting. This \u00aending, while slightly lower than reported previously for obese binge eaters 11, 12 and BED, 13 is nonetheless considerably higher than the consistent \u00aending that dieting precedes binge eating in the vast majority of bulimic cases. 9, 10 Overall for the entire BED study group, the average age of \u00aerst overweight was 14.6 y, age of \u00aerst diet was 16.2 y, and age of binge eating was 19.4 y. This sequence, at \u00aerst glance, might be thought to be consistent with prevailing views that overweight leads to dieting which precipitates binge eating in vulnerable persons. However, 34% of the patients reported a sharp deviation from this pattern. For BED patients who report binge eating \u00aerst, the mean age of onset of binge eating was 11.6, the mean age of \u00aerst overweight was 12.4 y, and the mean age of \u00aerst diet was 17.1 y. In this pattern, binge eating leads to overweight which leads to dieting.", "qa": [["70_951823_2_1", "What are the risk factors associated with body dissatisfaction in bulimia nervosa and obesity?\n", "Risk factors associated with body dissatisfaction in bulimia nervosa and obesity include the presence of the SCS (Sociocultural Attitudes Towards Appearance Scale). The SCS has been found to be higher in individuals with bulimia nervosa and obesity, indicating a link between body dissatisfaction and these conditions. "], ["70_951823_2_2", "How does the age of onset of binge eating and BED differ depending on whether dieting or binge eating began first?\n", "The age of onset of binge eating and BED differs depending on whether dieting or binge eating began first. Patients who began binge eating first reported an earlier onset of overweight, a higher frequency of being teased about their weight and shape, and an earlier onset of BED diagnosis compared to those who reported dieting prior to their first binge. This suggests that the sequence of dieting leading to binge eating may not be consistent in all cases of BED. "], ["70_951823_2_3", "What are the similarities and differences between the two study groups in terms of demography, BMI, eating behavior disturbances, and psychological domains?\n", "The two study groups, one reporting dieting preceding binge eating and the other reporting binge eating preceding their first diet, did not differ significantly in terms of demography or gender, current BMI or highest BMI, weight cycling, eating behavior disturbances (binge eating frequency, overeating frequency, hunger, restraint, disinhibition), overvalued ideas regarding weight and shape, body image dissatisfaction, associated psychological domains (depression, self-esteem, drug problems, or self-consciousness), or in the distribution of DSM-IV psychiatric or personality disorders. This suggests that the two groups have similar characteristics in these aspects."]]}, {"passage_id": "4_208166626_0", "passage": "Type 1 diabetes (T1D) is a challenging chronic condition, which often leads to lowered life expectancy and diminished quality of life [1] . Despite significant advances in insulin therapy and technological developments, only 17% of youth and 21% of adults with diabetes achieve a glycated hemoglobin (HbA 1c ) level of <7.0% (58 mmol/mol), as recommended in clinical guidelines [2, 3] .\n\n In general, closed-loop insulin delivery systems, also called \"automated insulin delivery systems (AID)\" or \"artificial pancreas systems (APS),\" combine sensors for continuous glucose monitoring (CGM) and insulin pumps with a control algorithm, and these are characterized by automated insulin delivery in response to the user's glucose level. As subcutaneously administered insulin stays active for multiple hours, the algorithm used to calculate the amount of insulin needed has to predict future glucose values to operate safely. Closed-loop systems designed for commercial use have been shown to be safe and effective in reducing hyperglycemia and hypoglycemia in people with diabetes (PwD) of all age groups [4] [5] [6] [7] [8] , and these systems are therefore seen as the gold standard of future diabetes therapy [9] .\n\n Qualitative research on commercially developed closed-loop systems has indicated that individuals using these systems for relatively short periods report reduced anxiety [10] [11] [12] [13] [14] , improved quality of sleep [10, [14] [15] [16] [17] , and reduced burden of managing diabetes [12, 13, [17] [18] [19] and this led to greater freedom and flexibility in their lifestyle as a result [12, [16] [17] [18] . This is supported by a few quantitative studies that report less fear of hypoglycemia [10] [11] [12] [13] 20, 21] -although possibly because of small sample sizes, the changes are not consistently significant-a reduction in diabetes-specific distress in 2 studies [13, 20] , and, in a single study, improved sleep quality [22] . These studies have used a range of closed-loop or technology-specific quality-of-life instruments, with the Diabetes Technology Questionnaire being the most widely used.\n\n However, although a variety of commercial APS are under development and some have recently become available in a limited number of countries, they are not universally available, accessible, or affordable. Behind the hashtag #WeAreNotWaiting, a community of PwD and their families have created new tools and systems to help PwD better utilize their devices and data. These systems are co-created in the Do-It-Yourself Artificial Pancreas System (DIYAPS) community, but each user has to build their own individual system themselves and use at their own risk. Instructions and code for these systems have been made universally available via open-source platforms [23] . The DIYAPS or \"Open-Source Artificial Pancreas System\" (OpenAPS) is one of the most significant developments to emerge through this movement [24] . In these systems, insulin delivery is automated and remotely controlled by open-source algorithms and by reverse engineering and connecting commercially available and approved insulin pumps and CGM systems. The term \"open source\" describes software whose source code is publicly available. Open-source licenses usually deny liability and warranty and may require disclosing source code and referring to the project [25] .\n\n Initial observational studies on DIYAPS have described significant improvements in glycemic control, quality of life, and sleep quality in DIYAPS users of all age groups, including children and adolescents, where caregivers build and maintain these systems on their behalf [26] [27] [28] [29] [30] [31] . A limited number of studies are also specifically reporting on the experience of using DIYAPS, and in addition to highlighting improved sleep [28, 30, 32] and reduced burden of diabetes management [32] , they point to increased confidence, increased energy, and reduced mood swings [32] .\n\n Evidence of usage of DIYAPS is limited to date, as none of these systems have yet been evaluated by a randomized controlled trial, regarding safety and efficiency-although at least 1 is planned [33] . Observational studies largely describe outcomes self-reported by users and are mainly based on smaller cohort studies (up to n=80) [27] . There is an estimated 15+ million hours of real-world DIYAPS data, much of which have yet to be fully analyzed.", "qa": [["4_208166626_0_1", "How do closed-loop insulin delivery systems improve the management of type 1 diabetes?\n", "Closed-loop insulin delivery systems, also known as automated insulin delivery systems or artificial pancreas systems, combine continuous glucose monitoring (CGM) sensors and insulin pumps with a control algorithm. These systems automatically deliver insulin in response to the user's glucose levels. They have been shown to be safe and effective in reducing hyperglycemia and hypoglycemia in people with diabetes of all age groups. Closed-loop systems improve the management of type 1 diabetes by providing more accurate and timely insulin delivery, leading to better glycemic control and reduced burden of managing diabetes."], ["4_208166626_0_2", "What are the benefits of using DIYAPS (Do-It-Yourself Artificial Pancreas System) in the management of type 1 diabetes?\n", "DIYAPS is a community-driven movement where individuals with type 1 diabetes and their families create their own artificial pancreas systems using open-source platforms and instructions. Observational studies have shown significant improvements in glycemic control, quality of life, and sleep quality in DIYAPS users of all age groups. These systems have been reported to reduce the burden of diabetes management, improve sleep quality, increase confidence and energy, and reduce mood swings. DIYAPS provides individuals with more control over their diabetes management and allows them to better utilize their devices and data."], ["4_208166626_0_3", "What are the limitations and challenges associated with the usage of DIYAPS in the management of type 1 diabetes?\n", "While DIYAPS has shown promising results in observational studies, there are limitations and challenges associated with its usage. Currently, none of these systems have been evaluated through randomized controlled trials for safety and efficiency. Most of the evidence is based on self-reported outcomes by users and smaller cohort studies. Additionally, DIYAPS requires users to build and maintain their own systems, which may not be feasible or accessible for everyone. The open-source nature of DIYAPS also raises concerns regarding liability, warranty, and the need to disclose source code. Further research and evaluation are needed to fully understand the safety, efficacy, and long-term outcomes of DIYAPS in the management of type 1 diabetes."]]}, {"passage_id": "5_205990002_1", "passage": "HCMV infection was defined by the detection of HCMV in blood by use of any assay, in the absence of clinical manifestations or organ-function abnormalities, whereas HCMV disease was defined by the detection of either systemic or local HCMV infection, in the presence of clinical symptoms and/or organ-function abnormalities [21] . HCMV infection was diagnosed on the basis of either antigenemia (for children receiving an HSCT before March 2007) or DNAemia (for patients who received a transplant after March 2007), according to methods described elsewhere [22, 23] . Patients were preemptively treated when 2 pp65-positive leukocytes/200,000 leukocytes were detected (or at the time when a single positive cell was detected twice 2-3 days apart) or when a cutoff level of 10,000 DNA copies/mL of whole blood was reached [24] . Preemptive therapy was based on intravenous administration of ganciclovir (5 mg/kg twice a day), which was replaced by foscarnet (90 mg/kg twice a day) for cases of ganciclovir-induced neutropenia (defined as \u03fd0.5 \u03eb 10 9 neutrophils/L), or a sustained increase in HCMV levels in the blood during receipt of ganciclovir therapy. Antiviral treatment was stopped when virus had been cleared from the blood according to the guiding assay (i.e., after 2 consecutive negative results were noted). Relapses were treated similarly.\n\n Donor/recipient HCMV serologic findings were evaluated using ELISA (ETI-Cytok-G Plus; DiaSorin), according to a method reported elsewhere [25] ; in a subgroup of patients, serum neutralizing antibody was tested on both fibroblasts and endothelial cells, to assess passive antibody transfer, which was revealed by a lack of neutralizing antibody on fibroblasts and by detection of low titers (\u03fd1:160) on endothelial cells [26] .\n\n Immunologic follow-up. Immunologic reconstitution was investigated at 30, 60, 90, 180, and 360 days after transplantation (unless transplant rejection or relapse of the underlying disease occurred). The lymphocytes of the patients were tested to evaluate the frequency of HCMV-specific CD4 \u03e9 and CD8 \u03e9 T cells producing interferon (IFN)-\u2425, by means of cytokine flow cytometry performed after in vitro stimulation with autologous, monocyte-derived, HCMV-infected dendritic cells, as described in detail elsewhere [15] . Absolute CD3 \u03e9 CD4 \u03e9 and CD3 \u03e9 CD8 \u03e9 T cell counts were determined in heparinized peripheral blood samples by means of direct immunofluorescence flow cytometry (Beckman Coulter). The total number of HCMV-specific CD4 \u03e9 and CD8 \u03e9 T cells was calculated by multiplying the percentages of HCMV-specific T cells producing IFN-\u2425 by the relevant absolute CD4 \u03e9 and CD8 \u03e9 T cell count. On the basis of results obtained by testing 46\n\n HCMV-seropositive and 8 HCMV-seronegative healthy blood donors, subjects with an HCMV-specific CD4 \u03e9 or CD8 \u03e9 T cell count of \u03fe0.4 cells/L of blood were considered to be immune [15] . In patients receiving HSCT, levels of at least 1 CD4 \u03e9 and 3 CD8 \u03e9 HCMV-specific T cells/L of blood were considered to be protective [17] . Statistical analysis. The Mann-Whitney U test was used to compare median values between different groups of patients, whereas Fisher's exact test was used to compare percentages between groups.\n\n The probabilities of developing HCMV infection and an HCMV-specific immune response during the first year after transplantation, as well as the incidences of transplantationrelated mortality (TRM) and GVHD, were calculated and expressed as cumulative incidences, with competing risks taken into account [27, 28] . Differences between groups were compared using the Gray test or the log-rank test, as appropriate. The Cox proportional hazard regression model was used to analyze factors potentially interfering with specific T cell recovery. The following variables were considered: (1) patient characteristics (sex, HCMV serologic findings, age at transplantation, mismatch in the sex of the donor and patient, and alloreactivity of the NK cells of the donor toward the recipient), (2) disease characteristics (e.g., malignant disorders vs.", "qa": [["5_205990002_1_1", "What are the diagnostic criteria for HCMV infection and HCMV disease?\n", "HCMV infection is defined as the detection of HCMV in blood without clinical manifestations or organ-function abnormalities. On the other hand, HCMV disease is defined as the detection of systemic or local HCMV infection in the presence of clinical symptoms and/or organ-function abnormalities."], ["5_205990002_1_2", "What is the preemptive therapy for HCMV infection and what are the criteria for initiating treatment?\n", "Preemptive therapy for HCMV infection involves the administration of antiviral drugs such as ganciclovir or foscarnet. Treatment is initiated when a certain threshold of HCMV-positive leukocytes or a specific level of HCMV DNA copies in the blood is reached."], ["5_205990002_1_3", "How is the immune response to HCMV evaluated in patients after transplantation?\n", "The immune response to HCMV is evaluated by measuring the frequency of HCMV-specific CD4+ and CD8+ T cells producing interferon (IFN)-\u03b3. This is done through cytokine flow cytometry after in vitro stimulation with HCMV-infected dendritic cells. The absolute counts of CD4+ and CD8+ T cells are also determined to calculate the total number of HCMV-specific T cells."]]}, {"passage_id": "69_1675713_0", "passage": "In patients with possible symptoms of coronary artery disease (CAD) it is important not only to detect patients with the disease but at the same time to identify patients with no CAD. Myocardial perfusion imaging (MPI) can be used to demonstrate myocardial perfusion abnormalities in patients with and without known CAD [1] [2] [3] and to evaluate the risk of new cardiac events in patients with known or intermediate risk of CAD [4, 5] . In daily clinical practice 35-65% of all MPIs are without perfusion defects despite symptoms of myocardial ischemia [6] [7] [8] . Considering the radiation dose and the significant costs of a MPI, it could be of considerable importance if biomarkers can be used as a screening modality before referral to MPI.\n\n Recently, high sensitivity C-reactive protein (hsCRP) levels have been found in patients with myocardial perfusion abnormalities [9] . CRP is the most examined inflammation marker in relation to cardiovascular disease (CVD) and substantial evidence indicates that baseline hsCRP level is an independent predictor of cardiovascular events both in patients with non-fatal myocardial infarction (MI) and in apparently healthy individuals [10, 11] . Similarly, two recent prospective studies and a meta-analysis of previous studies have shown, that interleukin 6 (IL-6), a proximal mediator of CRP, are associated with risk of CAD about as strongly and in addition to established risk factors [12] . Moreover, the heart failure biomarker N-terminal of the pro-hormone brain natriuretic peptide (NT-proBNP) also has diagnostic and prognostic importance in terms of cardiovascular events and mortality in patients with stable angina pectoris and in patients with acute coronary syndrome [13] [14] [15] . However, the clinical consequences of elevated NT-proBNP levels are not fully elucidated and concomitantly new markers with different pathophysiological approaches emerge. YKL-40 is a marker of inflammation and endothelial dysfunction, and matrix metalloproteinase 9 (MMP-9) belongs to an enzyme family specialized in breaking down constituents of the extracellular matrix. YKL-40 protein expression is found in vivo in both macrophages and vascular smooth muscle cells in the atherosclerotic plaque where it seems to participate in processes during early stages of atherosclerosis by promoting the process of the atherosclerotic plaque formation [16] . The major source for MMPs is also immigrated monocytes/macrophages and vascular smooth muscle cells [17] , and MMP-9 seems to be one of the predominant MMPs within the vulnerable plaque, where it promotes plaque progression and destabilization [18, 19] . Both YKL-40 and MMP-9 therefore appear to be associated with the early pathophysiology of atherosclerosis. Furthermore, YKL-40 is associated with the presence and extent of coronary artery disease (CAD) [20] [21] [22] and elevated YKL-40 levels are seen in patients with myocardial infarction (MI) [22, 23] . Serum MMP-9 levels are gradually increasing with progressing coronary ischemic symptoms [24] and might be useful as an index marker of plaque activity in patients with known CAD [25] .\n\n The objective of the present study was to examine whether these markers alone or in combination could be used as a screening modality in patients suspected of CAD prior to referring to MPI.\n\n Baseline demographic, medical history and paraclinical variables in relation to gender are presented in Table 1 . There was an equal distribution of genders and no significant difference in age between genders. There were no differences in systolic and diastolic blood pressure, prevalence of hypertension or diabetes or otherwise use of medication between genders. Although women had higher HDL levels than men, there was no difference in total cholesterol levels. A higher prevalence of CAD was seen in the male part of the population where a higher proportion of treatment with statins also were seen.\n\n An equal number of men and women were capable of performing the bicycle ergometer test, but significantly more women than men were stressed with dypyridamole. Only 19 (7.8%) patients, more men than women, had a low post stress EF but none of these had ESV index below lower normal limit. Myocardial perfusion defects were found in 44 (18.1%) patients, more often in men than in women (p,0.001).\n\n Biomarker levels according to outcome of MPI are shown in Table 2 . NT-proBNP levels were elevated in patients with myocardial perfusion defects (p,0.001). This was found for both men and women.", "qa": [["69_1675713_0_1", "How can myocardial perfusion imaging (MPI) be used in the diagnosis and evaluation of coronary artery disease (CAD)?", "Myocardial perfusion imaging (MPI) can be used to detect myocardial perfusion abnormalities in patients with and without known CAD. It can help identify patients with the disease and evaluate the risk of new cardiac events in patients with known or intermediate risk of CAD."], ["69_1675713_0_2", "What biomarkers have been found to be associated with myocardial perfusion abnormalities and cardiovascular disease (CVD)?", "High sensitivity C-reactive protein (hsCRP), interleukin 6 (IL-6), N-terminal of the pro-hormone brain natriuretic peptide (NT-proBNP), YKL-40, and matrix metalloproteinase 9 (MMP-9) have been found to be associated with myocardial perfusion abnormalities and cardiovascular disease (CVD). These biomarkers can provide diagnostic and prognostic information in patients with stable angina pectoris, acute coronary syndrome, and myocardial infarction (MI)."], ["69_1675713_0_3", "How do gender differences impact the prevalence of coronary artery disease (CAD) and the use of statins in the population studied?", "In the population studied, there was a higher prevalence of CAD in men compared to women. Additionally, a higher proportion of men were treated with statins. However, there were no significant differences in age, blood pressure, prevalence of hypertension or diabetes, or use of medication between genders. Women had higher HDL levels than men, but there was no difference in total cholesterol levels."]]}, {"passage_id": "70_2402869_1", "passage": "Compared with electrophoresis and iso-electrofocusing, HPLC is fully automated and less laborious, 15 and was therefore preferred for the Dutch neonatal screening programme.\n\n We describe here the clinical validation of the Bio-Rad Variant Newborn Screening (Vnbs), the comparison with G7 (Tosoh BioScience) and Ultra 2 (Primus Corporation), and the results of the subsequent pilot screening carried out by the National Institute for Public Health and the Environment (RIVM) in Bilthoven and IJsselland Hospital (YSL) in Capelle aan den IJssel.\n\n \n\n For the validation study of the Bio-Rad Vnbs 94 random fresh umbilical cord blood samples were collected at the Zaans Medical Center in Zaandam with full parental consent. In addition, residual umbilical cord blood from seven anonymous premature babies was provided by the Sanquin blood bank, Leiden.\n\n To determine whether the Vnbs recognizes all common variants, 30 blood samples were prepared by mixing blood containing high HbF with adult blood containing a haemoglobin variant that was available at the time (HbA, HbS, HbC, HbD-Los Angeles, HbE or HbJ). These anonymized samples were obtained from the routine diagnostic service of the Leiden University Medical Center, Leiden. All samples were genotyped by multiplex PCR and/or direct DNA sequencing on the ABI Prism 3730 DNA Analyzer (PE biosystems Foster City/CA, USA). 16 -18 The blood samples were spotted on filter paper identical to the paper used in the regular neonatal screening (Whatman #903). These dried blood spot (DBS) samples were analysed on the Vnbs within seven days after the blood had been spotted on the paper. Because whole blood with haemoglobin variants was more accessible than DBS, we used selfmade DBS with whole blood and mixtures of whole blood. The whole blood samples were also analysed on the Vnbs for comparison to exclude discrepancies between the used material (whole blood or DBS).\n\n All samples were also analysed on the Variant II, according to the manual (Bio-Rad), which has been proven to be a valid method for the recognition and quantification of nearly all common mutations associated with haemoglobinopathy in adults and neonates. 19 \n\n For analysis 2.5 mL blood was diluted in 250 mL deionized water. From the DBS, 3-mm \u00d8 discs were extracted in 250 mL deionized water in a 96-well microtitre plate. To ensure better extraction, the loaded plates were put on a shaker for 5 minutes.\n\n \n\n The HPLC systems, calibration material and control samples were used in full compliance with the manufacturers' instructions.\n\n Into a 96-well microtitre plate, 3 mm \u00d8 DBS were extracted in deionized water (Vnbs: 230 mL; Ultra 2 and G7: 400 mL). The plates were shaken for 5 -30 minutes.\n\n The FAES retention time markers were analysed 20 times in one run to determine the within-run precision of all three HPLC systems. The between-run precision was determined by analysing the FAES retention markers on 20 different days.\n\n \n\n Between March and June 2006, the RIVM and the YSL analysed 21,969 DBS (see Table 1 ) from the routine neonatal screening programme on the Vnbs. Parents had given permission to use the spots for anonymous scientific research purposes. The YSL also analysed its samples on the Ultra 2 (Primus Corporation) and confirmed the abnormal patterns on the G7 (Tosoh BioScience). All samples with an abnormal pattern were exchanged between the two laboratories. Interpretation of the HPLC pattern\n\n The Vnbs classifies 14 retention time windows. HbBart's, the g 4 tetramer formed in a-thalassaemia, elutes in the 'FAST' window, at the beginning of the run as a tall and narrow peak ( peak height/total area 0.0600) (see Figure 1a ). Total fetal haemoglobin (HbF) consists of the acetylated HbF in window 'F1' and the HbF peak in window 'F'. The peak in window '1' represents degradation products of HbA, which itself elutes in window 'A'. HbA 2 and HbE elute in the same window, but because HbA 2 is below the detection level in neonates, a peak in this window is putatively identified as HbE. The peak percentage is calculated by dividing the peak area by the total area of all peaks.", "qa": [["70_2402869_1_1", "What is the purpose of the Bio-Rad Variant Newborn Screening (Vnbs) and how does it compare to other screening methods?\n", "The Bio-Rad Variant Newborn Screening (Vnbs) is used for clinical validation and screening of newborns. It is compared to other screening methods such as G7 and Ultra 2 to determine its effectiveness and accuracy. HPLC is preferred for the Dutch neonatal screening program due to its automation and reduced labor requirements."], ["70_2402869_1_2", "How are blood samples prepared for analysis on the Vnbs and what materials are used?\n", "Blood samples for analysis on the Vnbs are prepared by mixing blood containing high HbF with adult blood containing a hemoglobin variant. These samples are genotyped using multiplex PCR and/or direct DNA sequencing. The samples are then spotted on filter paper and dried to create dried blood spot (DBS) samples. The DBS samples are analyzed on the Vnbs within seven days of being spotted on the paper. Whole blood samples are also analyzed on the Vnbs for comparison."], ["70_2402869_1_3", "What is the classification system used by the Vnbs and how does it interpret the HPLC patterns?\n", "The Vnbs uses a classification system with 14 retention time windows. HbBart's, a tetramer formed in alpha-thalassemia, elutes in the 'FAST' window as a tall and narrow peak. Total fetal hemoglobin (HbF) is classified into the acetylated HbF in window 'F1' and the HbF peak in window 'F'. The peak in window '1' represents degradation products of HbA, which elutes in window 'A'. HbA2 and HbE elute in the same window, with a peak in this window being identified as HbE in neonates. The peak percentage is calculated by dividing the peak area by the total area of all peaks."]]}]