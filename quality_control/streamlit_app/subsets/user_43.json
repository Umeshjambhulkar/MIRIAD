[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "22_943861_0", "passage": "Thoracic cavity injuries include 25% of mortalities in traumatic events and are associated with a 40% mortality rate, generally (1, 2) . Studies have shown that early diagnosis of such traumas can decrease the mortality rate and the resultant burden, significantly. CT scan with a high priority for detection of chest traumas is the gold standard for diagnosis of thoracic traumas (3) (4) (5) . Although this diagnostic test has high accuracy, patients undergoing CT scan receive a high radiation dose; thus, it is recommended to use this test only when it is indicated (6) (7) (8) . In addition, CXR is used as the early diagnostic test in patients with thoracic injuries, yet the accuracy of it is not very high (9) (10) (11) (12) (13) (14) .\n\n CUS can be a reliable and accurate alternative to CXR.\n\n However, diagnostic yield of CUS largely depends on the operator's expertise (15) (16) (17) . However, structural changes of CUS in recent years have led to higher quality and\n\n Tanaffos 2014; 13 (4) : [29] [30] [31] [32] [33] [34] [35] [36] [37] [38] [39] [40] spatial resolution, resulting in greater accuracy in the critical care and emergency management services (18) (19) (20) (21) (22) (23) .\n\n One of the most common thoracic injuries is pneumothorax and its early detection in multiple trauma patients is critically important. Several studies have demonstrated the high sensitivity and specificity of CUS (24) (25) (26) (27) (28) . In this regard, three meta-analyses during the past 5 years showed that the sensitivity and specificity of CUS in diagnosis of pneumothorax varied between 78.6-90.9% and 98.2-99%, respectively (29) (30) (31) . But, these studies have some limitations such as the small number of included articles, lack of evaluating the inter-study threshold variation, lack of publication bias assessment, and evaluation of only English-language articles. Thus, it seems that another meta-analysis is needed to overcome these limitations. The present systematic review and metaanalysis was designed to evaluate the diagnostic accuracy of CUS and CXR for detection of pneumothorax in comparison with CT scan as the gold standard.\n\n \n\n The study was conducted according to the Metaanalysis Of Observational Studies in Epidemiology (MOOSE) statement providing a detailed guideline of preferred reporting style for systematic reviews and metaanalyses (32) . Relevant articles were identified through a literature search of online databases (PubMed, SCOPUS, EMBASE, Cochrane, CINAHL, and Trip databases) with no time or language limitation. The initial search was broad and included the following words: (\"ultrasound\" or \"sonography\" or \"ultrasonography\" or \"radiography\" or \"chest film\" or \"chest radiograph\") and (\"pneumothorax\" or \"aerothorax\") and (\"sensitivity\" and \"specificity\" or \"diagnostic accuracy\" or \"diagnostic yield\"). In addition, we ran a hand search in the reference lists of all articles meeting the inclusion criteria and previous meta-analysis studies to find more studies. In addition, it was attempted to contact the authors of all studies that met the inclusion criteria and request unpublished data and abstracts. \n\n \n\n Two authors (M.Y, H.A) extracted data independently from studies, using a standardized data abstraction form.\n\n They collected data related to study design, patient characteristics, CUS diagnosis criteria and operator, CUS transducer, blinding status, and sampling method. The authors were contacted for clarification of study sample, regarding missing or insufficient data, if necessary. In cases of duplicate reporting, data were used from the study on the largest number of patients or individual patient data from each study, if available.\n\n We assessed the quality of the included studies using the QUADAS2. Two reviewers (MY, HA) independently reviewed each study and rated their quality as \"good,\" \"fair,\" or \"poor\". Quality assessment was conducted based on criteria of diagnostic studies, accounting for study design and presence of bias including selection, performance, recording, and reporting bias. The studies with high risk of bias were defined as poor quality, presence of moderate risk (did not affect the results) was considered as fair quality, and those with minimal risk as good quality. In this regard, inter-rater reliability was acceptably high (95%). Disagreements were discussed by a third reviewer (A.M.J) and settled with consensus decision. In analyses, the mixed-effects binary regression model was used, a type of random effect model used when the heterogeneity source is not clear. Statistical heterogeneity was measured using the I 2 and \u03c7 2 tests (P < 0.10 was representative of significant statistical heterogeneity) (35) .\n\n Sensitivity and subgroup analyses were performed to check the expected or measured heterogeneity. The sensitivity analysis was done using studies with good and fair quality levels and applied based on a bivariate metaregression model. All possible causes of heterogeneity including the operator, ultrasound probe, CUS frequency, study subjects (trauma/non-trauma), CUS signs, and type of sampling (consecutive versus convenience sampling)\n\n were included as covariates in the meta-regression model. (Table 2) . specificity for CUS (31) . The two latest meta-analyses were in concordance with the present meta-analysis. However, all three mentioned meta-analyses had some limitations.\n\n The first limitation was the small number of articles included in their analyses. The second one was lack of publication bias assessment. The third one was that they only considered English-language articles, which may lead to possible publication bias.\n\n On the other hand, we performed an extensive search \n\n The present meta-analysis showed that the diagnostic accuracy of CUS was higher than that of supine CXR for detection of pneumothorax. It seems that CUS is superior to CXR for detection of pneumothorax, even after adjusting for possible sources of heterogeneity.", "qa": [["22_943861_0_1", "What are the advantages of using CUS (ultrasound) over CXR (chest radiography) for the detection of pneumothorax?\n", "CUS (ultrasound) has been shown to have higher diagnostic accuracy compared to CXR (chest radiography) for the detection of pneumothorax. It is considered superior to CXR, even after adjusting for possible sources of heterogeneity. CUS has higher sensitivity and specificity, making it a reliable and accurate alternative for the early detection of pneumothorax in multiple trauma patients."], ["22_943861_0_2", "What are the limitations of previous meta-analyses on the diagnostic accuracy of CUS and CXR for the detection of pneumothorax?\n", "Previous meta-analyses on the diagnostic accuracy of CUS and CXR for the detection of pneumothorax have some limitations. Firstly, they included a small number of articles in their analyses, which may limit the generalizability of their findings. Secondly, they did not assess publication bias, which could introduce bias in the results. Lastly, they only considered English-language articles, potentially leading to publication bias and excluding relevant studies in other languages."], ["22_943861_0_3", "How was the present meta-analysis conducted to evaluate the diagnostic accuracy of CUS and CXR for the detection of pneumothorax?\n", "The present meta-analysis followed the Metaanalysis Of Observational Studies in Epidemiology (MOOSE) statement, which provides a detailed guideline for reporting systematic reviews and meta-analyses. Relevant articles were identified through a literature search of online databases with no time or language limitation. Data extraction was done independently by two authors, and the quality of included studies was assessed using the QUADAS2 criteria. Statistical analyses were performed using mixed-effects binary regression models, and sensitivity and subgroup analyses were conducted to check for heterogeneity."]]}, {"passage_id": "70_17608940_0", "passage": "Breast cancer is the most common malignancy among women in the United States, with an estimated 207,090 women expected to be diagnosed in 2010. 1 With less than 40,000 women expected to die because of the disease this year, increasingly more women will survive and require ongoing medical care. Care of the women with breast cancer requires knowledge of a variety of specific medical issues that confront these patients, such as the increased risk for bone loss and fracture.\n\n Breast cancer increases the risk of a woman for bone loss. Bone loss occurs through multiple mechanisms, including the risk of premature ovarian failure, the increased risk of bone loss following the onset of menopause, and the effect of cancer therapies on bone mineral density (BMD). These women are also commonly advised to avoid the use of estrogen therapy, which has previously been considered the first-line therapy for the prevention of osteoporosis, as the majority of breast cancers are defined by the presence of estrogen and/or progesterone receptors. This leaves limited options for the treatment of breast cancer therapy-induced bone loss. In addition to the recently identified receptor activator of nuclear factor-\u03baB ligand (RANKL) inhibitors such as denosumab, which inhibit osteoclast stimulation, the effects of nonhormonal options such as the bisphosphonates, which inhibit osteoclast-mediated bone resorption, have been investigated in this setting. This review investigates the current and emerging\n\n Women with localized or early-stage breast cancer undergoing adjuvant chemotherapy are at increased risk for bone loss. Those with the most significant loss of bone density are the ones who experience premature ovarian failure. [2] [3] [4] The rate of chemotherapy-related amenorrhea is most affected by the choice of chemotherapeutic agent, dosing, and the age of the patient at treatment, with those over 40 at highest risk. [5] [6] [7] Menopause in these women may occur up to 10 years early, 2 and those women who become menopausal are documented to have a BMD significantly lower than women who remain premenopausal after treatment, 3, 4 with a documented difference in BMD at 1 year of between 3%-14% at the lumbar spine.\n\n Women are also at risk of bone loss from antihormonal therapy. Tamoxifen, a selective estrogen receptor modulator, has been used primarily for hormone-sensitive breast cancers for over 20 years. Although tamoxifen has been shown to increase BMD in postmenopausal women, BMD declines by 1.44% per year among premenopausal women compared with a 0.24% increase among women taking placebo. 8 Despite the protective effect on BMD in postmenopausal women, tamoxifen is not used commonly in this population. Aromatase inhibitors (AIs) such as letrozole, anastrozole, and exemestane are now considered for first-line therapy, either as primary adjuvant treatment or in sequence following tamoxifen after several studies documented a significant improvement in disease-free survival when compared with tamoxifen alone. [9] [10] [11] [12] [13] [14] [15] [16] AIs prevent the peripheral conversion of androgens into estrogens. Although this effect improves the risk of recurrence in women with breast cancer, it also has a detrimental effect on bone. AIs have been documented to increase the risk of fracture 9,10,13-17 and osteoporosis. Bone loss of 4%-5% at the lumbar spine has been documented after 2 years of AI therapy, 18, 19 with between 3% and 4% loss at the hip. From baseline to 5 years, therapy with anastrozole was associated with an 8.1% lower BMD at the lumbar spine than tamoxifen 20 among postmenopausal women participating in the Anastrozole Tamoxifen Alone or in Combination trial.\n\n In addition, breast cancer itself, without the presence of skeletal metastases, may affect the risk of fracture. Women with newly diagnosed breast cancer without the presence of soft tissue or skeletal metastases have been documented to have an almost five-fold increase in the risk of vertebral fractures compared with healthy women. 21 Those with soft tissue metastases and without known skeletal metastases have a 23-fold increased risk of vertebral fracture. These fracture rates remain significantly elevated even after those subsequently found to have skeletal disease are excluded.", "qa": [["70_17608940_0_1", "What are the risk factors for bone loss in women with breast cancer?\n", "Risk factors for bone loss in women with breast cancer include premature ovarian failure, increased risk of bone loss following menopause, and the effects of cancer therapies on bone mineral density (BMD). Women with localized or early-stage breast cancer undergoing adjuvant chemotherapy are at increased risk for bone loss, especially those who experience premature ovarian failure. Antihormonal therapies such as tamoxifen and aromatase inhibitors also contribute to bone loss in these women."], ["70_17608940_0_2", "How does breast cancer treatment affect bone density in women?\n", "Breast cancer treatment, including chemotherapy and antihormonal therapies, can lead to bone loss in women. Chemotherapy-related amenorrhea, caused by the choice of chemotherapeutic agent, dosing, and age of the patient, increases the risk of bone loss. Premature menopause may occur up to 10 years early in women with breast cancer, and those who become menopausal have significantly lower BMD compared to premenopausal women. Antihormonal therapies like tamoxifen and aromatase inhibitors also contribute to bone loss, with aromatase inhibitors increasing the risk of fracture and osteoporosis."], ["70_17608940_0_3", "What is the impact of breast cancer on the risk of fractures in women?\n", "Women with breast cancer, even without skeletal metastases, have an increased risk of fractures. Those with newly diagnosed breast cancer without soft tissue or skeletal metastases have a nearly five-fold increase in the risk of vertebral fractures compared to healthy women. Women with soft tissue metastases and no known skeletal metastases have a 23-fold increased risk of vertebral fracture. These fracture rates remain elevated even after excluding those with subsequent skeletal disease. Breast cancer itself, along with the effects of treatment, contributes to the increased risk of fractures in women."]]}, {"passage_id": "7_39711923_1", "passage": "Renal disease was defined as a composite of acute kidney injury (AKI), chronic kidney disease (CKD) at all stages, and end-stage renal disease (ESRD), including patients on hemodialysis (HD). Endocavitary device included the presence of either a pacemaker, an internal cardiac defibrillator (ICD), a left ventricular assist device (LVAD), or a right ventricular assist device (RVAD). The presence of any prosthetic material was defined to include patients who had any of the following: prosthetic valve, endocavitary device, intravenous graft material, prosthetic joint, orthopedic rod, and bone plates or screws.\n\n Hospital-acquired IE was defined as IE developing in a patient hospitalized for more than 48 h prior to the onset of signs/symptoms consistent with IE. Health care-associated IE was defined as IE diagnosed within 48 h of admission in an outpatient with extensive health care contact as reflected by any of the following criteria: (i) receipt of intravenous therapy, wound care, or specialized nursing care at home within the 30 days prior to the onset of infection; (ii) attendance at a hospital or hemodialysis clinic or receipt of intravenous chemotherapy within the 30 days before the onset of infection; (iii) hospitalization in an acute care hospital for 2 or more days in the 90 days before the onset of infection; or (iv) residence in a nursing home or long-term care facility (20) . Community-acquired IE was defined as IE diagnosed at the time of admission (or within 48 h of admission) in a patient not fulfilling the criteria for health careassociated IE.\n\n Paravalvular complication was defined as the presence of any of the following in a patient with native valve IE: paravalvular abscess, paravalvular fistula, or valvular perforation. Prosthetic valve complication was defined as the presence of any of these same complications in a patient with prosthetic valve IE. Persistently positive blood culture was defined as having positive blood cultures \u03fe72 h following initiation of antifungal therapy.\n\n For the subgroup analysis on antifungal therapy, patients were assigned to treatment groups based on the antifungal drug that they received for the majority of the first 30 days of therapy. These groups were termed majority regimen backbone groups. Patients receiving an echinocandinbased regimen for \u03fe15 days of the first 30 days of treatment were classified as being in the echinocandin backbone therapy group, and those receiving an amphotericin B-based regimen for \u03fe15 days of the first 30 days of treatment were placed in the amphotericin B backbone therapy group. An amphotericin B-based regimen was defined as a regimen that included any of the following: amphotericin B deoxycholate, amphotericin B colloidal dispersion (ABCD), amphotericin B lipid complex (ABLC), or amphotericin B liposomal formulation (LAmB). An echinocandin-based regimen was defined as a regimen that contained caspofungin, micafungin, or anidulafungin. A treatment regimen was defined as a majority combination therapy regimen if the patient received at least two antifungal drugs concomitantly for \u03fe15 days of the first 30 days of therapy. A treatment regimen was defined as receiving any combination therapy if the patient received \u03fe1 day of two antifungal drugs concomitantly at any point during therapy. Suppressive antifungal therapy was defined as transition of antifungal therapy to azole-based therapy following initial treatment period for patients treated with either amphotericin B-or echinocandinbased therapy. For patients treated from onset of infection with azolebased therapy, suppressive therapy was defined as a duration of azole therapy of \u03fe120 days.\n\n Outcomes. Clinical characteristics, complications (both clinical and echocardiographic), and mortality were compared between those receiving amphotericin B-based therapy and those receiving echinocandinbased therapy. These same variables were compared between the following groups: (i) those receiving adjunctive surgical therapy versus those receiving medical therapy alone and (ii) those infected with Candida albicans versus those infected with Candida parapsilosis. Additionally, univariate analysis was performed to look for predictors of in-hospital and 1-year mortality in the overall cohort.\n\n Statistical analysis. All statistical analyses were performed using JMP Pro (version 11.0). Patients' demographics and clinical variables were described as means and standard deviations for continuous data and proportions for categorical data. The 2 or Fisher exact test was used to compare categorical variables between groups, as appropriate.", "qa": [["7_39711923_1_1", "What are the risk factors for hospital-acquired infectious endocarditis (IE)?\n", "Risk factors for hospital-acquired IE include being hospitalized for more than 48 hours prior to the onset of signs/symptoms consistent with IE. Additionally, extensive healthcare contact, such as receiving intravenous therapy, wound care, or specialized nursing care at home within the 30 days prior to infection, attending a hospital or hemodialysis clinic, receiving intravenous chemotherapy, or being hospitalized in an acute care hospital for 2 or more days in the 90 days before infection, can also increase the risk of hospital-acquired IE."], ["7_39711923_1_2", "How is prosthetic valve complication defined in patients with infective endocarditis (IE)?\n", "Prosthetic valve complication in patients with IE is defined as the presence of paravalvular abscess, paravalvular fistula, or valvular perforation. These complications can occur in patients with either native valve IE or prosthetic valve IE."], ["7_39711923_1_3", "What is suppressive antifungal therapy in the treatment of fungal infections?\n", "Suppressive antifungal therapy refers to the transition of antifungal therapy to azole-based therapy following the initial treatment period for patients treated with either amphotericin B or echinocandin-based therapy. For patients treated from the onset of infection with azole-based therapy, suppressive therapy is defined as a duration of azole therapy of more than 120 days. This type of therapy aims to prevent the recurrence of fungal infections and maintain long-term control of the infection."]]}, {"passage_id": "86_16395892_19", "passage": "This system will be outlined in the Manual of Operations for the Core Lab(s) which is prepared and submitted by the Core Lab to the DCC [data coordinating centre] prior to initiating of the study.\n\n At a minimum this system must include: ) The inclusion of at least two known quality control samples; the reported measurements of the quality control samples must fall within specified ranges in order to be certified as acceptable.\n\n ) Calibration at FDA approved manufacturers' recommended schedules.\n\n The chair of the pathology committee will circulate to all of the study pathologists . . . samples [sic] biopsy specimens for evaluation after criteria to establish diagnosis of FSGS has been agreed. This internal review process will serve to ensure common criteria and assessment of biopsy specimens for confirmation of diagnosis of FSGS.\" \n\n \n\n Trial investigators must o en seek a balance between achieving a su ciently long follow-up for clinically relevant outcome measurement, and a su ciently short follow-up to decrease attrition and maximise completeness of data collection. Non-retention refers to instances where participants are prematurely \"o -study\" (ie, consent withdrawn or lost to follow-up) and thus outcome data cannot be obtained from them. The majority of trials will have some degree of nonretention, and the number of these \"o -study\" participants usually increases with the length of follow-up.\n\n It is desirable to plan ahead for how retention will be promoted in order to prevent missing data and avoid the associated complexities in both the study analysis (Item c) and interpretation. Certain methods can improve participant retention, -such as nancial reimbursement; systematic methods and reminders for contacting patients, scheduling appointments, and monitoring retention; and limiting participant burden related to follow-up visits and procedures (Item ). A participant who withdraws consent for follow-up assessment of one outcome may be willing to continue with assessments for other outcomes, if given the option.\n\n Non-retention should be distinguished from non-adherence. Non-adherence refers to deviation from intervention protocols (Item c) or from the follow-up schedule of assessments (Item ), but does not mean that the participant is \"o -study\" and no longer in the trial. Because missing data can be a major threat to trial validity and statistical power, non-adherence should not be an automatic reason for ceasing to collect data from the trial participant prior to study completion. In particular for randomised trials, it is widely recommended that all participants be included in an intention to treat analysis, regardless of adherence (Item c).\n\n statistical power, while those with low validity will not accurately measure the intended outcome variable. One study found that only % ( / ) of randomised trials in acute stroke used a measure with established reliability or validity. Modi ed versions of validated measurement tools may no longer be considered validated, and use of unpublished measurement scales can introduce bias and in ate treatment e ect sizes.\n\n Standard processes should be implemented by local study personnel to enhance data quality and reduce bias by detecting and reducing the amount of missing or incomplete data, inaccuracies, and excessive variability in measurements.\n\n Examples include standardised training and testing of outcome assessors to promote consistency; tests of the validity or reliability of study instruments; and duplicate data measurements.\n\n A clear protocol description of the data collection process-including the personnel, methods, instruments, and measures to promote data quality-can facilitate implementation and helps protocol reviewers to assess their appropriateness. Inclusion of data collection forms in the protocol (ie, as appendices) is highly recommended, as the way in which data are obtained can substantially a ect the results. If not included in the protocol, then a reference to where the forms can be found should be provided. If performed, pilot testing and assessment of reliability and validity of the forms should also be described. All randomized infants completing the -month evaluation schedule will have fulfilled the infant clinical and laboratory evaluation requirements for the study. . . All randomized infants who are prematurely discontinued from study drug will be considered off study drug/on study and will follow the same schedule of events as those infants who continue study treatment except adherence assessment. All of these infants will be followed through months as scheduled.\n\n Randomized infants prematurely discontinued from the study before the -month evaluation will have the following clinical and laboratory evaluations performed, if possible: . . . . . .\n\n Once an infant is enrolled or randomized, the study site will make every reasonable effort to follow the infant for the entire study period . . . It is projected that the rate of loss-to-follow-up on an annual basis will be at most % . . . Study site staff are responsible for developing and implementing local standard operating procedures to achieve this level of follow-up.\n\n . Participant Withdrawal Participants may withdraw from the study for any reason at any time.", "qa": [["86_16395892_19_1", "What are some methods that can improve participant retention in a clinical trial?\n", "Some methods that can improve participant retention in a clinical trial include financial reimbursement, systematic methods and reminders for contacting patients, scheduling appointments, and monitoring retention, and limiting participant burden related to follow-up visits and procedures."], ["86_16395892_19_2", "How can non-retention be distinguished from non-adherence in a clinical trial?\n", "Non-retention refers to instances where participants are prematurely \"off-study\" and outcome data cannot be obtained from them, while non-adherence refers to deviation from intervention protocols or from the follow-up schedule of assessments. Non-adherence does not mean that the participant is \"off-study\" and no longer in the trial."], ["86_16395892_19_3", "What are some examples of standard processes that can be implemented to enhance data quality and reduce bias in a clinical trial?\n", "Some examples of standard processes that can be implemented to enhance data quality and reduce bias in a clinical trial include standardizing training and testing of outcome assessors to promote consistency, testing the validity or reliability of study instruments, and conducting duplicate data measurements."]]}, {"passage_id": "34_3820653_0", "passage": "Magnetic resonance imaging (MRI) is the gold standard for defining myocardial substrate in 3D and can be used to guide ventricular tachycardia ablation. We describe the feasibility of using a prototype magnetic resonance-guided electrophysiology (MR-EP) system in a pre-clinical model to perform real-time MRI-guided epicardial mapping, ablation, and lesion imaging with active catheter tracking. \n\n Experiments were performed in vivo in pigs (n = 6) using an MR-EP guidance system research prototype (Siemens Healthcare) with an irrigated ablation catheter (Vision-MR, Imricor) and a dedicated electrophysiology recording system (Advantage-MR, Imricor). Following epicardial access, local activation and voltage maps were acquired, and targeted radiofrequency (RF) ablation lesions were delivered. Ablation lesions were visualized in real time during RF delivery using MR-thermometry and dosimetry. Hyper-acute and acute assessment of ablation lesions was also performed using native T1 mapping and late-gadolinium enhancement (LGE), respectively. High-quality epicardial bipolar electrograms were recorded with a signal-to-noise ratio of greater than 10:1 for a signal of 1.5 mV. During epicardial ablation, localized temperature elevation could be visualized with a maximum temperature rise of 35 C within 2 mm of the catheter tip relative to remote myocardium. Decreased native T1 times were observed (882 \u00b1 107 ms) in the lesion core 3-5 min after lesion delivery and relative location of lesions matched well to LGE. There was a good correlation between ablation lesion site on the iCMR platform and autopsy. \n\n The MR-EP system was able to successfully acquire epicardial voltage and activation maps in swine, deliver, and visualize ablation lesions, demonstrating feasibility for intraprocedural guidance and real-time assessment of ablation injury.\n\n \n\n \n\n Radiofrequency (RF) catheter ablation reduces recurrences of ventricular tachycardia (VT) and appropriate implantable cardioverter defibrillator (ICD) therapies in patients with ischaemic 1,2 and nonischaemic cardiomyopathy. 3 However, catheter ablation is still limited by relatively low long-term success rates. Catheter ablation of VT has evolved from mapping and ablation of electrophysiologically defined re-entrant circuits to the identification and targeting of abnormal myocardial substrate (areas of scar and surrounding border zone containing a mixture of healthy and scar tissue). Although electrical surrogates of arrhythmogenic myocardium are assessed by contact electroanatomical mapping (EAM) of the endocardium and epicardium, there are several limitations to this approach. Electroanatomical mapping cannot interrogate the complex 3D anatomy of scar; the spatial resolution of voltage-based mapping is limited by multiple factors including electrode size, orientation, contact, and number of points collected; electrical criteria for scar annotation may not be universally applicable to pathological scar. 4 In patients with non-ischaemic cardiomyopathy who may have epicardial or intramural scar, the limitation of EAM to delineate fully the 3D geometry of scar has been well reported.\n\n Magnetic resonance imaging (MRI) using late-gadolinium enhancement (LGE) is the gold standard for non-invasive imaging of scar/fibrosis. 6 Late-gadolinium enhancement can be used for defining myocardial substrate in 3D and potentially identify channels of slow conduction prior to VT ablation. 7 These can be channels between areas of scar core or scar border zone (described as grey zone on LGE-MRI), where there is a mixture of normal and scarred myocardium and associated with slow conduction. 8 In patients with nonischaemic cardiomyopathy with epicardial substrate, where endocardial-only ablation is less likely to be successful, LGE-MRI has been correlated to areas of low epicardial voltage and used to guide epicardial ablation. Real-time MRI-guided EAM and ablation offers an attractive strategy to improve the precision of substrate identification, provide intraprocedural guidance, and facilitate assessment of ablation lesion formation. Previous work in this area has focused on characterizing correlations between MRI and EAM, 10 device tracking (using passive and active catheter tracking), 11 assessment of electrogram fidelity in the magnetic resonance (MR) environment, 12 and lesion evaluation. 13 To date, however, there are no studies evaluating epicardial mapping and ablation under real-time MRI guidance. In this study, we report the feasibility of performing epicardial mapping and ablation under real-time MRI guidance using active catheter tracking in a porcine model.", "qa": [["34_3820653_0_1", "What are the advantages of using magnetic resonance imaging (MRI) for guiding ventricular tachycardia ablation?\n", "MRI provides a 3D visualization of the myocardial substrate, allowing for precise guidance during ventricular tachycardia ablation. It can define areas of scar and identify channels of slow conduction, which can be crucial for successful ablation. Additionally, MRI can be used in real-time to guide epicardial mapping, ablation, and lesion imaging with active catheter tracking, providing accurate and immediate feedback during the procedure."], ["34_3820653_0_2", "How does magnetic resonance-guided electrophysiology (MR-EP) system improve the precision of substrate identification during ablation procedures?\n", "The MR-EP system combines the benefits of MRI and electrophysiology to enhance the precision of substrate identification during ablation procedures. It allows for real-time MRI-guided epicardial mapping, ablation, and lesion imaging with active catheter tracking. This means that the operator can visualize the ablation lesions in real-time using MR-thermometry and dosimetry, ensuring accurate delivery of radiofrequency ablation. The system also enables the assessment of ablation lesions using native T1 mapping and late-gadolinium enhancement (LGE), providing valuable information about the effectiveness of the procedure."], ["34_3820653_0_3", "What are the limitations of using electroanatomical mapping (EAM) for identifying arrhythmogenic myocardium?\n", "Electroanatomical mapping (EAM) has limitations when it comes to identifying arrhythmogenic myocardium. EAM cannot fully interrogate the complex 3D anatomy of scar, and the spatial resolution of voltage-based mapping is limited by various factors. These factors include electrode size, orientation, contact, and the number of points collected. Additionally, electrical criteria for scar annotation may not be universally applicable to pathological scar. In patients with non-ischaemic cardiomyopathy who may have epicardial or intramural scar, EAM is particularly limited in delineating the full 3D geometry of scar."]]}, {"passage_id": "10_7951092_5", "passage": "[20, 55, 56] Some investigators have reported using IDUS rather than fluoroscopy to perform emergent bedside ERCP in critically ill patients. [57] In a small case series by Lee et al., IDUS was used to direct endoscopic biliary stenting by measuring the insertion length of the probe between the major papilla and the lesion to determine the length of the plastic stent. Successful endoscopic biliary drainage was achieved in all nine enrolled patients without complications, and no fluoroscopy was required.\n\n [55] A prospective, single-armed study by Park et al. reported a 100% success rate of IDUS assisted stone removal in 35 patients with CBD stones (median size of 9 mm) without significant immediate or delayed complications. Stones were removed successfully after endoscopic sphincterotomy without biliary radiocontrast injection and only guided by IDUS to confirm the existence and clearance of stones. However, those with larger (\u226520 mm in diameter) or multiple CBD stones were not included in the study. [56] Lim et al. conducted a retrospective study with a larger cohort of 105 patients using IDUS to diagnose and management of extrahepatic biliary disease without the assistance of radiocontrast cholangiography. The technical success, defined by the placement of the US probe into the confluent of left and right hepatic duct, was 100% without significant associated complications. The mean diameter of CBD stones detected on IDUS was 6.4 \u00b1 3.5 mm. A total of 91 (86.6%) enrolled patients underwent biliary drainage, stone removal, bile duct biopsy, or brush cytology following IDUS as a single-step intervention, and most of the patients (82.9%, 87/105) underwent therapeutic procedures without contrast cholangiogram. Fluoroscopy was only used in a small number of patients to assist biliary cannulation (10, 9.5%), stone capture (9, 8.5%), biliary drainage (4, 3.8%), and clearance of remnant stones (8, 7 .6%). [20] Although IDUS-directed endoscopic biliary drainage and stone removal appeared effective and safe in experienced hands in these studies, further investigations are needed to compare its efficacy, feasibility, and safety with traditional radiocontrast cholangiogram-guided endoscopic biliary procedures.\n\n EUS offers the highest resolution of pancreas, allows direct cytopathological diagnosis and cystic fluid analysis through EUS-guided fine-needle aspiration. Therefore, EUS has been recommended as a valuable tool in the diagnosis and management of solid and cystic pancreatic lesions including intraductal papillary mucinous neoplasm (IPMN). [58] [59] [60] [61] The role of IDUS is now mainly on detection the extension of IPMN preoperatively and helps to determine the extent of surgical resection. [62, 63] In a randomized, prospective study, Cheon et al. evaluated forty patients with IPMN who underwent surgical resection. The study results showed that IDUS was more accurate than other imaging modalities (85% vs. 50%, P = 0.018) in preoperative assessment of tumor extension. In five patients with disease recurrence, only one was assessed by IDUS and four by other imaging tests preoperatively. [62] In another retrospective study of 24 patients with branch type IPMN, Kobayashi et al. concluded that the lateral spreading of tumor was associated with the dilation of main pancreatic duct (\u22656 mm) (P < 0.05). IDUS showed a sensitivity, specificity, and accuracy of 92%, 91%, and 92%, respectively, in the assessment of tumor extension along the main pancreatic duct. [63] The usefulness of IDUS also needs to be compared with other methods such as preoperative or intraoperative peroral pancreatoscopy with narrow-band imaging or biopsy which appeared helpful in identifying the occult or skip IPMN lesions, evaluate the resection margin, and modify the surgical plan.\n\n [60, 64, 65] \n\n Endoscopic snare papillectomy for duodenal papilla tumors has been established as an alternative treatment to surgical resection in selected cases. Signs now have been accepted as endoscopic resectable include intraductal extension <1 cm for adenoma, absence of invasion of duodenal muscular propria, pancreas, CBD, and progressive disease (PD) for malignancy. The recent published American Society for Gastrointestinal Endoscopy guideline recommended EUS evaluation for large ampullary lesion before treatment.", "qa": [["10_7951092_5_1", "What are the advantages of using IDUS (Intraductal Ultrasound) in endoscopic biliary drainage and stone removal procedures?\n", "IDUS offers several advantages in endoscopic biliary drainage and stone removal procedures. It allows for direct visualization and measurement of the insertion length of the probe, which helps determine the length of the plastic stent. IDUS can confirm the existence and clearance of stones without the need for biliary radiocontrast injection. It also aids in the diagnosis and management of extrahepatic biliary disease without the assistance of radiocontrast cholangiography. IDUS has shown high technical success rates and low complication rates in these procedures."], ["10_7951092_5_2", "How does IDUS compare to other imaging modalities in the preoperative assessment of tumor extension in intraductal papillary mucinous neoplasm (IPMN)?\n", "IDUS has been found to be more accurate than other imaging modalities in the preoperative assessment of tumor extension in IPMN. In a study evaluating patients with IPMN who underwent surgical resection, IDUS showed higher accuracy (85%) compared to other imaging tests (50%). IDUS has also demonstrated high sensitivity, specificity, and accuracy in assessing tumor extension along the main pancreatic duct in branch type IPMN. It provides valuable information for determining the extent of surgical resection in IPMN cases."], ["10_7951092_5_3", "What signs indicate that endoscopic snare papillectomy is a suitable alternative treatment for duodenal papilla tumors?\n", "Endoscopic snare papillectomy is considered as an alternative treatment to surgical resection for duodenal papilla tumors in selected cases. Signs that indicate endoscopic resectability include intraductal extension less than 1 cm for adenoma, absence of invasion of duodenal muscular propria, pancreas, and common bile duct (CBD), and absence of progressive disease (PD) for malignancy. EUS evaluation is recommended before treatment for large ampullary lesions to assess resectability."]]}, {"passage_id": "86_86849709_0", "passage": "Kabupaten Sumba Barat Daya is one of malaria endemic area on Nusa Tenggara Timur Province. Number of malaria cases in 2015 was 4,622 cases below Kabupaten Lembata with 8,887 cases. Puskesmas Kori has highest API on Kabupaten Sumba Barat Daya with API number 24.5 per mile (Dinas Kesehatan Kabupaten Sumba Barat Daya, 2015) Malaria is affected with environment, climate, vector and the bionomy and community activity followed by N. tabacum and Piper betle with LC 50 value from 124,28 and 95,75; 236,73 and 98,45; 313,58 and 122,99 ppm after 24 and 48 hours (Tennyson, 2012) .\n\n On Nusa Tenggara Timur, the banana plant (A. catechu L.) is widely found around local's houses. Beside being growth as local house vegetation, it is also used by the people as betel chewing complement, yet has not been utilized as bioinsecticide that can be used to control insect population that relatively environtment friendly and untoxic. This research objective is to study the effect of young Areca (A. catechu L.) seed as Anopheles sp biolarvacide on Kabupaten Sumba Barat Daya, Nusa Tenggara Timur Province.\n\n The design is laboratory experimental, using control group with Post test only control group design. The research was conducted for 5 months (March -July 2017). The young areca (A. catechu L.) seed and Anopheles sp. collection was taken place on Kori Village, Kabupaten Sumba Barat Daya, Nusa Tenggara Timur Province. The areca seed extract was processed on SATREPS Institute of Tropical Disease (ITD) Airlangga University laboratory. The test of areca (A. catechu L.) seed extract on Anopheles sp. larva was taken place on Waikabubak R&D Workshop for Animal Sourced Disease Control, Nusa Tenggara Timur Province.\n\n The areca seed taken from Kabupaten Sumba Barat Daya oftenly used by the local for beteling, aged + 2 bulan since flower stage until areca fruit, the rind is green colored and has tender seed structure. It then being cutted and air dried then blended into powder form. 250 gr of areca seed powder was added by 1500 ml 96% etanol (1:6 proportion) and to accelerate the extraction process, the ultrasonic device is operated. The ultrasonic treatment was repeated 3 times 2 minutes each. The result on every treatment was filtred and contained in the bottle to be evaporated. The filtrat obtained then being vaporized with vaccum rotary evaporator on 40\u00baC, speed 70 rpm and pressure 0.7 bar until a condensed extract was obtained. It then being ovened on 40\u00baC temperature for 24 hours. Final product is scaled with analytic weight scale.\n\n The larva used in this research is An. (Kazwaini, 2013) . One of the approach in the effort to control the vector transmitting disease is by preventing direct contact between human and mosquito. The usage of synthetic insecticide (chemical) is widely known as effective, relatively cheap, easy and practical yet has negative effect to environment (Sudrajat, 2010) . The bioinsecticide usage to control the vector is one alternative to reduce the effect of synthetic insecticide (Hasanah, 2012) .\n\n One of the plant that can be used as bioinsecticide to control bugs and pests is areca plant (Areca catechu L.). Areca is palm species vegetating Pacific, Africa and Asia particularly in Indonesia. It contains secondary metabolite such as alcaloid, flavonoid, saponin and tanin. Part of the plant that mostly used for nabati insecticide is the seed since the active ingredient like arekolin kind of flavonoid, able to paralyze and stop breathing on insects is highly found in young areca seed (Eri, 2014 (Misnarni, 2013; Tennyson, 2013) . The capturing or An vagus mosquito was conducted at 6pm to 10pm with aspirator around the cowshed belong to the local resident, mosquito captured is then took to the laboratory at Waikabubak for forced egg and tested.\n\n Toxicity test using the solvent with 7 group of various areca (A.catechu L.) seed extract concentrate, inside separate treatment and control container.", "qa": [["86_86849709_0_1", "What are the risk factors associated with malaria in Kabupaten Sumba Barat Daya?\n", "The risk factors associated with malaria in Kabupaten Sumba Barat Daya include environmental factors, climate conditions, vectors (such as mosquitoes), and community activities. Additionally, the presence of N. tabacum and Piper betle plants in the area may contribute to the spread of malaria."], ["86_86849709_0_2", "How can the young Areca seed be used as a bioinsecticide?\n", "The young Areca seed, found in Kabupaten Sumba Barat Daya, can be used as a bioinsecticide to control insect populations. The seed is processed into powder form and then extracted using ethanol. The resulting extract is condensed and dried to obtain a final product. The active ingredients in the young Areca seed, such as flavonoids, have insect-paralyzing properties and can be effective in controlling bugs and pests."], ["86_86849709_0_3", "What are the advantages of using bioinsecticides over synthetic insecticides for vector control?\n", "Bioinsecticides, such as the Areca seed extract, offer several advantages over synthetic insecticides for vector control. They are relatively environmentally friendly and non-toxic, reducing the negative impact on the environment. Bioinsecticides can be an alternative to synthetic insecticides, which are effective but can have harmful effects. Using bioinsecticides can help mitigate the negative effects of synthetic insecticides while still effectively controlling disease-transmitting vectors."]]}, {"passage_id": "8_1534718_0", "passage": "Chronic pancreatitis stems from relapsing episodes of acute pancreatitis, 1 and is characterized by destruction of acinar tissue, a sustained pancreatic inflammatory response, and fibrosis. 2, 3 Although development of chronic pancreatitis is strongly associated with heavy alcohol consumption, only a small percentage of heavy drinkers actually develop the disease [4] [5] [6] [7] suggesting that other predisposing factors (for example, genetics, environment, injury) must also be present for disease progression. Pancreatitis is responsible for approximately 3500 deaths each year in the USA, 16% of which are due to chronic disease with about half of those deaths due to alcohol. 8 Although the pathophysiology of chronic pancreatitis remains poorly understood, 9 pancreatic stellate cells (PSC) are believed to have a central role in the initiation and progression of the fibrotic response. 10 Under normal circumstances PSC remain quiescent but after pancreatic injury they be-come activated and transition to a myofibroblast-like, alphasmooth muscle actin (a-SMA)-positive cell type that is capable of depositing large quantities of fibrillar collagen in the interstitial spaces. 11, 12 The effects of alcohol exposure on PSC function have been largely deduced from in vitro studies and from analysis of human pathological specimens. Studies of the mechanisms of alcohol on PSC function in vivo remain ambiguous and are confounded by the fact that a good animal model of alcoholic chronic pancreatitis (ACP) does not yet exist. 9, 13 Connective tissue growth factor (CTGF; also known as CCN2) is a member of the CCN family of proteins 14, 15 which associates with components of the extracellular matrix or cell surface integrins 16 and regulates cellular processes such as, adhesion, migration, mitogenesis and differentiation. 15 Although CTGF has an important role in vertebrate development [17] [18] [19] it is weakly expressed in adult connective tissues except during wound healing, tissue regeneration, cancer or fibrosis. 16 A role for CTGF in pancreatic fibrosis was first proposed from studies that showed CTGF overexpression in acute necrotizing pancreatitis 20, 21 and in desmoplastic regions of pancreatic cancer. 22 In in vitro studies, activated PSC have been shown to co-express CTGF, transforming growth factor b-1 (TGF-b1), collagen 1 and other extracellular matrix proteins 23, 24 and to synthesize CTGF after exposure to ethanol or acetaldehyde. 25 However, data showing that CTGF is expressed by activated PSC in ACP in vivo are lacking.\n\n We have produced a rapid and efficient model of ACP in mice that mimics key pathophysiological features of the human form of the disease and which shows that activated PSC are a principal source of CTGF in ethanol-induced pancreatic fibrosis.\n\n All animal procedures were approved by the Institutional Animal Care and Use Committee of The Research Institute at Nationwide Children's Hospital (Columbus, OH). Male C57Bl/6 mice 6-8 weeks old were injected with ethanol (3.2 g/kg; administered in a 33.3% ethanol: 67.7% water solution) i.p. one time per day, six times per week, for 3 weeks. On one day each week, some mice also received an i.p. injection of cerulein every hour for 6 hours. (50 mg/kg; Sigma Chemical Co., St Louis, MI, USA). Control mice received either ethanol alone, cerulein alone, or water alone (n \u00bc 6 per group). Mice were housed three to a cage and fed a low-fat diet ad libitum. Twice weekly, serum samples were collected 1 hour after ethanol administration for assessment of peak blood alcohol levels (BAL). Mice were killed 2 days after the last ethanol treatment and pancreata were removed before fixation in 4% paraformaldehyde (pH 7.2-7.4) or for RNA extraction, as described below.\n\n Blood Alcohol Levels (BAL) Peak BAL were measured using an Ethanol-L3K assay (Diagnostic Chemicals Limited, Oxford, CT, USA). NADH produced in the assay reaction was quantified by measuring absorption at 340 nm with a SpectraMax M2 Microplate Reader (Molecular Devices, Sunnyvale, CA, USA).\n\n Fixed pancreatic tissues were embedded in paraffin, cut into 4 mm sections and stained with haemotoxylin-eosin for standard histological examination. Collagen staining was performed using acidified 0.1% Sirius red F3B (Pfalz & Bauer, Waterbury, CT) as described.", "qa": [["8_1534718_0_1", "What are the potential risk factors for the development of chronic pancreatitis?\n", "While heavy alcohol consumption is strongly associated with the development of chronic pancreatitis, other predisposing factors such as genetics, environment, and injury may also contribute to disease progression."], ["8_1534718_0_2", "What is the role of pancreatic stellate cells (PSC) in the initiation and progression of fibrosis in chronic pancreatitis?\n", "Pancreatic stellate cells (PSC) are believed to have a central role in the initiation and progression of the fibrotic response in chronic pancreatitis. After pancreatic injury, PSC become activated and transition to a myofibroblast-like cell type that is capable of depositing large quantities of collagen in the interstitial spaces."], ["8_1534718_0_3", "What is the role of connective tissue growth factor (CTGF) in pancreatic fibrosis?\n", "Connective tissue growth factor (CTGF) is a protein that regulates cellular processes such as adhesion, migration, mitogenesis, and differentiation. While weakly expressed in adult connective tissues, CTGF is overexpressed in acute necrotizing pancreatitis and in desmoplastic regions of pancreatic cancer. In in vitro studies, activated pancreatic stellate cells (PSC) have been shown to co-express CTGF and synthesize it after exposure to ethanol or acetaldehyde. However, data showing CTGF expression by activated PSC in alcoholic chronic pancreatitis in vivo are lacking."]]}, {"passage_id": "9_16346314_0", "passage": "In the past decade, the field of genomics has rapidly changed and expanded.\n\n 1 With these advancements also come new applications of genomics and genetics to clinical medicine. The information gathered from genetic testing and genome sequencing can reveal a great deal about not only an individual's current health, but his/her future health as well.\n\n 2 This rapid expansion of scientific and medical capacity is accompanied by rapid changes for law and policy making thoughtful regulation essential.\n\n The human genome includes many variations, most of which have no known significance. However, some variants can be the cause of important medical conditions, and for a subset of these, there are useful healthcare interventions, which can be deployed if the genetic variation is recognized. Sometimes, these genetic variations are the specific target of a genetic test. Sometimes, the variations are found incidentally, in a genetic test performed for other purposes, such as pharmacogenomics or preconception screening. 3 In 2013, the American College of Genetic Medicine (ACMG) released recommendations specifying which of these incidental findings should be given to clinicians. 4 The ACMG limited its recommendation to 56 genetic variations, which can result in approximately 24 genetic conditions. Most of these genetic conditions are very rare, with many of the available treatments limited to continued monitoring and increased surveillance for changes in symptomology and/or disease progression. 5 Anya E.R. Prince discusses these issues in her article, 'Prevention for those who can pay: insurance reimbursement of genetic-based preventive interventions in the liminal state between health and disease.'\n\n 6 Prince worries that while many health insurance companies offer coverage for genetic testing, fewer offer coverage for prophylactic measures and treatments for the conditions said testing might reveal.\n\n Lack of such coverage would undermine the policy goals that motivated insurance coverage mandates in the first place, and may perpetuate health disparities. We advance Prince's analysis of this issue by exploring actual coverage in the private health insurance market, which covers 64 per cent of Americans. 7 In particular, we analyse the coverage of two genetic conditions-BRCA and catecholaminergic polymorphic ventricular tachycardia (CPVT)-by reviewing policy documents of commercial health insurance companies, including Cigna, Aetna, Blue Cross Blue Shield, and United Health One. We find that, while genetic testing and consequent treatment is not universally covered, many companies do offer a broad scope of coverage in this area. Prince argues that the Affordable Care Act (ACA) and ACMG tout preventative measures without considering the impact the information can have on individuals who are unable to afford the preventative next steps.\n\n The ACA sought to increase the number of individuals in the U.S.A. with adequate health insurance by creating employer and individual mandates, creating new mechanisms for affordable coverage (health care exchanges), and expanding eligibility for insurance under existing mechanisms (primarily Medicaid). In addition to covering more people, the ACA tried to improve the quality of coverage, imposing caps on cost sharing and mandatory benefit packages. Preventative services are a cornerstone of the ACA, including immunizations, HIV screening, and well-woman visits.\n\n Section 2713 of the ACA requires non-grandfathered group plans as well as insurance offered in the individual or group market to provide coverage for evidence-based services that received a rating of A or B from the United States Preventative Task Force (USPSTF). 9 The ACA instructs that when a recommendation applies to a high-risk population, the recommended service must be covered for individuals within that population if deemed appropriate by a clinician.\n\n 10 Section 2713 also states that additional coverage for services beyond those provided by the USPSTF is not prohibited.\n\n 11 These provisions apply to those genetic tests and subsequent treatments that the USPSTF deems both beneficial and substantially backed by available evidence.\n\n 12 Thus, under the ACA, coverage for certain genetic tests and treatments has increased, although not all of the genetic conditions identified by the ACMG have received the requisite rating of an A or B by the USPSTF to mandate coverage.\n\n There are multiple ways in which a genetic test or subsequent treatment may not be subject to a legal coverage mandate. The plan may be grandfathered, and thus not subject to ACA coverage mandate. Or, the tests may not be recommended by the USPSTF. On the other hand, there are market forces, which shape private health insurance coverage, as well as more general legal principles, such as the contractual requirement for an insurer to cover medically necessary healthcare. Accordingly, we sought to understand whether the coverage gaps hypothesized by Prince actually exist in the real world of health insurance. To test this question, we selected two genetic conditions, which are medically actionable: BRCA and CPVT. 13 The UPSTF has recommended BRCA testing for women with family histories, but it has not made a genetic screening recommendation with regard to CPVT.", "qa": [["9_16346314_0_1", "What are some of the challenges in providing insurance coverage for genetic testing and subsequent treatments?\n", "Providing insurance coverage for genetic testing and subsequent treatments can be challenging due to various factors. One challenge is the limited number of genetic conditions that are covered by insurance companies. The American College of Genetic Medicine (ACMG) has recommended 56 genetic variations that should be given to clinicians, but many of these conditions are rare and have limited treatment options. Additionally, insurance companies may not offer coverage for prophylactic measures and treatments for the conditions revealed by genetic testing. This lack of coverage can undermine the policy goals of insurance coverage mandates and perpetuate health disparities. Furthermore, the Affordable Care Act (ACA) mandates coverage for evidence-based services recommended by the United States Preventative Task Force (USPSTF), but not all genetic conditions identified by the ACMG have received the necessary rating from the USPSTF to mandate coverage."], ["9_16346314_0_2", "How does the Affordable Care Act (ACA) impact insurance coverage for genetic testing and subsequent treatments?\n", "The Affordable Care Act (ACA) has had an impact on insurance coverage for genetic testing and subsequent treatments. The ACA sought to increase the number of individuals with adequate health insurance by creating employer and individual mandates, expanding eligibility for insurance, and improving the quality of coverage. Preventative services, including genetic testing, are a cornerstone of the ACA. Section 2713 of the ACA requires non-grandfathered group plans and insurance offered in the individual or group market to provide coverage for evidence-based services recommended by the USPSTF. However, not all genetic tests and treatments recommended by the ACMG have received the necessary rating from the USPSTF to mandate coverage. Additionally, the ACA allows for additional coverage beyond the USPSTF recommendations."], ["9_16346314_0_3", "How do market forces and legal principles impact insurance coverage for genetic testing and subsequent treatments?\n", "Market forces and legal principles can impact insurance coverage for genetic testing and subsequent treatments. Insurance coverage may not be subject to a legal mandate if the plan is grandfathered or if the tests are not recommended by the USPSTF. However, there are contractual requirements for insurers to cover medically necessary healthcare. The coverage gaps hypothesized by some researchers may not necessarily exist in the real world of health insurance. The availability of coverage for genetic testing and subsequent treatments can vary depending on the specific genetic condition and the insurance company."]]}, {"passage_id": "48_4608387_2", "passage": "Each patient-, treatment-, and facility-level variable was entered alone to predict time to receipt of outpatient rehabilitation services. If the P value was less than .05, then the variable was included in the multivariate model. In the multivariate model, we also included clinically important variables such as age, marital status, amputation level, living location before hospitalization, and discharge location. Backward selection was then used to remove variables 1 at a time to construct the final main effects model in which all P values were less than .05.\n\n The proportional hazards assumption for the Cox regression model was tested to determine whether the HRs remained constant over time. To do this, the interaction between each predictor in the final main effects model and time to receipt of outpatient rehabilitation services was added to the final main effects model. We added all interactions with a P value of less than .05 in the previous step before a final backward selection procedure was conducted to obtain the final model with main effect and interactions. If a variable violated the proportional hazards assumption, it means that the HR for this variable is changing over time, and we chose to show the HRs at some discrete time points during the follow-up period. Specifically, HRs and 95% CIs at 0, 90, 180, 270, and 365 days after discharge from the index surgical stay were calculated. The constant HRs and 95% CIs for the predictors not violating the hazards assumption were reported. All models took into account the correlation among patients from the same facility. This was necessary because patients from the same facility might have correlated outcomes even after adjusting for all the covariates in our dataset. For example, the clinicians from the same facility might have similar approaches to outpatient service use, causing correlations of outcomes within a center after removing the effects of all observed covariates. Accounting for the correlation allows us to obtain the correct variance estimate.\n\n PROC TPHREG in SAS version 9.1 b was used for all time-to-event analyses. P values were 2-sided, with statistical significance at P\u03fd.05 in the final model. Our tables included only the variables that were statistically significantly associated with outpatient use.\n\n There were a total of 2697 veterans (64.75%) with lower extremity amputation who received outpatient rehabilitation services based on clinic stop and provider type codes, while 1468 (35.25%) did not. Among those who received outpatient rehabilitation services, the average time \u03ee SD between discharge from the surgical hospitalization and first visit was 38.3\u03ee54.2 days (see table 2 ). Outpatient services were most commonly initiated by a visit to an amputee clinic. This was the pattern for 66.2% of all veteran amputees with any outpatient services after discharge. Table 3 compares baseline unadjusted characteristics of patients who did and did not receive outpatient rehabilitation services. Only statistically significant associations are shown. After adjusting for patient-, treatment-, and facility-level characteristics, some of these associations are no longer statistically significant. Table 4 shows the patient-, treatment-, and facilitylevel characteristics that remained independently associated with receipt of outpatient services after adjustment. With every 10-year increase in age, the likelihood of receiving outpatient rehabilitation declined (HR\u03ed.83; 95% CI, .80 -.86). Veterans who were married were more likely to receive outpatient services (HR\u03ed1.19; 95% CI, 1.10 -1.29). Those patients who were admitted to the hospital from extended care compared with being transferred from another hospital were less likely to receive outpatient services (HR\u03ed.41; 95% CI, .30 -.56), whereas there was no difference for those admitted from home (P\u03ed.50). Patients with transfemoral or bilateral amputations were less likely to initiate outpatient services than those with a single transtibial amputation (P\u03fd.0001). Patients with comor- There was only a single clinical characteristic that violated the proportional hazards assumption. Thus, the HRs for this variable did not remain constant over time (table 5) . Compared with patients discharged to an extended care facility, the likelihood of receiving outpatient rehabilitation services for those discharged home or to a different location was much higher initially but then declined over time. By 180 days postdischarge, patients discharged home were less likely to initiate outpatient services, and those initially discharged to an extended care facility became more likely to receive outpatient services.\n\n Identification of factors influencing receipt of outpatient rehabilitation services is important for gaining a better understanding of barriers to participation, and hence may enhance survival and quality of remaining life by improving mobility and function. 1, 5 In this observational study, we found that 65% of veterans with a lower extremity amputation received outpatient rehabilitation services.", "qa": [["48_4608387_2_1", "What factors were considered in the multivariate model to predict time to receipt of outpatient rehabilitation services?\n", "The multivariate model included patient-level variables such as age and marital status, as well as treatment-level variables like amputation level and living location before hospitalization. Facility-level variables were also taken into account."], ["48_4608387_2_2", "How was the proportional hazards assumption tested in the Cox regression model?\n", "The interaction between each predictor in the final main effects model and time to receipt of outpatient rehabilitation services was added to the model to test the proportional hazards assumption. If a variable violated the assumption, the hazard ratios (HRs) were shown at specific time points during the follow-up period."], ["48_4608387_2_3", "Why was it necessary to account for the correlation among patients from the same facility in the analysis?\n", "Accounting for the correlation among patients from the same facility was necessary because they might have correlated outcomes even after adjusting for all the covariates. This is because clinicians from the same facility might have similar approaches to outpatient service use, leading to correlations of outcomes within a center. By considering the correlation, the correct variance estimate can be obtained."]]}, {"passage_id": "13_25242222_0", "passage": "Subjective tinnitus can be defined as an auditory perception in the absence of an external sound stimulus, 1 described as a sound like a whistle or a hiss. It is estimated that over 30 million Americans have tinnitus; 2 in Brazil, it is believed that this number is about 28 million. 3 Thus, it is a public health problem.\n\n It is a common-sense conclusion among researchers that symptom severity can lead to losses in quality of life. The lack of control of tinnitus and its constant presence produces a high degree of stress; indeed, the emotional effect is variable and may range from a mild irritation associated with tinnitus, to states of anxiety, depression, and insomnia, even leading to suicide. 4 In patients with tinnitus, it is difficult to make objective measurements of emotional disorders such as anxiety and depression. However, several subjective assessment tools are available in Portuguese, and the Hospital Anxiety and Depression Scale (HADS) 5, 6 is one of the most used instruments, due to its ease of application.\n\n Since tinnitus is a subjective symptom, it is difficult to analyze, measure, and treat. Thus evaluations such as acuphenometry, the use of visual analog scales (VAS), and questionnaires to determine the impact on quality of life such as the Tinnitus Handicap Inventory (THI) 7, 8 are very important strategies, as are individual approaches in the treatment of these patients,.\n\n Among the therapeutic possibilities for sensorineural tinnitus, drug therapy, acupuncture, 9,10 transcranial magnetic stimulation, 11 cognitive-behavioral therapy (CBT), 12 and sound therapy (masking therapy 13 and habituation therapy) can be cited. 4 Some patients try several resources attempting to find a treatment that brings significant relief for their tinnitus.\n\n The process of habituation to tinnitus with the use of sound therapy consists of the stimulation of the ear by the presence of constant sounds, with the aim of reducing hypersensitivity in quiet surroundings. In this process, sound generators, with or without hearing amplification, are used with a neutral sound: music or white noise, at a low intensity in an attempt not to mask tinnitus, but to provide a reduction in its perception. Jastreboff 4 developed Tinnitus Retraining Therapy (TRT) as a habituation therapy that uses counseling and sound therapy. Fractal Tones Therapy 14 uses habituation therapy to reduce tinnitus, through a sound generator that produces fractal sounds (music); in this manner, the melody is maintained but does not repeat itself.\n\n To observe the effectiveness of sound enrichment in tinnitus sensation, minimum masking levels (MML) are used in order to evaluate the effect of masking the perception of tinnitus through the use of a broadband noise. 15 Currently, several protocols have been used for sound therapy; however, reports on the settings used in sound generators of hearing aids were not found in the literature. The aim of this study was to demonstrate the effectiveness of sound therapy with different types of sound generators through patients' follow-up, the relationship of sequential evaluations through previously established parameters (THI, VAS, MML), and the need for individual interventions through detailing the customized settings of these generators in patients unresponsive to previous treatments for tinnitus.\n\n This study was approved by the Ethics Committee under CEP protocol No. 1090/11. Patients were instructed about all procedures of the study and signed an informed consent.\n\n A prospective study of 10 selected patients from the Tinnitus Outpatient Clinic was conducted by the otolaryngologists responsible for this department. For the research, 20 retroauricular behind the ear (BTE) hearing aids with an open fitting were donated to be used by patients bilaterally. Of these 10 patients, five used the Mind 9440 model with fractal sounds (Widex TM ) and five used the Reach 62 Model (Beltone TM ) with white noise. Patients were recruited sequentially from the beginning of the study, alternating the indication of Mind 9 and Reach 62 generators, according to inclusion and exclusion criteria.\n\n Inclusion criteria: continuous chronic tinnitus complaints for over a year without improvement with drug therapies and with no specific treatment for tinnitus for at least 3 months. Hearing loss, when present, was not the main complaint of the patient.\n\n Exclusion criteria: conductive hearing loss or changes in the external and/or middle ear.\n\n During the use of sound generators, these patients were evaluated at the beginning of therapy, and at 1, 3, 6, 9, 12, 15, and 18 months, when the generators were switched off.", "qa": [["13_25242222_0_1", "What are some common treatment options for sensorineural tinnitus?\n", "Some common treatment options for sensorineural tinnitus include drug therapy, acupuncture, transcranial magnetic stimulation, cognitive-behavioral therapy (CBT), and sound therapy (masking therapy and habituation therapy). These treatments aim to reduce the perception and impact of tinnitus on the individual's quality of life."], ["13_25242222_0_2", "How is the effectiveness of sound therapy evaluated in tinnitus patients?\n", "The effectiveness of sound therapy in tinnitus patients can be evaluated through various methods. One approach is to use minimum masking levels (MML) to assess the effect of masking the perception of tinnitus using a broadband noise. Additionally, subjective assessment tools such as the Tinnitus Handicap Inventory (THI) and visual analog scales (VAS) can be used to determine the impact of tinnitus on the patient's quality of life."], ["13_25242222_0_3", "What is Tinnitus Retraining Therapy (TRT) and how does it work?\n", "Tinnitus Retraining Therapy (TRT) is a habituation therapy developed by Jastreboff. It involves counseling and sound therapy to help individuals habituate to their tinnitus. The process aims to reduce hypersensitivity to tinnitus in quiet surroundings by using sound generators that produce constant sounds, such as music or white noise, at a low intensity. The goal is not to mask the tinnitus but to provide a reduction in its perception, ultimately helping the individual cope with and reduce the impact of tinnitus on their daily life."]]}, {"passage_id": "30_79648047_1", "passage": "The thickest labial alveolar bone of root apical is found in proclined group which is 5.75\u00b12.22, and is followed by normal group which is 5.13\u00b11.95, whereas the least can be seen in retroclined group which is 3.63\u00b11.97. Numerical data also show that lingual alveolar bone is the thickest in retroclined group which is 11.08\u00b11.71, and is followed by normal group that is 7.13\u00b11.74. The least is shown by proclined group that is 6.73\u00b11.39. Table IV shows the correlation between inclination and the thickness of labial and lingual alveolar bones in the root apical. The numeric data explains that there is significant relationship between inclination and the thickness of labial and lingual alveolar bones in the root apical where p=0.00, p<0.05. Table V shows that fenestration on the surface of alveolar bone in teeth root of maxillary central incisor are 13 samples in retroclined group and 2 samples in normal group, while proclined group shows no fenestration. Fenestration is more common in retroclined group and more often takes place in the labial alveolar bone. This table shows that there is a significant correlation between teeth inclination and alveolar bone fenestration where p<0.05.\n\n This research also demonstrates that 90% of the normal group and 80% of the retroclined group correlate negatively to the alveolar bone thickness in each level. Proclined group shows 60% positive correlation to alveolar bone thickness in every level.\n\n This study is an observational research employing case series method to identify the correlation between inclination and the thickness of labial and lingual alveolar bone in maxillary central incisor. Subjects of this research are patients coming to RSGMP clinic at FKG USU aged 18-35 years old who have never had orthodontic treatment. The samples are their maxillary central incisor teeth.\n\n A thorough measurement of the thickness of alveolar bone of maxillary central incisor can aid an orthodontist to diagnose and plan the proper treatment to intensify the result. The movement of labial-lingual anterior teeth to increase the relationship between sagittal arch and maxillary mandibular is required in order to achieve harmonious profile. However, excessive teeth movement may result in iatrogenic symptoms including root resorption, gingiva recession, and alveolar bone loss. Apart from aesthetic value, periodontal health and alveolar bone boundaries are important factors in orthodontic treatment.\n\n This research shows that there is a significant correlation between inclination and the thickness of labial and lingual alveolar bone in root apical of maxillary central incisor. The result can be seen in table 4 where p=0.00, p<0.05. This finding confirms the previous study conducted by Zhou et al.\n\n The finding that retroclined maxillary central incisor teeth tend to have thinner labial bone support, especially in root apical area, shows that patients with retroclined incisor teeth need to be carefully treated. The orthodontist must very carefully decide whether to have conventional orthodontic treatment or combined orthodontic treatment in patients who have protruded maxillary with retroclined incisor teeth compensation. If compensated orthodontic is selected for patients with little skeletal discrepancy, the orthodontist must ensure efforts to control anterior teeth jaw torque and to achieve control of root movement. The appropriate teeth torque is also essential to achieve better occlusion, face aesthetics, and stability. Complications may occur if torque is not controlled as expected. In this research, the thickness of labial alveolar bone in maxillary central incisor of retroclined group is 3.63\u00b11.97 and is the smallest number of bone thickness.\n\n The finding of this research shows that incisor teeth in retroclined group have bigger fenestration prevalence which is 13 teeth and dominant fenestrations take place on surface of labial root. Next in line is the normal group with 2 teeth. This finding confirms that of Lou et al. previous study. After fenestration takes place, cortical plate is penetrated, and restoration of perforated area is no longer possible unless there is tooth relapse. Therefore, it is necessary to have thorough evaluation of periodontal bone support in patients with retroclined incisor teeth.", "qa": [["30_79648047_1_1", "What are the potential complications that can occur in orthodontic treatment for patients with retroclined incisor teeth?\n", "Patients with retroclined incisor teeth may experience complications in orthodontic treatment, including root resorption, gingiva recession, and alveolar bone loss. Excessive teeth movement can lead to these iatrogenic symptoms, which can negatively impact periodontal health and the boundaries of the alveolar bone. Therefore, careful consideration and evaluation of periodontal bone support are necessary for patients with retroclined incisor teeth."], ["30_79648047_1_2", "How does the thickness of labial and lingual alveolar bone in the root apical area correlate with teeth inclination in maxillary central incisors?\n", "The research findings indicate a significant correlation between teeth inclination and the thickness of labial and lingual alveolar bone in the root apical area of maxillary central incisors. Retroclined incisor teeth tend to have thinner labial bone support, especially in the root apical area. On the other hand, proclined incisor teeth have thicker labial alveolar bone. This correlation between inclination and alveolar bone thickness is important for orthodontists to consider when diagnosing and planning treatment for patients."], ["30_79648047_1_3", "What is the prevalence of fenestration in the alveolar bone of maxillary central incisors, and where does it predominantly occur?\n", "The research findings show that fenestration, which refers to the presence of perforations in the cortical plate of the alveolar bone, is more common in retroclined incisor teeth. Specifically, 13 teeth in the retroclined group exhibited fenestration, while only 2 teeth in the normal group showed fenestration. The dominant fenestrations occur on the surface of the labial root. Once fenestration occurs, it is not possible to restore the perforated area unless there is tooth relapse. Therefore, thorough evaluation of periodontal bone support is necessary for patients with retroclined incisor teeth to prevent complications associated with fenestration."]]}, {"passage_id": "60_5216194_1", "passage": "[8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] [21] [22] [23] [24] This causes endothelial activation and reduced vascular integrity, release of tissue factor (with associated onset of coagulopathy), and increased nitric oxide levels (with associated hypotension). 25 Thrombocytopenia is most commonly caused by loss of platelets from damaged tissue or more generalised virus induced disseminated intravascular coagulation, where coagulation factors are depleted. 26 Disseminated intravascular coagulation, along with acute hepatic impairment, predisposes the patient to bleeding complications. Other complications of severe disease include acute kidney injury, hepatitis, and pancreatitis. 21 An early antibody response, along with reduced lymphocyte depletion, is associated with effective viral clearance and survival. 16 The development of shock is still not well understood. Many factors may contribute, including bacterial sepsis, possibly through gut translocation of bacteria; a direct effect of the virus; disseminated intravascular coagulation; and haemorrhage. 23\n\n Ebola virus infection is transmitted mainly through close physical contact with infected patients. There is no evidence of a risk of infection before symptoms develop, but late diagnosis delays effective patient isolation, allowing for potential transmission of the infection among contacts. Screening and active case finding are therefore essential to avoid or stop an epidemic.\n\n Early diagnosis hinges on identifying patients who are at risk. Case definitions developed by WHO and the US Centers for Disease Control and Prevention (CDC) are based on a history of exposure and clinical evidence of illness (for example, fever, headache, and myalgia). In the current epidemic areas, history of exposure is now less useful.\n\n Screening ensures the quick identification of potential cases that need immediate isolation and investigation. People who are asymptomatic and have epidemiological risk factors may need to be monitored (for example, twice daily temperature readings) for the duration of the incubation period, depending on their risk of exposure. This ensures rapid recognition of symptoms and immediate isolation.\n\n Contacts of infected patients (including healthcare workers and household contacts) are at risk of infection if they were exposed to the patient's body fluids without protective equipment within the past 21 days. 2 3 Brief interactions, such as walking past a person or moving through a hospital, do not constitute close contact.\n\n Epidemiological risk factors are divided into high risk, some risk, low (but not zero) risk, and no identifiable risk categories.\n\n A contact is defined by WHO as someone who has slept in the same household as a patient; had direct physical contact with the patient during the illness or at the funeral; touched the patient's body fluids, clothes, or bed linens during the illness; or been breast fed by the patient (babies). 27\n\n Boxes 1 and 2 list infection prevention and control measures for healthcare workers and people living in affected areas. If infection is suspected on the basis of initial screening, immediate isolation is warranted before any further investigations. This is crucial to reduce contact with other patients and healthcare workers while the patient is being investigated. Isolation measures should be continued until the patient has tested negative. 28\n\n The highest risk facing healthcare workers when looking after infected patients is inadvertently touching their own faces or neck under the face shield during patient care, and removing (doffing) personal protective equipment (PPE; shown in fig 3\u21d3) .\n\n Healthcare workers should understand the following basic principles of using PPE: Donning-PPE must be donned correctly in the proper order before entering the patient care area. Because PPE cannot be adjusted while in the patient care area, care should be taken to ensure it is as comfortable as possible before entering and that no skin is exposed. Donning activities must be directly observed by a trained observer and a final check performed before entering the patient care area\n\n During patient care-PPE must remain in place and be worn correctly for the duration of exposure to potentially contaminated areas. PPE should not be adjusted during patient care. Healthcare workers should regularly disinfect gloved hands using an alcohol based hand rub or chlorinated water, particularly after handling body fluids. If there is a partial or total breach in PPE (such as gloves separating from sleeves to leave exposed skin, a tear in an outer glove, or a needlestick) during patient care, the healthcare worker must move immediately to the doffing area to assess the exposure and implement the facility exposure plan, if indicated Doffing-Removal of used PPE is a high risk process that requires a structured procedure, a trained observer, and a designated area for removal to ensure protection. PPE must be removed slowly and deliberately in the correct sequence to reduce the possibility of self contamination or other exposure.", "qa": [["60_5216194_1_1", "What are the risk factors for Ebola virus infection?\n", "Risk factors for Ebola virus infection include close physical contact with infected patients, exposure to the patient's body fluids without protective equipment, and direct physical contact with the patient during their illness or at the funeral. Other risk factors include touching the patient's body fluids, clothes, or bed linens during their illness, and being breastfed by the patient (for babies)."], ["60_5216194_1_2", "How can healthcare workers prevent the transmission of Ebola virus?\n", "Healthcare workers can prevent the transmission of Ebola virus by following infection prevention and control measures, such as wearing personal protective equipment (PPE) correctly and consistently. They should don PPE in the proper order before entering the patient care area, ensure it is comfortable and no skin is exposed, and have their donning activities observed by a trained observer. During patient care, PPE should remain in place and be worn correctly, and healthcare workers should regularly disinfect gloved hands. When doffing PPE, it should be removed slowly and deliberately in the correct sequence to reduce the possibility of self-contamination or other exposure."], ["60_5216194_1_3", "What are the complications of severe Ebola virus disease?\n", "Complications of severe Ebola virus disease include endothelial activation and reduced vascular integrity, release of tissue factor leading to coagulopathy, increased nitric oxide levels causing hypotension, thrombocytopenia, acute hepatic impairment, bleeding complications, acute kidney injury, hepatitis, pancreatitis, and shock. Effective viral clearance and survival are associated with an early antibody response and reduced lymphocyte depletion. The development of shock in Ebola virus infection is still not well understood and may be influenced by factors such as bacterial sepsis, direct effects of the virus, disseminated intravascular coagulation, and hemorrhage."]]}, {"passage_id": "10_195261181_5", "passage": "With few exceptions, all tumour samples formed three clusters according to specific marker gene expression levels ( figure 6A ). The three HCC subtypes presented distinct immune cell profiles (figure 6B and C and online figure S20 ). Briefly, subtype 2 samples were characterised by reduced infiltration of lymphocytes, with consequent high frequencies of DCs and natural killer (NK) cells (figures 6C-E and online figure S21). Subtype 3 samples showed high frequencies of Treg cells, Breg cells, and M2-polarised macrophages, all of which are immunosuppressive cells. Subtype 1 samples showed relatively normal T cell infiltration levels, but there were fewer infiltrating B cells, especially Breg cells ( figure 6C and D) . Consistent with these findings, the expression levels of immunosuppressive molecules including PD-1, PD-L1, Tim-3, and CTLA-4 were significantly upregulated in subtype 3 HCC samples (figures 6F and online figure S22 ). In detail, Breg cells showed enhanced expression of PD-L1 and Ki-67; CD8+ T cells expressed more CTLA-4, TIM-3, and PD-1; macrophages demonstrated higher expression levels of PD-L1 and IL-1\u03b2; and Treg cells overexpressed 4-1BB, ICOS, and Ki-67, suggesting more functional and proliferative Treg cells in subtype 3 HCCs. In parallel with the increased frequency of myeloid cells in subtype 2 samples, these monocytes also overexpressed IL-1\u03b2 ( figure 6F) . Moreover, the RNA-seq data revealed that the expression levels of all immune suppressive marker genes (eg, LAG3, PDCD1, HAVCR2, TIGIT, and TNFRSF9) and functional genes (eg, GZMA and GZMB) were upregulated ( figure 6G ). Based on these characteristics, we classified HCC subtypes 1, 2, and 3 as the immunocompetent subtype, immunodeficient subtype, and immunosuppressive subtype, respectively. Importantly, these subtypes were applicable to nearly all HCC lesions from the same patient and from multiple patients, suggesting that interlesional heterogeneity did not alter the classification.\n\n We thus tried to understand the underlying mechanisms by which such distinctive local immune statuses are established in the HCC microenvironment. Because our data suggested that the immunome was better correlated with metabolome than transcriptome and proteome ( figure 4F) , and the differentiation and function of immune cells are largely determined by cell metabolism, 19 we first explored the metabolomic variations among the three HCC subtypes. HCC subtype 3 showed inhibited glycolysis and enhanced mitochondrial respiration, supported by the reduced lactic acid level and increased abundance of metabolites involved in the tricarboxylic acid (TCA) cycle ( figure 7A ). HCC subtype 2 showed increased activity of nucleotide biosynthesis, while subtype 1 was characterised by upregulated flow through the urea cycle. The altered expression levels of enzymes that mediated these metabolic processes were consistent with the changes in the levels of the metabolites. The clustering of differentially expressed RNAs based on the immunophenotypic classification showed marked changes in genes involved in metabolic regulation ( figure 7B and C) . Notably, the enriched KEGG pathways, such as metabolic pathways, oxidative phosphorylation, glyoxylate and dicarboxylate metabolism, and the TCA cycle, were largely consistent with the metabolomic findings.\n\n Infiltrating immune cells are recruited by chemokines and cytokines. We therefore investigated whether there was a characteristic chemokine/cytokine microenvironment in each HCC subtype. The RNA-seq data revealed that the expression levels of all chemokines and cytokines were quite low except that of CCL14 (which is able to recruit monocytes and macrophages) in HCC subtype 2, which is consistent with its immunodeficient figure 7D ). The overexpression of VEGFA and many other genes encoding tumour suppressive chemokines/cytokines (eg, TGFB1, CCL8 and IL10) was observed in HCC subtype 3. Enhanced expression levels of T-cell recruiting molecules such as CXCL9, CXCL10, CXCL11 and CXCL16 were found in both subtypes 1 and 3, in agreement with their abundant T cell infiltration.", "qa": [["10_195261181_5_1", "What are the different immune cell profiles observed in the three subtypes of hepatocellular carcinoma (HCC)?\n", "The three subtypes of HCC have distinct immune cell profiles. Subtype 2 is characterized by reduced infiltration of lymphocytes and higher frequencies of dendritic cells (DCs) and natural killer (NK) cells. Subtype 3 has high frequencies of regulatory T cells (Treg cells), Breg cells, and M2-polarized macrophages, which are immunosuppressive cells. Subtype 1 shows relatively normal T cell infiltration levels but fewer infiltrating B cells, especially Breg cells."], ["10_195261181_5_2", "How do the different HCC subtypes differ in terms of immune suppressive molecules?\n", "The expression levels of immunosuppressive molecules, such as PD-1, PD-L1, Tim-3, and CTLA-4, are significantly upregulated in subtype 3 HCC samples. Breg cells in subtype 3 show enhanced expression of PD-L1 and Ki-67, CD8+ T cells express more CTLA-4, TIM-3, and PD-1, macrophages demonstrate higher expression levels of PD-L1 and IL-1\u03b2, and Treg cells overexpress 4-1BB, ICOS, and Ki-67. These findings suggest that subtype 3 HCCs have more functional and proliferative immunosuppressive cells."], ["10_195261181_5_3", "How do the metabolic profiles differ among the three subtypes of HCC?\n", "The metabolomic variations among the three HCC subtypes show distinct metabolic profiles. HCC subtype 3 shows inhibited glycolysis and enhanced mitochondrial respiration, supported by reduced lactic acid levels and increased abundance of metabolites involved in the tricarboxylic acid (TCA) cycle. HCC subtype 2 shows increased activity of nucleotide biosynthesis, while subtype 1 is characterized by upregulated flow through the urea cycle. The altered expression levels of enzymes involved in these metabolic processes are consistent with the changes in metabolite levels."]]}, {"passage_id": "67_55279626_1", "passage": "The quality of life after surgery is the main problem for these women, their not only physical but also psychic and social state (6, 7) .\n\n The assessment of influence of surgery and socio-demographic agents on anxiety and depression in women with breast cancer was the main objective of this work.\n\n 50 women with breast cancer at age of 30 to 71 years, median 55.5, before and after mastectomy were included to our research. Research was performed in Breast Diseases Ward at the Oncology Center in Bydgoszcz during the period from August 2006 to March 2007. All patients voluntarily approved their participation in the research and completed a questionnaire on their own. Earlier each woman has been informed about objective and rules of research in details as well as was assured about anonymity and personal data protection. 30 women did not give us permission for participation in research.\n\n Universally accepted BECK scale was used in assessment of the level of depression. The scale includes 21 statements assessing at a range of 0 to 3 points. The number of points of 0 to 11 corresponds to the state without depression, from 12 to 26 corresponds to mild depression, from 27 to 49 points corresponds mildsevere depression, whereas the number of points ranged from 50 to 63 points shows very severe depression.\n\n The HAD scale (hospital anxiety and depression scale) was used for assessment of anxiety.\n\n The HAD scale consists seven statements that are assessed at a range of 0 to 3 points and it is related to current patients' state. The total number of obtained points was from 0 to 21 points, where the range of 0 to 7 points means normal level of anxiety, 8 to 10 points means intensified anxiety level and 11 to 21 means high anxiety level. Questionnaire was given patients two times -first time in the day of admission to ward and the next one in the last day of staying in hospital, about four days after surgery.\n\n Approval for conducting of our research has been obtained from Bioethical Board of the Collegium Medicum at Nicolaus Copernicus University in Toru\u0144.\n\n Test 't' for dependent samples was used for assessment of significance of differences between levels of anxiety and depression before and after surgery. Taking value of significance level at a \u00a3 0.05 and if value of 'p' was p > a then mentioned above differences were not statistically significant. The Spearman's test -R (ranks order test) was used for estimation of relationship between the level of feeling anxiety and depression and patients age. Statistical test chi 2 (chi square) was used for estimation relationships between quality variables i.e. education, occupational and social status and obtained results, taking level of significance at a = 0.05 (p=0).\n\n Socio-demographic data is show in tab. 1. The largest group included women at age of 51 to 60 years (36%) whereas women at age below 40 years were smallest group of patients (8%). Most of women had vocational education level, 17 patients (34%) whereas women with higher education level belonged to smallest group of patients, 8 patients (16%). Working women were a largest group of patients, 27 women (54%), the number of unemployed women was only 7 (14%). Depression was not recognized in above half of all patients both before and after surgery, 25 (50%) and 30 (60%) respectively. Whereas one of analyzed patients (2%) had very severe depression before surgery. Women after surgery had significantly lower intensity of depression (p < a) (tab. 2). The numbers of women who felt normal and high level of anxiety before surgery were the same, i.e. 21 (42%) of patients in each group. The high level of anxiety intensity was observed in 15 women (30%). During post-surgery time the intensity of anxiety was significantly lower (p < a) (tab. 2).\n\n The values of rank by points for depression intensity of each individual woman were balanced from 0 to 51 points. The median value of depression intensity before surgery was equal 12 points. The number of points for depression intensity after surgery in individual cases was ranged from 0 to 35 points. The median value of depression intensity after surgery was equal 8 points. Those differences were statistically significant (p<0.05) ( fig. 1) . The values by points for intensity of anxiety before surgery were ranged from 0 to 22 points individually. The median value of intensity of anxiety was equal 9 points. The values by points for intensity of anxiety after surgery for each woman separately were ranged from 0 to 22 points. The median value of intensity of anxiety after surgery was equal 6.5 points. The differences were statistically significant (p<0.05) ( fig.", "qa": [["67_55279626_1_1", "What are the main factors that contribute to the quality of life after breast cancer surgery?\n", "The main factors that contribute to the quality of life after breast cancer surgery include not only physical but also psychological and social aspects. Women may experience changes in their physical appearance, emotional well-being, and social interactions, which can impact their overall quality of life."], ["67_55279626_1_2", "How is the level of depression assessed in women with breast cancer before and after mastectomy?\n", "The level of depression in women with breast cancer before and after mastectomy is assessed using the universally accepted BECK scale. This scale consists of 21 statements that are scored on a range of 0 to 3 points. The total number of points corresponds to different levels of depression, with higher scores indicating more severe depression."], ["67_55279626_1_3", "What is the HAD scale used for in the assessment of women with breast cancer?\n", "The HAD scale, or hospital anxiety and depression scale, is used for the assessment of anxiety in women with breast cancer. It consists of seven statements that are scored on a range of 0 to 3 points. The total number of points obtained indicates the level of anxiety, with higher scores indicating higher levels of anxiety. The HAD scale is administered to patients before and after surgery to evaluate changes in anxiety levels."]]}]