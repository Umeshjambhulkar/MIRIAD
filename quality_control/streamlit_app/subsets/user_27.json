[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "50_207488614_2", "passage": "[12, 22] While the OHSU group reported no significant difference in the fusion rate using rhBMP-2 compared with ICBG, the York group found modest clinical benefits with improvement in fusion rates with BMP. Both studies detailed an increase in the rate of all complications; however, they only reported a statistically significant increase in cancer rates when they compared rhBMP-2 with ICBG. Additionally, they both argued that reports of rhBMP-2 provided by the manufacturer inadequately presented adverse events and appeared to contain serious selective reporting. [12, 22] \n\n It has been suggested that BMPs may be toxic to neural tissue and may incite a vigorous inflammatory response in some patients. [13] After BMP was implanted, some patients reported increased discomfort and pain leading to a concerning rise in incidence of reoperation. A recent study by Crandall et al. reported postoperative nerve damage and cage migration as sources of pain in research (17) sources in their articles, with a few citing companies and businesses (6) and patients and healthcare personnel (6) . Table 4 summarizes the sources of evidence with regard to the specific complications.\n\n Public perception of medical drugs in general is largely influenced by news media publications and reports. The importance of reporting medical news accurately and scientifically is paramount to the public having an educated view on medical drugs and devices. In our current report, we identified notable trends among the news publications with regard to rhBMP-2. In our study, we found that from 2001 to 2005, news publications highlighted the release of BMP and its subsequent FDA approval with over half of these articles not mentioning adverse complications. After 2005, scientific reports of possible adverse events announced by the FDA and other independent researchers were cited by newspapers and by 2008, we found that the over-representation of complications from rhBMP-2 was significantly increased patients. [7] Additionally, they found that complications such as seroma and osteolysis occurred more often at higher doses. [7] Fu et al. noted that BMPs may cause wound complications and bone formation in abnormal sites. [12] In the cervical spine, it was noted that abnormal bone growth can be excessive, blocking the patient airway and causing difficulty swallowing and speaking. [12] These complications of excessive bone formation were the third most frequently mentioned complications in national publications (14%) and fourth in local newspapers (5%).\n\n RE was a prevalent complication reported with the use of BMP bone graft. RE is a condition in men where the internal vesical sphincter muscle at the base of the bladder fails to contract during ejaculation. [25] While in reproductive young males RE could lead to sterility and the need for artificial insemination procedures, the female equivalent to this disorder has not been clinically described. RE was only noted when BMP was implanted in the lumbar spine in ALIF procedures, presumably due to its proximity to the reproductive system and bladder. According to a published report by Lubelski et al., ALIF procedures already poses a high risk of numerous other urological complications, which are further exacerbated by both the inflammatory response potentially associated with rhBMP-2. [15] In their study of two-level ALIF spinal fusion procedures in the lumbar spine region, Carragee et al. reported that the experimental group who had fusions with BMP-2 had 7.2% incidence of RE while it was only reported in 0.6% of patients in the control group. [5] Although RE could be a problematic complication for young men of reproductive age having spinal fusion with BMP in the lumbar spine, our analysis found that this risk was mentioned in 24% of national newspapers and the third most commonly mentioned in local newspaper articles at 14%.\n\n Our analysis found that the risk of cancer was commonly mentioned in 24% of major newspapers (1 st highest, tied with RE) and 14% (1 st highest, tied with inflammation) of local newspaper articles. Not all of the articles listed recognized research publications as cited evidence (<78%). The issue of cancer risk is an especially important one and multiple studies have reported conflicting evidence for this controversial risk.\n\n Carragee et al. demonstrated that patients who were treated with rhBMP-2 were 4-5 times more likely to develop a new malignancy. [4, 11] The study also reported that BMP may fuel existing cancers and its use is only suggested in cases where ICBG is more problematic, especially in older patients. [3] Other studies reported substantial evidence that the risk of cancer is dose-dependent, with higher doses of BMP increasing the risk of new malignancies. [6, 11] Specifically, Caragee et al.", "qa": [["50_207488614_2_1", "What are the reported complications associated with the use of rhBMP-2 in spinal fusion procedures?\n", "The reported complications associated with the use of rhBMP-2 in spinal fusion procedures include an increase in the rate of all complications, with a statistically significant increase in cancer rates compared to ICBG. Other complications mentioned include postoperative nerve damage, cage migration, seroma, osteolysis, abnormal bone growth, and excessive bone formation."], ["50_207488614_2_2", "How has the public perception of rhBMP-2 been influenced by news media publications?\n", "The public perception of rhBMP-2 has been influenced by news media publications. From 2001 to 2005, news publications highlighted the release and FDA approval of BMP, with over half of these articles not mentioning adverse complications. However, after 2005, scientific reports of possible adverse events announced by the FDA and other independent researchers were cited by newspapers, leading to an over-representation of complications from rhBMP-2 in news articles."], ["50_207488614_2_3", "What is the association between the use of rhBMP-2 and the risk of cancer?\n", "Studies have reported conflicting evidence regarding the association between the use of rhBMP-2 and the risk of cancer. Carragee et al. demonstrated that patients treated with rhBMP-2 were 4-5 times more likely to develop a new malignancy. Other studies have reported that the risk of cancer is dose-dependent, with higher doses of BMP increasing the risk of new malignancies. However, it is suggested that the use of rhBMP-2 should be limited to cases where ICBG is more problematic, especially in older patients."]]}, {"passage_id": "58_27899648_0", "passage": "Localized alveolar ridge defects are frequently found in partially edentulous patients that impair proper aesthetic, phonetic, and oral hygiene. [1] [2] [3] These defects are associated with defi cit in volume of bone and soft tissues within the alveolar process resulting from traumatic tooth extraction, advanced periodontal diseases, developmental defects, external trauma and tumors.\n\n ridge deformities into three types according to the vertical and horizontal defect components: [4] 1. Class I defect (Buccolingual loss of tissue contour with a normal apicocoronal height) 2. Class II defect (Apicocoronal loss of tissue with normal buccolingual contour) 3. Class III defect (A combination of buccolingual and apicocoronal loss).\n\n Later, Allen et al. [5] introduced severity as a classifi cation criterion in the evaluation of alveolar deformities. Severity is classifi ed as:\n\n Mild deformity <3 mm, moderate deformity 3-6 mm, and severe deformity >6 mm.\n\n Abrams et al. [6] studied the prevalence of anterior ridge deformities in the mandibular and maxillary arches of partially edentulous patients and reported the presence of defects in 91% of the cases. Class III defects were the most prevalent (55.8%), followed by Class I defects (32.8%) and Class II defects (2.9%).\n\n Over the last decade, advancements and modifi cations in technologies in the fi eld of restorative dentistry and Periodontics have been able to achieve best results to restore form, function and aesthetic of the patient. Reconstructive procedures for the deformed alveolar ridge are guided bone regeneration, bone graft and soft tissue graft placement beneath the fl ap or in pouch made in damaged area. [7, 8] Soft tissue ridge augmentation is a valuable periodontal plastic surgery procedure for correction of ridge defects for aesthetic purposes. Epithelial connective tissue graft, onlay graft, subepithelial connective tissue graft, roll pedicle graft, interpositional graft technique, and combined onlay interpositional graft are the most employed approaches in this scenario. [7] [8] [9] [10] [11] [12] [13] In literature, little data is available about the comparison of subepithelial connective tissue graft in pouch and modifi ed subepithelial connective tissue graft in the treatment of alveolar ridge defects. Therefore, to explore the benefi cial effects of modifi ed subepithelial connective tissue graft over subepithelial connective tissue graft in pouch, if any, in alveolar ridge defects the present study was undertaken.\n\n Forty non-smoker individuals (24 males and 16 females, age between 25 and 55 years) with 40 class III alveolar ridge defects in maxillary anterior region were selected for the study in the Department of Periodontics, Dr. Z. A. Dental College, Aligarh. The study was designed as a randomized, clinical study comparing the alveolar ridge augmentation outcomes using modifi ed connective tissue graft and subepithelial connective graft in pouch. Inclusion criteria for the patients were absence of any systemic and periodontal diseases, not taking any medication, no pregnancy or lactation, not previously treated for periodontal reasons, cause of tooth loss be trauma, congenital missing, and tooth fracture. To be included in the study, each patient had to present <20% plaque (PL+), and bleeding on probing (BOP+) sites. Selected sites were randomly divided by fl ip of coin method in two groups. Group I was treated by modifi ed subepithelial connective tissue graft (combined onlay connective tissue graft), while group II by subepithelial connective graft in pouch method.\n\n After recruitment of the patients, the study protocol, risks, benefi ts, and procedures were explained, and written informed consents were obtained from every patient. All the examinations, treatment, and procedures associated with this study followed the principles according to the Declaration of Helsinki. The study was properly reviewed, and approved by the Ethical Committee of Institute.\n\n Stone casts were prepared at baseline and after 3, and 6 months postoperatively for measuring the dimension of alveolar ridge defects. The extension of the ridge defect was defi ned as distance between the buccal-proximal line angles of both adjacent teeth at the vertical level of the papilla tips. It was measured with an orthodontic caliber (Z\u00fcrcher Model, Medidenta Z\u00fcrich, Swiss), having a division of one tenth of a millimeter.", "qa": [["58_27899648_0_1", "What are the common causes of localized alveolar ridge defects in partially edentulous patients?\n", "Localized alveolar ridge defects in partially edentulous patients can be caused by traumatic tooth extraction, advanced periodontal diseases, developmental defects, external trauma, and tumors."], ["58_27899648_0_2", "How are alveolar ridge deformities classified according to their vertical and horizontal defect components?\n", "Alveolar ridge deformities are classified into three types based on their vertical and horizontal defect components: Class I defect (buccolingual loss of tissue contour with a normal apicocoronal height), Class II defect (apicocoronal loss of tissue with normal buccolingual contour), and Class III defect (a combination of buccolingual and apicocoronal loss)."], ["58_27899648_0_3", "What are the different approaches used in soft tissue ridge augmentation for the correction of ridge defects?\n", "The most employed approaches in soft tissue ridge augmentation for the correction of ridge defects include epithelial connective tissue graft, onlay graft, subepithelial connective tissue graft, roll pedicle graft, interpositional graft technique, and combined onlay interpositional graft."]]}, {"passage_id": "88_132905538_8", "passage": "Increased intake of cherries, omega-3 fatty acids, low fat milk and coffee are also advocated [116] . There was evidence for a non-additive interaction of sugar-sweetened drinks consumption with a urate-associated variant of SLC2A9 for the risk of gout [117] . Alcohol intake with T allele of lipoprotein receptor-related protein 2 gene (LRP2) rs2544390 was reported in determining the risk of hyperuricaemia and gout [118, 119] .\n\n The studies of genetic inheritance of gout and hyperuricaemia provide a lot useful information. More than 40 genetic loci only can explain less than 10% of high uric acid levels in serum. We also need to consider the genetic background in different ethnical populations. The further efforts will be to understand the functional roles of the novel genes in the pathways of uric acid metabolism. The investigation can identify the new pharmacological target for gout and bring new therapeutic tools from preventing to treating gout patients [55] . miRNAs and epigenetic screening are also helpful to identify the regulator elements for potential gout gene's expression.\n\n Microbiome and metabolite factors are also need to be considered when managing gout patients clinically. At the present times, not enough reports have been published in the field. It can be useful to exam the intestinal levels of Bacteroides caccae, Bacteroides xylanisolvens, Faecalibacterium prausnitzii, Bifidobacterium pseudocatenulatum in gout patients. Screening key metabolites in serum may also helpful in clinical management of gout and hyperuricaemia patients.\n\n Total about 10 genetic loci were identified to influence the medications of gout. These loci can be used to predict the drug's response and adverse effects. For\n\n \n\n \n\n Age; gender; geographic residence; other conditions for heart, kidney and liver, allergic history etc \n\n Personalized medicine has made great progress due to the development of the technology in genetic and genomic approaches. The ultimate goal for personal medicine of gout management is to provide the best medical advice and best medical treatment according to conditions of individual patients. The patient conditions including age, gender, ethnic group, life styles, genetic variations for common gout associated genes are important factors for clinical managements. Most importantly the pharmacogenetic loci for the common medications for gout provide useful guidance for individual patients. The developments of miRNA profiling, epigenetics investigation, metabolites screening and microbiota research will make personalized medicine even more in great details for management. It will revolutionize medical cares for gout patients in near future.\n\n \u00a9 2019 The Author(s). Licensee IntechOpen. This chapter is distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/ by/3.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.", "qa": [["88_132905538_8_1", "How can personalized medicine contribute to the management of gout?", "Personalized medicine in the context of gout management aims to provide tailored medical advice and treatment based on individual patient conditions. Factors such as age, gender, ethnic group, lifestyle, and genetic variations for common gout-associated genes play important roles in clinical management. Additionally, pharmacogenetic loci for common gout medications can guide treatment decisions. Advancements in miRNA profiling, epigenetics investigation, metabolite screening, and microbiota research further enhance the potential of personalized medicine in gout management."], ["88_132905538_8_2", "What role do genetic factors play in the development and treatment of gout?", "Genetic inheritance plays a significant role in gout and hyperuricemia. While more than 40 genetic loci have been identified, they can only explain less than 10% of high uric acid levels in serum. Understanding the functional roles of novel genes in uric acid metabolism pathways is a key focus of research. Genetic background in different ethnic populations also needs to be considered. Genetic loci can also influence the response and adverse effects of gout medications, allowing for personalized treatment approaches."], ["88_132905538_8_3", "How can microbiome and metabolite factors be considered in the clinical management of gout?", "Microbiome and metabolite factors are important considerations in the clinical management of gout patients. While there is currently limited research in this field, examining intestinal levels of specific bacteria and screening key metabolites in serum can provide valuable insights. Bacteroides caccae, Bacteroides xylanisolvens, Faecalibacterium prausnitzii, and Bifidobacterium pseudocatenulatum are potential bacteria of interest. Screening metabolites in serum can aid in the clinical management of gout and hyperuricemia patients, contributing to a more comprehensive approach to treatment."]]}, {"passage_id": "47_25046227_1", "passage": "Smoking cessation reduces allcause mortality among individuals aged 60 years, and the relative risk for death decreases with longer smokingcessation duration even among individuals aged 80 years. 19 It is estimated, for example, that smokers between ages 55 and 64 years may gain 4 years of life by quitting smoking. 20 Smoking cessation is also important for reducing chronic disease risk and increasing active life expectancy among older smokers. 21, 22 Among individuals aged 60 years, smoking cessation decreases the risk of acute coronary events and stroke within a few years of quitting. 23 Likewise, smoking cessation among older individuals is associated with improvement in activities of daily living. 22, 24 With respect to lung cancer specifically, it is well documented that smoking is the primary causal factor. 10 Smoking cessation, however, clearly and unequivocally reduces risk of lung cancer. 10, 25 Data from case-control studies demonstrate that former smokers have a 20% to 90% reduction in lung cancer risk compared with current smokers. 10 The reduction in risk is evident within 5 years of smoking cessation and increases with longer smoking abstinence. 10 Smoking cessation also improves lung cancer prognosis and survival. Patients with early stage lung cancer who continue to smoke after diagnosis have an 86% increased risk of recurrence. 26 The 5-year survival rate for patients aged 65 years with early stage nonsmall cell lung cancer who quit smoking is 70% compared with 33% among those who continue smoking; among those aged 65 years who have limited stage small cell lung cancer, the 5-year survival rates for quitters versus smokers are 63% versus 29%, respectively. 26 In the National Lung Cancer Screening Trial, smoking abstinence for 7 years yielded a lung cancer-specific mortality reduction comparable to that produced by annual LDCT screening. 27 The reduction was greater when smoking abstinence was combined with lung screening. 27 There is also suggestive evidence that smoking cessation among lung cancer patients is associated with a better response to chemotherapy, radiotherapy, and surgery. 26, 28, 29 Are Lung Cancer Screening Patients Motivated to Change Their Smoking?\n\n Research on smoking-cessation motivation among older smokers in general is mixed. Some studies report no difference in motivation between smokers older than 50 years and younger smokers. 30 Conversely, other research suggests that older smokers, particularly those aged >65 years, may be less motivated to quit smoking and/or may perceive that smoking cessation has limited health benefit at their age. 31, 32 Although health care use is high among older people, 33 most providers do not offer smokingcessation services, especially to older smokers. 34, 35 A study of Medicare beneficiaries aged >64 years (N 5 346,674) demonstrated that only 50% of these smokers reported that they usually or always received smoking-cessation advice from their health care provider. 33 Approximately 50% of lung cancer screening patients are smokers. 15, [36] [37] [38] [39] Motivation for smoking cessation varies somewhat among this subsample of smokers undergoing lung screening. Among current smokers in the Dutch-Belgian NELSON Lung Cancer Screening Trial, 41% reported no intention to quit smoking. 40 In the United States, however, the subset of lung cancer screening participants who report low motivation to quit smoking is lower. For example, only 13% of smokers reported no motivation to quit smoking in the US National Lung Screening Trial. 41 In smaller US studies of lung cancer screening patients, many smokers were interested in quitting smoking and in receiving smoking-cessation services 42 and reported increased motivation to quit after screening. 32 Two lung cancer screening trials (N 5 313) demonstrated that approximately 2 = 3 of smokers were ready to quit smoking; 25% within the next month and 40% within the next 6 months. 43 Furthermore, 60% of lung cancer screening participants who smoked expressed strong interest in receiving smoking-cessation counseling and nicotine replacement therapy (NRT), and 50% were interested in using the smoking-cessation medication bupropion. 43 In a pilot lung cancer screening study with 55 female smokers, 35% were ready to make changes within the next month; and between 1 = 3 and 1 = 2 of all smokers expressed interest in receiving NRT and other smoking-cessation pharmacotherapies. 44 It is noteworthy that there is some concern that lung cancer screening results might undermine motivation to quit smoking in smokers. For example, smokers may perceive negative screening results as evidence that they are not at risk for lung cancer. 45, 46 There are limited data to support this concern; the relation between screening results and smoking behavior is not well understood. Some findings suggest that motivation to quit smoking does not vary by screening results.", "qa": [["47_25046227_1_1", "What are the benefits of smoking cessation for older individuals?\n", "Smoking cessation has numerous benefits for older individuals. It reduces the risk of acute coronary events, stroke, and lung cancer. It also improves activities of daily living and increases active life expectancy. Quitting smoking can lead to a 20% to 90% reduction in lung cancer risk compared to current smokers. The reduction in risk is evident within 5 years of smoking cessation and increases with longer abstinence. Additionally, smoking cessation improves lung cancer prognosis and survival rates."], ["47_25046227_1_2", "How does smoking cessation affect the mortality rate among individuals aged 60 years and older?\n", "Smoking cessation reduces all-cause mortality among individuals aged 60 years and older. The relative risk for death decreases with longer smoking cessation duration, even among individuals aged 80 years. For example, smokers between ages 55 and 64 years may gain 4 years of life by quitting smoking. Quitting smoking is associated with increased life expectancy and a lower risk of chronic diseases among older smokers."], ["47_25046227_1_3", "What is the motivation for smoking cessation among lung cancer screening patients?\n", "Motivation for smoking cessation varies among lung cancer screening patients. In some studies, a subset of smokers undergoing lung screening reported no intention to quit smoking. However, in other studies, many smokers expressed interest in quitting smoking and receiving smoking-cessation services. Approximately 2/3 of smokers in lung cancer screening trials were ready to quit smoking, with 25% planning to quit within the next month and 40% within the next 6 months. Many lung cancer screening participants who smoked expressed a strong interest in receiving smoking-cessation counseling and medication."]]}, {"passage_id": "2_152199165_6", "passage": "22 Clinical Dementia Rating (CDR) scale 33 : This scale is based on semi-structured interview of the patient and a reliable informant (e.g., caregiver) and characterizes six domains of cognitive and functional performance: memory, orientation, judgment and problem solving, community affairs, home and hobbies, and personal care. It classifies people with dementia into four categories: questionable, mild, moderate and severe. Limitations of the CDR scale include length of time to administer the test (approximately 60-90 minutes) and reliance on clinical judgment and collateral source information. 34 The Washington University Alzheimer's Disease Research Center (ADRC) holds the United States Copyright for the Clinical Dementia Rating (CDR) and associated training materials.\n\n A study evaluated the Mini-Mental State Examination (MMSE) scores onto the Clinical Dementia Rating scale categories in 524 individuals with probably Alzheimer's disease. The MMSE discriminated well between CDR stages questionable (0.5), mild (1), moderate (2) and severe (3) but performed poorly in the separation between CDR stages zero and 0.5. 35 The MMSE range for mild AD (CDR 1) was 21-25, for moderate (CDR score 2) 11-20, and for severe (CDR score 3) less than 10.\n\n There are numerous rating scales that have been used in the assessment and monitoring of patients with Alzheimer's disease. The most common cognitive scales that are used in clinical trials include the MMSE, CDR and ADAS-cog. However, the CDR and the ADAS-cog are lengthy to administer and not practical in a clinical setting. The MMSE is advocated for use in patients with Alzheimer's disease. However, the scale is copyrighted and a license should be obtained prior to the use of this scale. The MoCA, an assessment tool that is used by many clinicians, has not been validated in patients with moderate or severe Alzheimer's disease.\n\n The optimal duration of therapy with cholinesterase inhibitors has not been established, in particular when to discontinue a cholinesterase inhibitor because of a perceived lack of clinical benefit. Duration of treatment during randomized controlled trials has been relatively short, generally ranging from 3-6 months. 29 Although there have been several open-label extension and observational studies that have used enrolled patients for more than one year, since these studies are uncontrolled, their results should be interpreted with caution. 36;37 In the DOMINO (Donepezil and Memantine in Moderate to Severe Alzheimer's Disease) study, patients with moderate-to-severe Alzheimer's disease were treated with donepezil for a minimum of 3 months and then randomized to continue donepezil, stopping donepezil, stopping donepezil and starting memantine, or adding memantine 38 . Patients who continued on the donepezil scored on average 1.9 points higher on a standardized MMSE (minimum clinically important difference 1.4) than patients who had donepezil discontinued (95% CI, 1.3 to 2.5). In a double-blind trial, institutionalized patients (n=40) with moderate to severe Alzheimer's disease and treated with a cholinesterase inhibitor for at least two years were randomized to cholinesterase inhibitor continuation or discontinuation for 8 weeks. 39 There was no significant difference in proportion of patients with global worsening (based on Clinicians' Global Impression of Change scale) in the two groups.\n\n In a retrospective cohort study of nursing home residents (n=178) treated with cholinesterase inhibitor monotherapy, patients who discontinued a cholinesterase inhibitor were significantly more likely than those who continued on the cholinesterase inhibitor to show behavioural worsening, and to exhibit symptoms of repetitive behavior. 40 The decision to discontinue a cholinesterase inhibitor based on perceived lack of efficacy is challenging. In a questionnaire that obtained Canadian clinician's perceptions on discontinuation of a cholinesterase inhibitor, most respondents agreed that progression to a severe stage (i.e., Global Deterioration Scale 7 indicating development of swallowing difficulties) was a trigger to discontinue the medication 41 . However, the MMSE was seen as unhelpful for making decisions about discontinuation.\n\n The Canadian Consensus Conference on the Diagnosis and Treatment of Dementia (2012) indicates that discontinuing cholinesterase inhibitors in patients with moderate to severe Alzheimer's disease may lead to worsening of cognitive function and greater functional impairment as compared with continued therapy.\n\n 14 They suggest that cholinesterase inhibitors be discontinued when:\n\n a. The patient and/or their proxy decision-maker decide to stop after being appraised of the risks and benefits of continuation and discontinuation b. The patient is sufficiently nonadherent with the medication c.", "qa": [["2_152199165_6_1", "What are the limitations of the Clinical Dementia Rating (CDR) scale and why might it not be practical in a clinical setting?", "The CDR scale has limitations such as the length of time required to administer the test (approximately 60-90 minutes) and the reliance on clinical judgment and collateral source information. These factors make it less practical for use in a clinical setting."], ["2_152199165_6_2", "What are the most common cognitive scales used in clinical trials for assessing patients with Alzheimer's disease?", "The most common cognitive scales used in clinical trials for assessing patients with Alzheimer's disease include the Mini-Mental State Examination (MMSE), Clinical Dementia Rating (CDR), and Alzheimer's Disease Assessment Scale-cognitive subscale (ADAS-cog)."], ["2_152199165_6_3", "What factors should be considered when deciding to discontinue a cholinesterase inhibitor in patients with Alzheimer's disease?", "The decision to discontinue a cholinesterase inhibitor in patients with Alzheimer's disease should take into account factors such as the patient and/or their proxy decision-maker's choice after being informed of the risks and benefits, the patient's adherence to the medication, and the stage of the disease. The Canadian Consensus Conference on the Diagnosis and Treatment of Dementia suggests that discontinuing cholinesterase inhibitors in patients with moderate to severe Alzheimer's disease may lead to worsening cognitive function and greater functional impairment."]]}, {"passage_id": "50_28641799_0", "passage": "tion, such as renal disease, vitamin D deficiency or familial hypercalcemia hypocalciuria [3] . NPHPT has generated a considerable scientific interest since its first formal recognition in the Third International Workshop on the Management of Asymptomatic Primary Hyperparathyroidism in 2008 [4] . However, this entity remains incompletely described, particularly regarding its pathophysiology, epidemiology, natural history, and management; although its diagnosis is becoming more common in different clinical settings. NPHPT has been proposed as an early or a mild variety of classical HPT. However, contradictory publications exist for NPHPT evolution to a hypercalcemic HPT [5] [6] [7] , or against this progression in general population [8] . Furthermore, interpretation of the data is biased by the differing definition of NPHPT and the methods used to Introduction \u25bc Traditionally, diagnosis of primary hyperparathyroidism (HPT) is based on the demonstration of high total and/or ionized serum calcium associated with an increased or unsuppressed serum parathyroid hormone (PTH) concentration [1] . However, in the last years, the understanding of HPT has evolved, and it is now characterized as having several distinctive clinical forms [2] . Routine measurement of calcium levels and generalization of PTH determination has led to the identification of a new clinical entity named normocalcemic primary hyperparathyroidism (NPHPT). NPHPT is characterized by persistently normal total and ionized serum calcium concentrations and consistently elevated PTH levels, after ruling out secondary causes of PTH eleva-Normocalcemic and asymptomatic hyperparathyroidism diagnosis are becoming more common. However, their pathophysiology is incompletely known. The aim of the present study was to evaluate the clinical effect of calcium-sensing receptor polymorphism (A986S) in normocalcemic and asymtomatic HPT. Prospective study conducted with 61 consecutive normocalcemic and asymptomatic HPT patients was followed up during a minimum period of 1 year. Secondary causes of hyperparathyroidism were ruled out. Calcium and phosphorus metabolism parameters were evaluated in at least 2 determinations during follow-up to classify as normocalcemic or asymptomatic hyperparathyroidism. Bone mineral density and A986S polymorphism genotype were also analyzed. Thiry-eight patients (62.3 %) had the genotype A986A, and 23 (36.7 %) patients had A986S (20 patients, 32.8 %) or S986S (3 patients, 4.9 %). Age, sex, and genotype distribu-tions were comparable in both normocalcemic and asymptomatic hyperparathyroidism. In normocalcemic patients, S allele genotype was associated to statistically significant higher level of intact PTH: 92.0 (SD 18.5) vs. 110.6 (SD 24.4) pg/ml, p < 0.05; and remained significant after adjustment by multiple linear regression. In asymptomatic hyperparathyroidism, A986A genotype resulted in a statistically significant higher level of intact PTH, alkaline phosphatase and procollagen amino-terminal propeptide; but only serum calcium remained as an independent predictor of serum intact PTH levels after a multiple linear regression. Bone mineral densitometry between genotypes did not show statistically significant differences. A986S polymorphism of CaSR is an independent predictor of PTH level in normocalcemic hyperparathyroidism patients, but not in asymptomatic hyperparathyroidism. More studies are needed to evaluate the effect of other polymorphisms in normocalcemic and asymptomatic hyperparathyroidism.\n\n Endocrine Care exclude secondary hyperparathyroidism. This reflects the lack of evidence about natural history and pathophysiology of NPHPT. Previous studies suggest that NPHPT may be related to target tissue resistance to PTH and modulated by postmenopausal estrogen deficiency [9] . However, this hypothesis has not been further studied. Single nucleotide polymorphism (SNP) in Calcium Sensing Receptor (CaSR) -rs17251221 (A986S) -has been linked to PTH resistance and higher calcium levels in adult women [10, 11] , but its effect has never been studied in mild HPT patients. A986S is localized in exon 7 of the CaSR gene, coding the intracellular domain of the receptor [12] , and it is associated to a relative loss of CaSR function [13] .", "qa": [["50_28641799_0_1", "What are the potential causes of normocalcemic primary hyperparathyroidism (NPHPT)?\n", "The potential causes of normocalcemic primary hyperparathyroidism (NPHPT) are renal disease, vitamin D deficiency, or familial hypercalcemia hypocalciuria. However, the exact pathophysiology of NPHPT is still not fully understood."], ["50_28641799_0_2", "How is normocalcemic primary hyperparathyroidism (NPHPT) diagnosed?\n", "Normocalcemic primary hyperparathyroidism (NPHPT) is diagnosed based on persistently normal total and ionized serum calcium concentrations, along with consistently elevated parathyroid hormone (PTH) levels. Secondary causes of elevated PTH levels must be ruled out."], ["50_28641799_0_3", "What is the role of the calcium-sensing receptor polymorphism (A986S) in normocalcemic and asymptomatic hyperparathyroidism?\n", "The calcium-sensing receptor polymorphism (A986S) has been found to be an independent predictor of parathyroid hormone (PTH) levels in normocalcemic hyperparathyroidism patients. However, its effect on asymptomatic hyperparathyroidism is not significant. Further studies are needed to evaluate the effect of other polymorphisms in normocalcemic and asymptomatic hyperparathyroidism."]]}, {"passage_id": "80_17451531_2", "passage": "Typical spondyloarthropathy features include inflammatory back pain, arthritis, enthesitis, uveitis, dactylitis, psoriasis, inflammatory bowel disease, positive clinical response to NSAIDs, family history of spondyloarthropathy, positive HLA-B27, and elevated CRP [13] . These updated criteria are assisting medical providers in earlier diagnosis and implementation of therapy.\n\n The use of various classification schemes over time to diagnose this subtype of arthritis has made it difficult to discern the natural history of ERA and to target appropriate treatment. Based on recent data, it appears that common theories on the presentation and progression of this disease are not accurate. In the past, axial involvement at diagnosis was felt to be rare while peripheral arthritis and enthesitis were much more commonplace in children [5, 10] . Children with ERA were expected to develop axial involvement only after prolonged inflammation. However, one study showed that 66-75 % of HLA-B27-positive JCA/JRA patients and 70-90 % SEA patients fulfilled the criteria for ankylosing spondylitis 5-10 years after the onset of symptoms [14] .\n\n Newer evidence suggests that axial involvement occurs much earlier. Two distinct phenotypes for ERA, those with predominantly axial or peripheral disease, appear to be emerging, each with a unique presentation, treatment requirement, and prognosis. Patients with axial ERA tend to be older with an average age of onset of 11 years and 4 months, have HLA-B27 positivity (83 %), have hip arthritis along with sacroiliac and lumbar spine symptoms, and more commonly have acute anterior uveitis or inflammatory bowel disease. The peripheral ERA cohort is younger with the average age of 9 years and 8 months, less commonly HLA-B27 positive (49 %), and has more ankle arthritis and enthesitis. The patients with axial disease seem to respond readily to anti-tumor necrosis factor (TNF) medications, a phenomenon also seen repeatedly in the adult literature [15\u2022] . Several studies have shown a lack of efficacy for DMARDs in axial disease [16] [17] [18] . Additionally, there is evidence in the adult literature that while symptoms can be well controlled by anti-TNF agents, radiographic progression may be difficult to halt once initiated [14, 19, 20] . This suggests that there may be a window of opportunity in children to intervene early in ERA to avoid chronic axial complications. However, more research is needed to identify those children in whom early treatment would be beneficial.\n\n Increased utilization of MRI has allowed us to detect silent and early sacroiliac disease, particularly when the MRI is enhanced by contrast [21] . One study suggested that axial involvement can be seen in over half of patients with ERA after 2-3 years of disease and can be seen on MRI in 10 % prior to clinical symptoms [15\u2022] . In most ERA patients, the sacroiliac joints are the first area of axial involvement [6\u2022] . Registry data from the Childhood Arthritis and Rheumatology Research Alliance (CARRA) demonstrated that 28 % of children had sacroiliac inflammation at diagnosis [22\u2022] [24\u2022] . Fifty three (37 %) of the children had sacroiliitis on physical exam or imaging. Eleven of these 53 patients (21 %) had silent disease with no back pain, stiffness, or abnormal exam reported. Inflammation was seen on MRI in 7, in plain radiographs in 8, and on both methods of imaging in 4 [24\u2022] . This is similar to an earlier report that 20 % of JSpA patients have sacroiliitis on MRI despite lack of axial symptoms [25] . Another recent retrospective study revealed that the majority (93 %) of the participating ERA patients had MRI evidence of inflammation in either the sacroiliac joints (78 %), the lumbar spine (67 %), or both (52 %). The average interval between diagnosis and the MRI was 3.8 years [26\u2022\u2022] .\n\n The literature demonstrates an overall poor prognosis for ERA patients. The very nature of ERA with initially vague and sometimes intermittent symptoms as well as the insensitivity of plain films to early inflammatory sacroiliac disease leads to delays in diagnosis and treatment. Prior to the introduction of biologic medications, ERA had an 18 % probability of remission at a median of 16.5 years, which was less than oligoarticular JIA (54 %) and systemic JIA (47 %) [27] . Another study from the prebiologic period reported a remission rate of 44 % at 15.3 years [3] .", "qa": [["80_17451531_2_1", "What are the common features and criteria used to diagnose spondyloarthropathy?\n", "Typical features of spondyloarthropathy include inflammatory back pain, arthritis, enthesitis, uveitis, dactylitis, psoriasis, inflammatory bowel disease, positive clinical response to NSAIDs, family history of spondyloarthropathy, positive HLA-B27, and elevated CRP. These criteria are used by medical providers to assist in the earlier diagnosis and implementation of therapy for spondyloarthropathy."], ["80_17451531_2_2", "How does the presentation and progression of early-onset rheumatoid arthritis (ERA) differ from previous theories?\n", "Previous theories suggested that axial involvement in ERA was rare at diagnosis, while peripheral arthritis and enthesitis were more common in children. However, newer evidence suggests that axial involvement occurs much earlier in ERA. Two distinct phenotypes for ERA are emerging, with some patients having predominantly axial disease and others having peripheral disease. Each phenotype has a unique presentation, treatment requirement, and prognosis."], ["80_17451531_2_3", "What is the role of MRI in detecting sacroiliac disease in ERA patients?\n", "Increased utilization of MRI has allowed for the detection of silent and early sacroiliac disease in ERA patients. MRI can detect axial involvement in over half of patients with ERA after 2-3 years of disease, and it can even be seen in 10% of patients prior to clinical symptoms. The sacroiliac joints are often the first area of axial involvement in ERA, and MRI can reveal inflammation in these joints even in the absence of back pain or abnormal physical exam findings. MRI has shown that a significant percentage of ERA patients have inflammation in the sacroiliac joints and lumbar spine, highlighting the importance of this imaging modality in the diagnosis and monitoring of ERA."]]}, {"passage_id": "56_3409088_0", "passage": "Mary University of London Background There is no trial based evidence on how to improve therapeutic relationships in psychosis. The latter predict enhanced treatment adherence, less severe symptoms, better social functioning and fewer hospitalisations. Previous research has identified a lack of shared understanding in psychiatrist-patient communication in the treatment of psychosis 1 . This often arose in exchanges about psychotic symptoms in the context of mental state assessment. Patients repeatedly attempted to discuss the content and emotional consequences of their hallucinations and delusions, whilst psychiatrists tended to avoid engaging with these concerns in an attempt to avoid disagreement. Currently mental health professionals receive little training specific to how to communicate effectively with patients with psychosis. We developed a training programme based on research findings that psychiatrist-patient shared understanding, assessed by means of psychiatrist 'self-repair', is associated with better relationships. It focusses on: engaging with the patient to acknowledge their distressing experience without an underlying goal of changing the patient's beliefs; acknowledging negative symptoms as protective; working with patients with long standing negative symptoms to set their own, albeit small, treatment goals; and empowering and involving the patient in decisions 2 .The training was novel as it was developed from micro-analysis of psychiatrist-patient communication in previously recorded routine psychiatric encounters. Aims This paper will outline the TEMPO programme communication training for psychiatrists on improving shared understanding and the therapeutic relationship, and present findings from the cluster randomized controlled trial. Methods In a cluster randomized controlled trial in the U.K., 21 psychiatrists were randomized. 97 (51% of those approached) outpatients with schizophrenia/schizoaffective disorder were recruited. 64 (66% of the sample recruited at baseline) were followed up after 5 months. The intervention group received four group and one individualized session. The primary outcome, rated blind, was psychiatrist effort in establishing shared understanding, self-repair. Secondary outcome was the therapeutic relationship. Results Psychiatrists receiving the intervention used 44% more self-repair than the control group (6.4, 95% CI 1.46 to 11.33, p<.011, a large effect) adjusting for baseline self-repair. Psychiatrists rated the therapeutic relationship more positively (0.20, 95%CI 0.03 to 0.37, p=.022, a large effect), as did patients (0.21, 95% CI 0.01 to 0.41, p=.043, a medium effect). Conclusions This is the first study to test an intervention for psychiatrists to enhance communication with patients with psychosis. It suggests that shared understanding, which can be challenging in the treatment of psychosis, can be targeted in training and is important for improving the quality of the communication and the therapeutic relationship.", "qa": [["56_3409088_0_1", "How does the TEMPO program aim to improve the therapeutic relationship between psychiatrists and patients with psychosis?\n", "The TEMPO program focuses on improving shared understanding between psychiatrists and patients with psychosis. It encourages psychiatrists to engage with patients, acknowledge their distressing experiences without trying to change their beliefs, recognize negative symptoms as protective, work with patients to set their own treatment goals, and involve them in decision-making. The program is based on research findings that show shared understanding, assessed through psychiatrist \"self-repair,\" is associated with better relationships."], ["56_3409088_0_2", "What were the primary and secondary outcomes measured in the cluster randomized controlled trial of the TEMPO program?\n", "The primary outcome measured in the trial was psychiatrist effort in establishing shared understanding, assessed through psychiatrist \"self-repair.\" The secondary outcome was the therapeutic relationship between psychiatrists and patients. These outcomes were rated blind, meaning the assessors were unaware of the group assignments."], ["56_3409088_0_3", "What were the results of the cluster randomized controlled trial of the TEMPO program?\n", "Psychiatrists who received the TEMPO program intervention used 44% more self-repair than the control group, indicating a greater effort in establishing shared understanding. Both psychiatrists and patients rated the therapeutic relationship more positively in the intervention group. These findings suggest that the training program can improve communication and the quality of the therapeutic relationship between psychiatrists and patients with psychosis."]]}, {"passage_id": "28_6369638_0", "passage": "Disparities in cancer are well documented among African Americans [1] [2] [3] . African American men have the highest incidence and mortality cancer rates for all sites combined as well as for prostate, lung, colorectal and other cancers. Breast cancer mortality rates are 30% higher for African American women compared with White women despite lower incidence rates [1, 2] . Both incidence and mortality rates for colorectal cancer are higher among African American women than other groups of women [3] . The effective use of social and cultural constructs to communicate about health and health behavior change may be an important step in health disparity reduction.\n\n As suggested by previous authors [4] , a cultural perspective allows us to examine how membership in a specific group influences an aspect of life such as health, including differential health outcomes or 'disparities'. Culturally appropriate communication may provide an important opportunity to address health disparities, but the specific strategies used to realize this potential can take many forms. While there is widespread agreement that communication programs and materials will be more effective when they are 'culturally appropriate' for the populations they serve [5] [6] [7] , little is known about how best to achieve cultural appropriateness.\n\n To help fill this gap, this research examined preferences for presentation of race-specific evidence about colorectal cancer among African American men and women. Focus group interviews elicited participants' thoughts and attitudes and anticipated behavioral response to five strategies for presenting cancer information-general, race specific, disparity, social math and framing ;5-year probability of death or survival. For each of these five strategies, we sought to learn (i) the strengths and weaknesses of presentation formats, (ii) how presentation affected memory for and understanding of the information and (iii) whether men and women might respond differently to evidential statements. If effective, this strategy could prove useful in structuring the presentation of cancer evidence in health promotion campaigns that target African Americans.\n\n Health communication researchers [8, 9] have described five basic approaches currently used to achieve cultural appropriateness in targeted health communications: constituent involving, peripheral, linguistic, sociocultural and evidential. 'Constituent involving' strategies are one of the more straightforward activities to increase cultural competency. This process involves the inclusion of members of the community in intervention activities as advisory board members or intervention staff, whether they are trained as paraprofessionals or act as natural helpers. 'Peripheral' approaches seek to enhance effectiveness of communication by packaging content in colors, fonts, images, photographs or declarative titles (e.g. A magazine for African Americans) likely to appeal to a given group. Previous authors [9] described 'linguistic' strategies as one of the more basic elements of the attempt to make health education programs and materials more culturally sensitive. This strategy makes materials accessible by providing them in the native or dominant language of a group. These materials may be produced for a specific health promotion activity or translations of existing materials. 'Sociocultural' approaches discuss disease in the context of specific social and/or cultural characteristics of the group. The final approach to culturally relevant health education materials uses evidence and is the focus of this paper.\n\n 'Evidential' approaches [8] provide and discuss data specific to a group (e.g. between 1973-92, colorectal cancer in African American men increased 40%). While most evidence used in health promotion is statistical, it need not be. Testimonials and statements related to personal, family or group experience can also be used as a form of evidence. Evidential statements seek to raise awareness, concern and/or perceived personal vulnerability to a health concern by showing that it affects others similar to members of the target audience. Research has suggested that the perception that a problem affects others 'like you' can increase thinking about the problem, the decision to engage in prevention and planning to do so [10] . In a recent review of injury prevention intervention studies conducted among racial or ethnic minority populations, evidential approaches to cultural appropriateness were used less frequently than any of the other four strategies [11] .\n\n Previous research [12] has confirmed the importance of presenting risk factor information when informing men and women age 50 years and over of the risks of colorectal cancer. Presenting risk information increased perceived risk without increasing worry, fear or anxiety. Additional research [13] has explored the presentation of evidence in cancer communications targeting African American and Hispanic women. These authors evaluated response to four risk communication formats. The data seemed to suggest a preference for information about family history and personal risk that was provided in graphic and quantitative forms.\n\n Despite these studies, relatively little is known about African American preferences that influence responses to risk communication formats or health statistics in health promotion programs. To address this issue, one component of the formative research for this African American colorectal cancer education campaign sought to learn from members of the community how best to present statistical forms of evidential statements.", "qa": [["28_6369638_0_1", "How do disparities in cancer affect African Americans, particularly in terms of incidence and mortality rates for different types of cancer?", "Disparities in cancer among African Americans are evident in higher incidence and mortality rates compared to other racial groups. African American men have the highest incidence and mortality rates for various cancers, including prostate, lung, colorectal, and others. African American women also experience higher mortality rates for breast cancer and higher incidence and mortality rates for colorectal cancer compared to other groups."], ["28_6369638_0_2", "How can cultural appropriateness in health communication help address health disparities among African Americans?", "Cultural appropriateness in health communication is seen as an important step in reducing health disparities. By using social and cultural constructs to communicate about health and health behavior change, it becomes possible to address the differential health outcomes or disparities experienced by specific groups, such as African Americans. Strategies for achieving cultural appropriateness include constituent involving, peripheral, linguistic, sociocultural, and evidential approaches."], ["28_6369638_0_3", "What are evidential approaches in health communication, and how can they be used to raise awareness and promote behavior change among African Americans?", "Evidential approaches in health communication involve providing and discussing data specific to a particular group, such as African Americans. This can include statistical evidence, testimonials, or statements related to personal, family, or group experiences. Evidential statements aim to raise awareness, concern, and perceived personal vulnerability to a health concern by showing that it affects others similar to the target audience. Research suggests that perceiving a problem as affecting others \"like you\" can increase engagement in prevention and planning."]]}, {"passage_id": "21_305815_1", "passage": "Additionally, we detected FXR expression in neonatal rat cardiac fibroblasts (NRCFs), another cell type in the heart ( Figure 1D) .\n\n Because activation-induced receptor autoregulation has been reported for FXR in some cell types, we next investigated whether FXR agonist-induced activation would regulate FXR expression in cardiomyocytes. Real-time quantitative PCR indicated that NRVMs activation by either natural (chenodeoxycholic acid, or CDCA) or synthetic (GW4064) FXR activators significantly induced FXR mRNA expression, suggesting the existence of a ligand-mediated auto-activation loop in cardiomyocytes ( Figure 1E and F) . Furthermore, both agonists significantly induced cardiomyocyte expression of the orphan nuclear receptor small heterodimer partner (SHP; NROB2), a well-known FXR target, in cardiomyocytes ( Figure 1E and F).\n\n To initially explore the biological function of FXR in cardiomyocytes, we first examined the effect of FXR agonists upon cellular viability. Graded concentrations of GW4064 and CDCA were added to the medium and incubated for 6 -72 h. Both GW4064 and CDCA reduced cell viability in a concentration-and timedependent manner in NRVMs. At 6 h, almost all concentrations of GW4064 tested had no significant effect upon viability (data not shown). However, a 24 h treatment of NRVMs with 3 or 5 mmol/L GW4064 caused 15.1 or 26.9% reduction in cell viability, respectively, compared with DMSO-treated controls (Supplementary material online, Figure S1 ). Chenodeoxycholic acid, although effective, was less efficient than GW4064 in reducing the viability, with significant effects apparent at concentrations of 75 mmol/L after 24 h. To examine whether the FXR agonistmediated reduction in cell viability resulted from apoptosis, we first employed Hoechst 33258 staining to identify apoptosis. Double-staining with Hoechst for nuclei and phalloidin for sarcomere organization in NRVMs demonstrated GW4064-induced typical apoptosis in a dose-and time-dependent manner ( Figure 2A and B) . For example, apoptotic nuclei were barely detectable (4.3%) after 12 h exposure to 5 mmol/L GW4064, but were evident (15.8%) in the cells after 24 h, and further elevated (29.8%) after 48 h. At 72 h, however, no further increase in apoptotic cells was visible because of the progression of the apoptotic cells to death, resulting in positive staining for Hoechst and propidium iodide, as well as loss of cells from the cover slip (data not shown). Chenodeoxycholic acid also reproducibly induced a similar although less potent apoptotic response than GW4064 ( Figure 2B ). Similar apoptotic responses were elicited in H9c2 cardiomyocytes, but relatively higher concentrations of GW4064 and CDCA were required to induce apoptosis in comparison with NRVMs ( Figure 2C) . To confirm the results of apoptosis from Hoechst 33258 staining, flow cytometric analysis with annexin V -FITC binding and JC-1 labelling was performed, both of which are detectors of early-stage apoptosis. Both GW4064 and CDCA treatment resulted in dose-dependent induction of early apoptosis compared with vehicle-treated NRVMs (Supplementary material online, Figure S2 ). These data strongly suggest that the activation of FXR induces the apoptotic death of cardiomyocytes at both early and later stages.\n\n Alterations of mitochondrial function have been cited as a vital mechanism for apoptotic cell death in many systems. We \n\n Temporal changes in the intra-mitochondrial calcein signal after FXR agonist treatment are shown in Figure 2E . To ensure that the decrease in intra-mitochondrial calcein staining was related to MPTP changes and not non-specific injury to mitochondrial membranes, cells were treated with cyclosporin A (CsA), a known MPTP inhibitor. Cyclosporin A (1 mmol/L) was efficient at inhibiting FXR agonist-induced calcein leakage from mitochondria, confirming the involvement of MPTP mechanism ( Figure 2D, top) .\n\n Mitochondrial dysfunction was further studied in living cells by examining mitochondrial DCm, which was determined in situ using JC-1 in both NRVMs and H9C2 cardiomyocytes. Control cells showed bright, thread-like red-orange fluorescent JC-1 aggregates within mitochondria, representing normally hyperpolarized membrane potential ( Figure 2D, bottom) .", "qa": [["21_305815_1_1", "What is the role of FXR in cardiomyocytes?\n", "FXR, or farnesoid X receptor, is expressed in cardiomyocytes and can be activated by natural or synthetic FXR agonists. Activation of FXR in cardiomyocytes induces FXR mRNA expression and the expression of the orphan nuclear receptor small heterodimer partner (SHP), which is a known FXR target. FXR activation in cardiomyocytes has been shown to have an effect on cellular viability, reducing cell viability in a concentration- and time-dependent manner. It can also induce apoptosis in cardiomyocytes, leading to apoptotic cell death at both early and later stages. Additionally, FXR activation can cause alterations in mitochondrial function, including changes in mitochondrial permeability transition pore (MPTP) and mitochondrial membrane potential."], ["21_305815_1_2", "How do FXR agonists affect cell viability in cardiomyocytes?\n", "FXR agonists, such as GW4064 and chenodeoxycholic acid (CDCA), have been shown to reduce cell viability in cardiomyocytes. The reduction in cell viability is concentration- and time-dependent, with higher concentrations of GW4064 and CDCA causing a greater reduction in cell viability. The mechanism by which FXR agonists reduce cell viability is through the induction of apoptosis. Apoptotic nuclei can be detected in cardiomyocytes after exposure to FXR agonists, and flow cytometric analysis confirms the induction of early-stage apoptosis. These findings suggest that the activation of FXR leads to apoptotic cell death in cardiomyocytes."], ["21_305815_1_3", "How does FXR activation affect mitochondrial function in cardiomyocytes?\n", "FXR activation has been shown to cause alterations in mitochondrial function in cardiomyocytes. One mechanism by which FXR agonists affect mitochondrial function is through changes in mitochondrial permeability transition pore (MPTP). FXR agonist-induced calcein leakage from mitochondria, which is related to MPTP changes, can be inhibited by cyclosporin A, a known MPTP inhibitor. Additionally, FXR activation can affect mitochondrial membrane potential, as indicated by changes in the fluorescent JC-1 aggregates within mitochondria. These findings suggest that FXR activation can lead to mitochondrial dysfunction in cardiomyocytes."]]}, {"passage_id": "80_14392808_1", "passage": "The importance of proper quality management in test evaluation, method validation, and smart implementation, as well as coordinated training requirements before use, cannot be overstressed for these POC devices to be effective.\n\n Testing for HIV at the POC has changed the landscape of surveillance in endemic settings. The low-cost, flexible transport and storage requirements, and the lack of a need for well-trained laboratory technicians have greatly aided in their successful implementation [13] [14] [15] [16] . With the decentralization of health care workers (HCWs) in RLS, mobility transfers and staff turn over issues, increasing visibility of counselors coupled with less-trained individuals performing RDT, adequate training, supervision and assessment will be imperative for proper sample collection, analysis, and interpretation. HCW will require initial clinician oversight, and regular structured follow-up assessment, to ensure that highquality specimens are being collected, credible testing performed, and any training gaps correctly identified and timely addressed. Clear SOPs illustrating the stepwise technique for collection of specimens should be implemented at each site (e.g., finger-stick blood versus whole blood or interstitial fluid). Reassessment of RDT procedures will ensure highquality blood specimens are being collected, positive patient-HCW interactions reinforced, and pain minimized. This will be very important for pediatric populations and will aid in increasing numbers tested and patient retention, if patients have a favorable view of HIV testing and community HCW.\n\n Currently, there are seven FDA-approved HIV RDT on the market; however many more products are approved by other regulatory agencies and are currently in use [13, 19, 20] . Due to high prevalence of HIV in certain settings, employing accurate HIV RDT is not only important in patient care but also in program efficiency. As mentioned before, with a high test volume, a mere 0.5% error rate among 10 million people screened would result in 50,000 patients misdiagnosed (false-positive or false-negative).\n\n Performance evaluation of RDT is oftentimes overlooked before implementation in endemic settings. The CDC and WHO have made great strides in supporting performance evaluation of HIV RDT in specific regions, so that Ministries of Health can roll out approved products [19, 21] . The performance characteristics of RDT in HIV-endemic settings, unfortunately, are less straightforward than what appears true with CD4 tools. Diverse HIV-1 and HIV-2 subtypes circulating regionally, as well as within patient recombinant and dual infections, all affect the performance of HIV RDT [13, 14] . Most HIV RDTs are based on antigens from HIV-1 subtype B, thus it is important to evaluate their performance based on the coating antigen and with respect to circulating subtypes [13] . One study evaluating OraQuick HIV-1/2 (OraSure Technologies, Inc., Bethlehem, PA) RDT on stored specimens from a blood bank in Kinshasa, Democratic Republic of Congo (DRC), reported 100% specificity and sensitivity among 72 known HIV-positive, non-subtype-Bconfirmed specimens [22] . It will be important in the future for such controlled performance evaluations to ensue elsewhere in sub-Saharan African settings.\n\n Studies have shown that poor performance is still encountered using approved RDT testing algorithms. Poor sensitivity and specificity has been demonstrated in controlled Journal of Tropical Medicine 3 performance evaluations in Uganda [15, 16] , the DRC [17] , Ethiopia [23] , and Cameroon [24] . In Uganda and the DRC, performance evaluations have demonstrated weak-positive bands with some RDTs, notably the Determine HIV 1/2 RDT (Determine; Abbott Laboratories, Germany) [15] [16] [17] . In Uganda, when weak-positive bands were included in performance evaluation, as per manufacturer's instructions, the test had low specificity (94.1%) and a low PPV (74.0%). Exclusion of the 37 samples (5.8%) with a weak-positive band improved the specificity (99.6%) and positive predictive value (97.7%) compared to EIA and Western blot (WB). In the DRC study [17] , a high number of false-positive results, due to inclusion of weak-positive bands, was discovered when compared to WB and p24 EIA (Immunocomb Conbfirm HIV-1/2-antibody, Orgenics, Yavne, Israel).\n\n In a subsequent evaluation in the same Ugandan population [16] , Determine was reevaluated, as were four new commercially available RDTs: Uni-Gold HIV (1/2) (UniGold; Trinity [24] .", "qa": [["80_14392808_1_1", "What are the challenges associated with implementing point-of-care HIV testing in resource-limited settings?\n", "The challenges associated with implementing point-of-care HIV testing in resource-limited settings include the need for proper quality management in test evaluation, method validation, and smart implementation. Coordinated training requirements before use are also important to ensure effective use of these devices. Additionally, the decentralization of healthcare workers, mobility transfers, and staff turnover issues can pose challenges in maintaining proper training, supervision, and assessment for sample collection, analysis, and interpretation. Clear standard operating procedures (SOPs) should be implemented at each site to ensure proper specimen collection techniques. Reassessment of rapid diagnostic test (RDT) procedures is necessary to ensure high-quality blood specimens are being collected and to reinforce positive patient-healthcare worker interactions."], ["80_14392808_1_2", "How does the performance of HIV rapid diagnostic tests (RDTs) vary in different regions and settings?\n", "The performance of HIV rapid diagnostic tests (RDTs) can vary in different regions and settings due to factors such as the diversity of HIV-1 and HIV-2 subtypes circulating regionally, as well as within patient recombinant and dual infections. Most HIV RDTs are based on antigens from HIV-1 subtype B, so it is important to evaluate their performance based on the coating antigen and with respect to circulating subtypes. Studies have shown that poor sensitivity and specificity have been demonstrated in controlled performance evaluations in various countries, including Uganda, the Democratic Republic of Congo (DRC), Ethiopia, and Cameroon. Weak-positive bands with some RDTs have been observed, leading to low specificity and positive predictive value. It is important to conduct controlled performance evaluations in different settings to ensure accurate and reliable HIV testing."], ["80_14392808_1_3", "What are the potential consequences of using HIV rapid diagnostic tests with high error rates in high-prevalence settings?\n", "Using HIV rapid diagnostic tests (RDTs) with high error rates in high-prevalence settings can have significant consequences. For example, with a high test volume, even a small error rate can result in a large number of patients being misdiagnosed. If 0.5% error rate is present among 10 million people screened, it would lead to 50,000 patients being misdiagnosed as false-positive or false-negative. This can have serious implications for patient care and program efficiency. Therefore, employing accurate HIV RDTs is crucial in order to ensure proper diagnosis and appropriate management of HIV in high-prevalence settings."]]}, {"passage_id": "60_72900638_0", "passage": "Congenital mesoblastic nephroma (CMN) is the most common solid renal tumor found in fetuses and neonates. It can be detected using sonography and magnetic resonance imaging (MRI). This unilateral tumor has a wide spectrum of sonographic characteristics. It can appear either hyperechoic or isoechoic in comparison to the renal parenchyma and is usually heterogeneous in echotexture. Due to its varying appearance, it is difficult to sonographically distinguish this neoplasm from Wilms tumor. Wilms tumor is the most common type of renal malignancy in children. Other pathologies to be considered include angiomyolipoma, focal renal hypertrophy, renal cell carcinoma, nephroblastomatosis (a precursor to Wilms), and nephrogenic adenofibroma.\n\n A review of the current literature on CMN will aid physicians and sonographers because its analysis will provide a set of guidelines for discriminating renal masses in utero. We discuss the pathogenesis of congenital mesoblastic nephroma\n\n Congenital mesoblastic nephroma accounts for 75% of all tumors identified in the first six months of life. It is the most common renal neoplasm seen in young infants. It can be identified in children, adolescents, and, rarely, in the adult. CMN is also known as leiomatous hamartoma, fetal renal hamartoma, mesenchymal hamartoma, Bolande's tumor, and congenital fibrosarcoma. 1, 2 The mass usually occurs unilaterally and has a male to female ratio of 1:1. 3 There is no evidence of ethnic influ-ence on the occurrence of CMN, nor is there any hereditary-linked evidence.\n\n CMN is most often identified late in the third trimester of pregnancy. The earliest reported diagnosis of this neoplasm was in the 26th week of gestation. Consideration of gestational age is important when assessing for possible CMN.\n\n Lymphoma, leukemia, and neuroblastoma have been associated with CMN. There is also an increased risk of this neoplasm in patients with Beckwith-Wiedemann syndrome as well as in fetuses with chromosomal abnormalities.\n\n CMN typically presents as a solid mass with cystic areas of necrosis in the center. Figures 1 through 3 show a heterogeneous renal mass arising from the kidney. It is often isoechoic in comparison to the renal parenchyma; however, this lesion can appear hypoechoic or hyperechoic relative to the cortex and can arise from any area of the kidney. This lesion is not encapsulated, but it tends to be well circumscribed. Figures 4 and 5 illustrate the classic sonographic characteristics of CMN. With the use of color or power Doppler, a vascular \"ring\" will illuminate the borders of the mass. It may also demonstrate arteriovenous shunting. 2 MRI may be used prenatally and postnatally to delineate the borders of the mass and provide clear, accurate measurements of the mass. As with any lesion, the presence of enlarged or inflamed lymph nodes in the surrounding area may be suggestive of malignancy. When any mass is detected, scanning the adjacent area for abnormalities is crucial.\n\n Prenatally, this lesion can be fatal if the mass compresses the lungs, resulting in pulmonary hypoplasia. Polyhydramnios is common due to increased urine production from renal hyperfusion as well as decreased gastrointestinal uptake of amniotic fluid due to bowel compression. 4 Hydrops has also been documented with CMN as a result of high cardiac output failure.\n\n Postnatally, patients with CMN most commonly present with a unilateral palpable abdominal mass with distortion of renal parenchyma and/or adjacent anatomy, such as the adrenal gland, liver, bowel, spleen, or diaphragm. Hypercalcemia, hypertension, and elevated plasma total renin concentration (PTRC) are commonly seen in neonates.\n\n These laboratory values have both been reported to return back to normal levels once treatment has begun and the neoplasm is removed. 5 The most significant primary differential diagnosis, Wilms tumor, is nearly indistinguishable from CMN with sonography. Wilms tumors are the most common renal tumor in children one year or older, and there have been very few reported cases of Wilms tumor diagnosed perinatally. 6,7 CMN is therefore more likely to be diagnosed in children younger than a year old.\n\n Curative treatment usually consists of postnatal complete or partial nephrectomy of the affected kidney. Although it is a benign lesion, CMN can involve the renal parenchyma, perinephric tissue, or adjacent adrenal gland. Therefore, careful examination to determine the extent of the mass is necessary.", "qa": [["60_72900638_0_1", "What are the common sonographic characteristics of congenital mesoblastic nephroma (CMN) and how does it differ from other renal masses?\n", "Congenital mesoblastic nephroma (CMN) typically presents as a solid mass with cystic areas of necrosis in the center. It can appear either hyperechoic or isoechoic in comparison to the renal parenchyma and is usually heterogeneous in echotexture. CMN is often isoechoic in comparison to the renal parenchyma, but it can also appear hypoechoic or hyperechoic relative to the cortex. It is not encapsulated but tends to be well circumscribed. Color or power Doppler can be used to identify a vascular \"ring\" around the borders of the mass, and it may demonstrate arteriovenous shunting. Other renal masses that should be considered as differential diagnoses include Wilms tumor, angiomyolipoma, focal renal hypertrophy, renal cell carcinoma, nephroblastomatosis, and nephrogenic adenofibroma."], ["60_72900638_0_2", "What are the risk factors associated with congenital mesoblastic nephroma (CMN)?\n", "There is an increased risk of CMN in patients with Beckwith-Wiedemann syndrome as well as in fetuses with chromosomal abnormalities. CMN has also been associated with lymphoma, leukemia, and neuroblastoma. However, there is no evidence of ethnic influence or hereditary-linked evidence for the occurrence of CMN."], ["60_72900638_0_3", "What are the common clinical presentations and laboratory findings in patients with congenital mesoblastic nephroma (CMN)?\n", "Postnatally, patients with CMN most commonly present with a unilateral palpable abdominal mass that can cause distortion of renal parenchyma and/or adjacent anatomy, such as the adrenal gland, liver, bowel, spleen, or diaphragm. Hypercalcemia, hypertension, and elevated plasma total renin concentration (PTRC) are commonly seen in neonates with CMN. These laboratory values have been reported to return back to normal levels once treatment has begun and the neoplasm is removed."]]}, {"passage_id": "45_16122545_0", "passage": "In the early 1980s, the development of shock wave lithotripsy (SWL) changed the therapeutic modalities for urinary stones [1] . The AUA/EAU Ureteral Stones Guideline Panel reported that the stone free rate for both SWL and ureteroscopy (URS) when treating proximal ureteral stones is around 81%. The rate for stones >10 mm decreased to 68% and 79% if they were treated by SWL and URS respectively [2] .\n\n URS has traditionally constituted the favored approach for the surgical treatment of mid and distal ureteral stones while SWL has been preferred for the less accessible proximal ureteral stones. With the development of smaller caliber semirigid and flexible ureteroscopes and the introduction of improved instrumentation, including the holmium: YAG laser, URS has evolved into a safer and more efficacious modality for treatment of stones in all locations in the ureter with increasing experience worldwide [3, 4] . Complication rates, most notably ureteral perforation rates, have been reduced to less than 5%, and long-term complications such as stricture formation occur with an incidence of 2% or less. Overall stone-free rates are remarkably high at 81% to 94% depending on stone location, with the vast majority of patients rendered stone free in a single procedure [2] .\n\n Moreover, impacted ureteral calculi are more difficult to fragment with SWL because of the lack of natural expansion space for the stones in the ureter, this result in a situation that is better managed by ureteroscopy [5] [6] [7] . Advances in endoscope design and the development of intracorporeal lithotripsy devices such as the Swiss lithoclast and holmium:YAG laser made the endoscopic treatment of any ureteral stone a possibility [8] [9] [10] .\n\n In this study we aimed at evaluation of the results of our management of the impacted upper ureteral stones using the semirigid ureteroscopes and pneumatic lithotripsy.\n\n Retrospective analysis of the data of 267 patients (218 males and 49 females; age range 18 to 69) who presented to urology department, Assiut university hospital, between April 2001 and April 2007 complaining of loin pain due to impacted upper ureteral stones (severely adherent or causing sever ureteral wall edema) was done. The patients had previous medical treatment for more than 1 month and 56 of them had at least one failed trial of SWL.\n\n Among the patients, 6 were 24-28 weeks pregnant females (who preferred ureteroscopy than percutaneous nephrostomy for such a long period till delivery), and 10 showed liver impairment (prothrombin concentration below 60%). The pregnant females were evaluated by US and MRU.\n\n The patients had a single stone in 236 (88.4%) and multiple stones in 31 cases (2 stones in 30 and 3 stones in one). The stone length ranged from 9 to 20 mm with a mean of 12.4 mm (70% <15 mm and 30% \u2265 15 mm); all were impacted in the upper ureter; 12 stones (4.5%) opposite L2, 20 (7.5%) opposite L3, 75 stones (28%) opposite L4 and 160 stones (60%) opposite L5.\n\n All patients had spinal anesthesia (except 9 patients who had general anesthesia), were put in a mild telendenberg's position then given IV furesamide 40 mg to guard against stone migration after disimpaction during pneumatic disintegration.\n\n The operation started by identification of the ureteral orifice and retrograde ureterography. A trial to gently advance a safety floppy tip 0.035 inch guide wire past the stone was done. Whether the wire passed the stone or not, we dilated of the ureteral orifice till 12 ch. then URS using R. Wolf long ureteroscope (8.5 ch. Tip) was done until the stone was reached.\n\n Disintegration using the Swiss pneumatic lithoclast was done and the stone gravels were retrieved using Dormia basket, but in case of smaller gravels a grasper was used to ensure removal of all sizable gravels. At the end of the maneuver ureterography is done to exclude perforation. In case of the pregnant females, x ray wasn't used.\n\n A DJ stent was applied for 6 weeks (until delivery in the pregnant females). Three months after its removal, x ray and ultrasound were done to ensure the stone free state and to evaluate the resolution of hydronephrosis.", "qa": [["45_16122545_0_1", "How has the development of shock wave lithotripsy (SWL) and ureteroscopy (URS) changed the therapeutic modalities for urinary stones?", "The development of SWL and URS in the early 1980s revolutionized the treatment of urinary stones. SWL and URS have become the preferred approaches for treating different types of ureteral stones based on their location. SWL is commonly used for proximal ureteral stones, while URS is favored for mid and distal ureteral stones. With advancements in technology and instrumentation, URS has become safer and more effective, with high stone-free rates and reduced complication rates."], ["45_16122545_0_2", "What are the advantages of ureteroscopy (URS) over shock wave lithotripsy (SWL) for the treatment of impacted ureteral calculi?", "Impacted ureteral calculi are more challenging to fragment with SWL due to the lack of natural expansion space in the ureter. URS, on the other hand, offers several advantages for the treatment of impacted stones. Advances in endoscope design and the development of intracorporeal lithotripsy devices, such as the Swiss lithoclast and holmium:YAG laser, have made URS a viable option for any ureteral stone. URS allows for direct visualization and precise targeting of the stone, making it more effective in fragmenting impacted stones compared to SWL."], ["45_16122545_0_3", "What are the key considerations and techniques involved in the management of impacted upper ureteral stones using semirigid ureteroscopes and pneumatic lithotripsy?", "The management of impacted upper ureteral stones using semirigid ureteroscopes and pneumatic lithotripsy involves several key considerations and techniques. The procedure typically starts with the identification of the ureteral orifice and retrograde ureterography. A safety floppy tip guide wire is then advanced past the stone, followed by dilation of the ureteral orifice. URS using a long ureteroscope is performed to reach the stone, and disintegration using the Swiss pneumatic lithoclast is carried out. Stone gravels are retrieved using a Dormia basket or grasper, and ureterography is done to check for perforation. In some cases, a DJ stent is applied for a specific duration, and follow-up imaging is performed to ensure stone-free status and evaluate the resolution of hydronephrosis."]]}, {"passage_id": "80_28945100_5", "passage": "Optic nerve sheath haemorrhage is, in their opinion, the result of angular, rotational, or axial movement of the eye about a point in the most anterior part of the optic nerve, posterior to the sclera.\n\n Our hypothesis is based on clinical evidence of similar cases such as choroidoretinal haemorrhages in road accidents (whiplash lesion with and without seat belts).\n\n Therefore, we agree with Green et al about the importance of choroidoretinal haemorrhages as alarm signs for cerebral haemorrhages, but we would like to point out the medicolegal importance of the ocular lesions without other complications, for suspecting a battered child syndrome, otherwise diYcult or impossible to diagnose. We suggest, therefore, that an accurate ophthalmoscopic examination should be mandatory in those cases. GIOVANNI Reply EDITOR,-The meticulous work of Green et al 1 has provided an important insight into the mechanisms responsible for the ocular signs in fatal non-accidental injury (NAI). While vitreous traction is likely to be a major factor in the pathogenesis of intraocular pathology, such as retinal detachment, there is indirect evidence that intravascular perfusion changes contribute to the characteristic intraretinal and preretinal haemorrhages. Firstly, haemorrhages of the same appearance and distribution as in NAI, often with vitreous haemorrhages, occur as a result of an acute rise in intracranial pressure (ICP). These signs may be seen in subarachnoid haemorrhage (Terson's syndrome) and with an acute cerebral venous sinus thrombosis. Retinal haemorrhages are thought to occur in these cases because blood flow is occluded in the central retinal vein by the acute rise in ICP as the vein traverses the subarachnoid space in the optic nerve sheath. Flow continues in the central retinal artery, rupturing the preretinal capillary plexuses. 2 An analogous acute rise in central retinal venous pressure may occur in shaking injuries in children. In these cases there is often evidence from ribcage bruising that the child has been gripped around the thorax, preventing venous return while cardiac output continues. This mechanism is thought to explain the occurrence of retinal haemorrhages with prolonged retching or vomiting. Moreover, intracranial pressure may rise acutely in NAI as a result of subarachnoid haemorrhage. Other causes of retinal haemorrhages associated with raised retinal venous pressure include asphyxia and epileptic fits. 3 Secondly, in acute central retinal vein occlusion, which is usually due to a localised vascular event, deep retinal haemorrhages extending to the periphery are seen. A similar pattern is seen in NAI suggesting a common mechanism via perfusion/pressure changes within the central retinal vein.\n\n We suggest that while vitreous traction forces, as a result of vitreous inertia, may well be the cause of the more severe ocular injuries such as retinal detachment, changes in retinal venous pressure are a cause of the retrohyaloid, preretinal, and intraretinal haemorrhages. \n\n EDITOR,-We are grateful to Liguori et al and to Talks and Elston for their helpful comments on our paper on non-accidental injury (NAI) in infancy, in particular those related to the possible eVect of increased vascular pressure in the pathogenesis of retinal haemorrhages in this condition.\n\n All of our cases died as a result of their injuries, and we are interested to hear that Liguori et al believe that they have a similar 'possible association between subdural haemorrhage and intraocular haemorrhages' in non-fatal cases of NAI, although it is unclear whether their cases are the result of direct head or eye trauma. It is important to emphasise that in all our cases brain injuries were as a result of indirect trauma, with no evidence of direct trauma either to the head or the eyes.\n\n We agree that it is well established that retinal haemorrhages can be associated with a range of conditions, including subarachnoid haemorrhage (Terson's syndrome) and other causes of raised intracranial pressure; and with raised intraocular or intrathoracic venous pressure, such as in central retinal vein thrombosis or acute thoracic compression injuries (such as may occur if the chest of an infant is compressed during shaking).", "qa": [["80_28945100_5_1", "What are some potential causes of optic nerve sheath hemorrhage?\n", "Some potential causes of optic nerve sheath hemorrhage include angular, rotational, or axial movement of the eye, as well as acute rises in intracranial pressure, subarachnoid hemorrhage, acute cerebral venous sinus thrombosis, shaking injuries in children, asphyxia, epileptic fits, and acute central retinal vein occlusion."], ["80_28945100_5_2", "How can retinal hemorrhages occur in cases of non-accidental injury?\n", "In cases of non-accidental injury, retinal hemorrhages can occur due to increased vascular pressure. This can be caused by subarachnoid hemorrhage, acute rises in intracranial pressure, shaking injuries in children, asphyxia, epileptic fits, and acute central retinal vein occlusion."], ["80_28945100_5_3", "What are some potential complications or associated conditions of optic nerve sheath hemorrhage?\n", "Some potential complications or associated conditions of optic nerve sheath hemorrhage include choroidoretinal hemorrhages, cerebral hemorrhages, and the suspicion of a battered child syndrome. It is suggested that an accurate ophthalmoscopic examination should be mandatory in cases of optic nerve sheath hemorrhage to assess for these complications or associated conditions."]]}, {"passage_id": "62_2068296_1", "passage": "All men and women over 21 years of age with a first time diagnosis of CRC (ICD-O-3 codes: C18-C21) after January 1, 2008 were eligible for participation. Risk factor/dietary questionnaires, pathology reports and saliva samples (for genotyping) were collected using methodologies developed in the Colon Cancer Family Registry (70) and the Multiethnic Cohort (MEC) (71) . The present study includes 950 cases recruited into the HCCS who were born in Mexico (42.3%), the USA (31.4%), Central/South America (16.6%), Cuba or the Caribbean Islands (1.8%) or Europe (0.4%). This study was approved by the University of Southern California Institutional Review Board and the California Committee for the Protection of Human Subjects, and all participants provided written informed consent.\n\n The Multiethnic cohort study (MEC) is a large prospective cohort study that includes subjects from various ethnic groups, including HL primarily from California and mainly, Los Angeles (71) . Between 1993 and 1996, participants returned a self-administered baseline questionnaire that obtained general demographic, medical and risk factor information. The MEC used state driver's license files as the primary source to identify study subjects in California. Surnames were used to identify HL individuals because race/ ethnicity was not available in driver's license files.\n\n In the cohort, incident cancer cases are identified annually through cohort linkage to population-based Surveillance, Epidemiology and End Results cancer registries in Los Angeles County as well as to the California State cancer registry in the same manner as in the HCCS. All men and women over age 21 with a first time diagnosis of CRC (ICD-O-3 codes: C18-C21) were included as eligible cases. The current study used questionnaire \n\n \n\n \n\n Additional controls for this CRC GWAS consisted of participants from a GWAS of type 2 diabetes conducted by the SIGMA Type 2 Diabetes Consortium. The primary goal of this consortium was to characterize the genetic basis of type 2 diabetes in four component studies: (i) Diabetes in Mexico Study (DMS, n = 472), (ii) Mexico City Diabetes Study (MCDS; n = 614), (iii) Universidad Nacional Aut\u00f3noma de M\u00e9xico (UNAM)/Instituto Nacional de Ciencias M\u00e9dicas y Nutrici\u00f3n Salvador Zubir\u00e1n Diabetes Study (UIDS; n = 1138) and (iv) the MEC (n = 2,106; described above) (35) . Whole blood-derived DNA samples in the present analysis included SIGMA participants without a diagnosis of diabetes. All participants in DMS, MCDS and UIDS were identified as Mexican.\n\n The HCCS and MEC CRC cases were genotyped using the Illumina HumanOmni2.5Exome-8v1.0 and HumanOmni2.5Exome-8v1.1 BeadChip arrays in the USC Norris Comprehensive Cancer Center Molecular Genomics Core (Los Angeles, CA, USA). MEC controls and controls derived from the Mexican SIGMA studies were genotyped using the Illumina HumanOmni2.5-4v1 SNP array at the Broad Institute Genetic Analysis Platform (Cambridge, MA, USA). Samples not passing SIGMA's standard QC procedures for raw data, as described previously, were removed prior to downstream QC steps on the combined set of cases and controls (35) . Controls from the MEC-SIGMA study (n = 93) were also genotyped on the HumanOmni2.5Exomev1 array (n = 62) and HumanOmni2.5Exome-8v1.1 array at the University of Southern California to allow for cross-platform validation.\n\n Genotype data were cleaned based on QC metrics at the individual subject and SNP levels. In brief, samples with <95% call rate, unintended replicates, sex mismatches between self-reported and genotypic predicted sex, and identity-by-descent with another sample were removed. Monomorphic SNPs, SNPs with <95% call rate and SNPs with mismatching alleles across platforms were eliminated. We also removed: SNPs with low concordance between intentional cross-platform replicates; SNPs not compared due to low call rate; SNPs discordant between platforms (using HapMap samples genotyped by Illumina); SNPs discordant in within-platform duplicates; and SNPs not present in all datasets. Eleven CRC cases from the MEC study were identified since selection for SIGMA participation, so these individuals were genotyped with controls but treated as cases for analytic purposes.\n\n All SNPs overlapping 1000 Genomes Project genotypes were matched to the forward strand.", "qa": [["62_2068296_1_1", "What are the risk factors associated with colorectal cancer?\n", "Risk factors for colorectal cancer include age (over 50 years old), a family history of colorectal cancer, certain inherited gene mutations (such as Lynch syndrome or familial adenomatous polyposis), personal history of inflammatory bowel disease, a diet high in red and processed meats, obesity, smoking, heavy alcohol use, and lack of physical activity."], ["62_2068296_1_2", "How is colorectal cancer diagnosed?\n", "Colorectal cancer is typically diagnosed through a combination of screening tests and diagnostic procedures. Screening tests include colonoscopy, sigmoidoscopy, fecal occult blood test, and stool DNA test. If an abnormality is detected during screening, further diagnostic procedures such as biopsy, imaging tests (such as CT scan or MRI), and blood tests may be performed to confirm the diagnosis and determine the stage of the cancer."], ["62_2068296_1_3", "What is the prognosis for colorectal cancer?\n", "The prognosis for colorectal cancer depends on various factors, including the stage of the cancer at the time of diagnosis, the individual's overall health, and the effectiveness of the treatment. Generally, the earlier the cancer is detected and treated, the better the prognosis. The five-year survival rate for localized colorectal cancer is around 90%, while the five-year survival rate for metastatic colorectal cancer is around 14%. However, it's important to note that these statistics are general estimates and individual outcomes may vary."]]}]