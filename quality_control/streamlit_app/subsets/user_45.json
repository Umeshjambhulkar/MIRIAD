[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "52_5051478_4", "passage": "Our recommendation is that the percentages of patients that benefitted, had no benefit or were worse after a procedure be routinely reported. Such Glasgow Benefit Inventory data could be more clinically useful than the current mean and standard deviation data being the method most commonly used. To date, such data are only available from five case series.\n\n The analysis of case series data showed material heterogeneity for most surgical procedures and the large Scottish National audit of otorhinolaryngological practice likewise had a wide range of mean Glasgow Benefit Inventory scores from reassurance to surgery. As such, departmental audit or individual audit of surgical practices should not have Glasgow Benefit Inventory as the main clinical outcome unless controlled for the case mix.\n\n As a systematic review, quality of reporting of the Glasgow Benefit Inventory scores from the literature identified was used with a cut-off of >50% of loss to follow-up being used and justified by the distribution analysis. From eligible papers, the Glasgow Benefit Inventory data reported varied in extent but where it could be used, such as in the comparison between the scores between aims of intervention, it was included. Apart from identifying large numbers of surgical case series reporting the Glasgow Benefit Inventory scores, one paper demonstrated its use to identify factors predicting benefit.44\n\n The majority of the literature reports surgical series. The majority of patients referred to otorhinolaryngological clinics are not managed surgically. Even those managed surgically could be managed otherwise. So the Glasgow Benefit Inventory scores of patients managed non-surgically are important to have comparisons with. As much Glasgow Benefit Inventory data were included in the analysis as possible but many papers had to be excluded because the results were displayed graphically from which numerical data could not be assessed. It was not considered viable to request further data from study authors as the majority were written by trainees' in non-research establishments. What was searched for and not identified except in five papers48,51,76,87,98 were reports of the percentage of patients for whom there was no or negative benefit of surgery. This could be one of the main strengths of the Glasgow Benefit Inventory scoring system that must be further investigated as it is with such percentages that differences between interventions or their aims could become more obvious.\n\n This review has highlighted the absence of any recommended method of reporting Glasgow Benefit Inventory data. This has stimulated the creation of a MRCHI website10 which will be regularly updated. The 118 papers identified reporting Glasgow Benefit Inventory outcomes, in retrospect, have all weaknesses in method of reporting the data. The Glasgow Benefit Inventory was specifically designed to have both positive and negative outcomes with the aim of being able to say that following an intervention x% of patients benefited, y% of patients did not benefit and z% of patients were worse. Such data could be used to inform patients of what the likelihood of overall benefit would be in addition to how successful technically the intervention was. It would also allow the Glasgow Benefit Inventory to be used for individual and departmental audit. What is not known is the range around a zero Glasgow Benefit Inventory score that would define no positive or negative benefit. Till this has been defined, what can be done is to report Glasgow Benefit Inventory outcomes as distribution plots. Arbitrary cut-off points within a given case series might then become obvious.\n\n At this stage, it probably would be incorrect to compare the benefit of interventions that did not have the same clinical objective such as surgery for hearing versus surgery for recurrent sore throats. This is because the components making up the total Glasgow Benefit Inventory score are not the same. This aspect needs further investigation using up-to-date statistical methods for factor rather than principal component analysis.\n\n We have provided a standardised set of representative outcome scores including distribution of data on five otolaryngology interventions, with principal component subscales. As with all representative scores, these are an average of all patients and surgeons, and therefore, it is expected these represent a random selection of patients with good and poor outcomes, as well as surgeons with better and worse outcomes. Thus, the data from these highly selective series are unlikely to give the same Glasgow Benefit Inventory benefits when applied to overall otorhinolaryngolical practices.66\n\n Case series are required of interventions yet to be reported, or reported insufficiently to give usable data. This should include patients managed non-surgically, with medication, physical therapy or the supply of devices and include the above-suggested distribution plots of the data. Such data would also be of interest to ascertain the area of benefit using subscore analysis or indeed performing principal component analysis. In addition, especially if prospectively planned, such case series can on multifactorial analysis give predictions of patient benefit.\n\n Factor analysis is merited of tonsillectomy patients' responses in comparison with other surgical and non-surgical interventions to identify variations that could lead to reconsideration renaming or reconfiguration of the subscores. [ \n\n \u2022 Glasgow Benefit Inventory is a validated patient-recorded outcome measure to assess quality of life post-medical and surgical interventions in otolaryngology albeit to date no medical interventions have been reported in detail.\n\n \u2022 In case series, it can be used to identify predictors of benefit.\n\n \u2022 Subscores can be useful in characterising the areas of benefit when a comparison is being made between different interventions where the surgical objectives might seem similar.\n\n \u2022 Although applicable for all otorhinolaryngological patients, there is sufficient differences in the mean benefit between six of the 11 surgical interventions for comparisons to be made between departments or individual clinicians presumably because of the greatly varying indications.\n\n \u2022 For cochlear implant, middle ear implant, stapes surgery, tonsillectomy and management of vestibular schwannoma, there is consistency of data in metaanalysis to suggest that these interventions can be compared for audit purposes.\n\n \u2022 Higher quality of reporting of the Glasgow Benefit Inventory data and investigation of non-surgical interventions are desirable reporting the distribution of the data to allow percentages that had no or negative benefit to be reported. Interventions for hearing (a-c): cochlear implant, middle ear implant (MEI) and stapes surgery. Intervention for tonsils (d). Forest plot of intervention for hearing and tonsils data with low heterogeneity: boxes represent mean score with lines for 95% confidence intervals. Summary (diamond) shows mean score with 95% confidence interval. Intervention for vestibular schwannoma: boxes represent mean score with lines for 95% confidence intervals. Summary (diamond) shows mean score with 95% confidence interval. Five studies were included in analysis for quality of life post-intervention for vestibular schwannoma (VS Comparison across interventions F = 103.5, P < 0.001 F = 68.2, P < 0.001 F = 4.2, P = 0.02 F = 46.2, P < 0.001", "qa": [["52_5051478_4_1", "How can the Glasgow Benefit Inventory (GBI) be used to inform patients about the likelihood of overall benefit from a medical or surgical intervention?\n", "The GBI is designed to have both positive and negative outcomes, allowing healthcare professionals to inform patients about the percentage of patients who benefited, did not benefit, or were worse after a particular intervention. This information can provide patients with insights into the overall likelihood of benefit and the technical success of the intervention, helping them make informed decisions about their healthcare."], ["52_5051478_4_2", "Why is it important to report Glasgow Benefit Inventory outcomes for non-surgical interventions and compare them with surgical interventions?\n", "The majority of patients referred to otorhinolaryngological clinics are not managed surgically, and even among those managed surgically, there may be alternative non-surgical management options. Comparing the GBI scores between surgical and non-surgical interventions allows for a comprehensive understanding of the benefits and outcomes associated with different approaches. This comparison helps identify the areas of benefit and provides valuable information for both individual and departmental audit."], ["52_5051478_4_3", "What is the significance of reporting the percentage of patients who experienced no or negative benefit from surgery according to the Glasgow Benefit Inventory?\n", "One of the main strengths of the Glasgow Benefit Inventory scoring system is its ability to highlight the percentage of patients who did not benefit or experienced negative outcomes after surgery. This information can help identify differences between interventions or their aims and allow for a more robust evaluation of the effectiveness of surgical procedures. Understanding the percentage of patients who did not benefit is crucial for improving patient care and clinical decision-making."]]}, {"passage_id": "83_52878942_2", "passage": "Selexipag may be used for clinical stabilization (if feasible, since guidelines recommend intravenous prostanoid therapy in WHO class IV), and, if necessary, as a bridge to bilateral lung transplantation or reverse Potts shunt creation in pediatric PAH. 2, 16 It should be noted that the current, sparse clinical data on the oral use of selexipag in children with PAH [13] [14] [15] do not allow any conclusions regarding short-, mid-, or long-term efficacy. We found that oral selexipag has been safe in the small number of PAH children we treated off-label. Moreover, Gallotti et al. 14 reported that transitioning from parenteral to oral prostanoid in children can be pursued safely under a strict protocol. The authors also described the initiation of oral triple therapy with selexipag in a child with severe PAH.\n\n 14 Since the first clinical data on selexipag in children with PAH are now available, 13, 14 we foresee that oral selexipag use will increase over the next months and years in the pediatric age group. 20 Our assumption is supported by a biocomparison study investigating a pediatric tablet (containing 50 mg selexipag) in adults: 21 Pharmacokinetic characteristics of selexipag and its metabolite ACT-333679 were comparable in both groups, 21 making it interesting for pediatric usage, potentially in small children.\n\n The add-on use of oral selexipag must still be considered ''experimental therapy'' and we suggest strict patient selection and enrollment in any appropriate clinical study that should include frequent echocardiographic evaluations 22 and also cardiac catheterization before and six months after the start of selexipag, as previously described. 13 The efficacy of selexipag was demonstrated in adult PAH patients, but this medication, although mentioned as a possible add-on therapy in current pediatric guidelines, 15, 17 is to date recommended only in adult PAH patients in combination with an ERA and/or a PDE-5i. Nevertheless, the available clinical experience on the use of oral selexipag for pediatric PAH, with more such studies ahead, is promising. Thus, the decision to add selexipag as a third oral PAH agent, or to replace intravenously administered PAH drugs with oral selexipag in rather ''stable'' pediatric PAH patients, might become a future strategy.", "qa": [["83_52878942_2_1", "What are the potential uses of oral selexipag in pediatric patients with pulmonary arterial hypertension (PAH)?\n", "Oral selexipag may be used for clinical stabilization in pediatric PAH patients, as well as a bridge to bilateral lung transplantation or reverse Potts shunt creation. However, it should be noted that the current clinical data on the oral use of selexipag in children with PAH is limited, and no conclusions can be drawn regarding its short-, mid-, or long-term efficacy."], ["83_52878942_2_2", "What precautions should be taken when considering the add-on use of oral selexipag in pediatric PAH patients?\n", "The add-on use of oral selexipag should be considered \"experimental therapy\" and strict patient selection and enrollment in appropriate clinical studies are recommended. Frequent echocardiographic evaluations and cardiac catheterization before and six months after starting selexipag should be included in the clinical study protocol. While selexipag has demonstrated efficacy in adult PAH patients, it is currently recommended only in combination with an endothelin receptor antagonist (ERA) and/or a phosphodiesterase-5 inhibitor (PDE-5i) in adult patients. However, the available clinical experience with oral selexipag in pediatric PAH patients is promising, and future strategies may involve adding selexipag as a third oral PAH agent or replacing intravenously administered PAH drugs with oral selexipag in stable pediatric patients."], ["83_52878942_2_3", "What is the potential for increased use of oral selexipag in the pediatric age group?\n", "With the availability of the first clinical data on selexipag in children with PAH, it is anticipated that the use of oral selexipag will increase in the pediatric age group in the coming months and years. A biocomparison study has shown comparable pharmacokinetic characteristics of selexipag in both pediatric and adult populations, making it potentially suitable for pediatric usage, even in small children. However, further studies and clinical experience are needed to establish the safety and efficacy of oral selexipag in pediatric PAH patients."]]}, {"passage_id": "60_52101979_0", "passage": "Interprofessional collaboration among allied health professionals is essential in the provision of holistic, early intervention pediatric practice for best patient outcomes (James & Chard, 2010) .\n\n However, there is evidence that teaming skills are not intuitive and that learning to work together does not always occur on the job (Barnsteiner, Disch, Hall, Mayer, & Moore, 2007) . The preprofessional period provides an opportunity to institute interprofessional education to facilitate the development of collaboration skills (Barnsteiner et al., 2007) . Unfortunately, most health care education is highly segregated (Carlisle, Cooper, & Watkins, 2004) . There is a need for interprofessional education programs that teach allied health students who are preparing to work in pediatric practice the skills required to collaborate with other professions in order to meet the complex needs of this population.\n\n Providing high-quality treatment in the current, complex health care environment requires the ability to collaborate with other professionals.\n\n A research synthesis conducted by the Institute of Medicine (2003) has illustrated that when health care workers understand the roles, language, and values of other professionals, they are able to work together more effectively to ensure high-quality care. Interprofessional collaboration is especially important in the provision of holistic, early intervention pediatric practice. A lack of continuity of care can threaten optimal service provision for the early childhood population. For example, in a study of the parental experience with early intervention services, parents highlighted the negative impact that a lack of cooperation among professionals had on their service delivery experience (James & Chard, 2010) . The parents felt that there was meaningful collaboration between themselves and the individual professionals but that this was lacking among the service providers.\n\n Furthermore, deficient collaboration among early intervention professions can drain the time of a family that is already experiencing the stress of caring for a child with special needs (Brotherson & Goldstein, 1992) .\n\n Occupational therapists play a key role in providing services for young children with special needs. Teaching occupational therapy (OT) students to work with other professionals before they graduate will lead to their working together effectively in a changing and challenging health care environment (Parsell and Bligh, 1998) .\n\n However, even when OT and other allied heath students are learning similar content, they typically do so without any interactions that cross professional boundaries (Carlisle et al., 2004) .\n\n Despite the fact that health care educational programs exist in close spatial proximity and offer services to the same population of clients, collaboration is rare. For example, at Western Michigan University, where this study took place, OT and Speech Language Pathology (SLP) students were often offering services to the same clients in the same treatment rooms at different times with minimal to no interaction among the treatment providers. This can lead to misunderstandings, the devaluation of others' contributions, and professional protectionism. Education that involves going beyond the confines of one's own discipline to develop teamwork, collaboration, and clinical reasoning skills in the context of an interprofessional team is an essential foundation for practice after graduation (Barnsteiner et al., 2007) .\n\n There are several difficulties in developing interprofessional education programs. These challenges include organizational barriers to implementation, such as incongruent class schedules and curriculums among disciplines, the lack of shared meeting space, and financial disincentives (Price et al., 2009; Rees & Johnson, 2007) . For example, Price et al. (2009) identified \"logistic enablers,\" such as the physical layout of the clinic, the electronic medical records communication system, and the support from leadership for increased time allotted for collaboration, as key elements of a successful interprofessional education program.\n\n Organizational determinants, including specified time and space for collaboration and fee structures that make collaboration financially feasible, are necessary for successful interprofessional work (Price et al., 2009; Rees & Johnson, 2007) .\n\n In addition, two other barriers to implementation of interprofessional education programs exist. First, there are currently no gold standard measuring tools to capture changes in interprofessional skills after engagement in an interprofessional education program (Thannhauser, Russell-Mayhew, & Scott, 2010) . Second, there is a limited understanding of both the elements that make an interprofessional education program effective and the developmental progression of interprofessional skills attainment (Barr & Ross, 2006) .\n\n There is a lack of well-developed tools for measuring outcomes of interprofessional education.\n\n In a systematic review of the literature of interprofessional education outcome measures, Thannhauser, Russell-Mayhew, and Scott (2010) concluded that little information exists about the psychometric properties of published instruments, and that none have been used in existing studies more than two times. Also, a major concern about the available instruments is the lack of validity information.", "qa": [["60_52101979_0_1", "What are the benefits of interprofessional collaboration in pediatric practice?\n", "Interprofessional collaboration in pediatric practice has been shown to improve patient outcomes and ensure high-quality care. When healthcare workers understand the roles, language, and values of other professionals, they are able to work together more effectively. Collaboration among professionals is especially important in the provision of holistic, early intervention pediatric practice, as a lack of continuity of care can threaten optimal service provision for the early childhood population. It allows for a comprehensive approach to meeting the complex needs of pediatric patients and ensures that all professionals involved are working towards the same goals."], ["60_52101979_0_2", "What are the challenges in implementing interprofessional education programs?\n", "There are several difficulties in developing interprofessional education programs. Organizational barriers, such as incongruent class schedules and curriculums among disciplines, lack of shared meeting space, and financial disincentives, can hinder the implementation of such programs. Additionally, there is a lack of well-developed tools for measuring outcomes of interprofessional education, making it difficult to assess the effectiveness of these programs. Furthermore, there is limited understanding of the elements that make an interprofessional education program effective and the developmental progression of interprofessional skills attainment. These challenges need to be addressed in order to successfully implement interprofessional education programs."], ["60_52101979_0_3", "How does a lack of collaboration among early intervention professions impact the experience of parents and families?\n", "A lack of collaboration among early intervention professions can have a negative impact on the experience of parents and families. In a study of the parental experience with early intervention services, parents highlighted the negative impact that a lack of cooperation among professionals had on their service delivery experience. While there may be meaningful collaboration between parents and individual professionals, the lack of collaboration among service providers can lead to misunderstandings, devaluation of others' contributions, and professional protectionism. This can further add to the stress and burden experienced by families who are already caring for a child with special needs. Collaborative efforts among professionals are crucial to ensure that families receive the support and services they need."]]}, {"passage_id": "61_54587163_3", "passage": "Under these circumstances, the activity of PHD is limited, which indirectly strengthens HIF-1\u03b1 activation and stabilization, thus triggering overexpression of target genes related to proliferation, cell migration and tumor invasion as clarified above.\n\n G protein-coupled receptor-91 (GPR91), also termed succinate receptor 1 (SUCNR1), is an orphan molecule that belongs to the G protein-coupled receptor (GPCR) family [60] , which was first spotted in a megakaryocytic cell in 1995 and called \"P2U2\" [61] . The gene encoding GPR91 was later uncovered through an expressed sequence tag data mining strategy in 2001 [62] . GPR91 consists of transmembrane domains connected by three hydrophilic extracellular loops (ECLs) and binding pockets [63] . In recent years, succinate was identified as a specific ligand binds to GPR91 thus triggering downstream physiological and pathophysiological cascades.\n\n GPR91 exhibits a wide distribution and high expression in kidney [64] , spleen, liver, small intestine [65] , cardiomyocyte [66] , retinal ganglion cells [67] , white adipose tissue [68] , hepatic stellate cells [69] and even on dendritic cells (DCs) [70] . This lays a solid foundation for investigating the role of GPR91 in blood pressure regulation, hematopoiesis [60] and the mechanisms involved in hypertension, heart failure, liver damage, diabetes, and even energy metabolism, angiogenesis and immunomodulation.\n\n Apart from these non-carcinogenic process, succinate also signals as an angiogenesis factor in tumorigenesis. Our recent research revealed that succinate elicits neovascularization by upregulating vascular endothelial growth factor (VEGF) expression in a HIF-independent way, which proves to be through the activation of extracellular regulated kinase (ERK) 1/2 and signal transducer and activator of transcription 3 (STAT3) via the specific succinate receptor GPR91 [22] . An increasing family of evidence suggests that the ERK1/2 signaling pathway is associated with angiogenesis [71] , proliferation, differentiation, apoptosis and oncogenesis [65] . In addition, recent findings have indicated that STAT3 is a major oncogenic contributor in diverse cancers, including colon carcinoma [72] . Once stimulated by the accumulation of succinate, the downstream activation will break out immediately, therefore leading to biochemical events and even tumorigenesis.\n\n TRAP1 is an evolutionarily conserved chaperone of the heat shock protein 90 (Hsp90) family, and has been shown to be upregulated in hepatocellular carcinoma [73] , gastric cancer [74] , colorectal cancer [75] , breast cancer [76] , thyroid carcinoma [77] and esophageal squamous cell cancer [78] . Recent studies have reported that TRAP1 can decrease SDH enzymatic activity in the respiratory chain, thus resulting in high concentrations of succinate [29, 79, 80 ]. The accumulated succinate will then contribute to oncogenesis by HIF-1\u03b1 stabilization, ROS production and GPR91 stimulation, as described above. In addition to the succinate-dependent effect, TRAP1 can also promote cellular migration and invasion through the STAT3/MMP2 pathway and antioxidant defenses [78] .\n\n Nuclear related factor 2 (NRF2) is a transcription factor belonging to the family of nuclear factor erythroid 2-related derived factors (NRFs). NRFs are regulated by Kelch-like ECH-associated protein 1 (KEAP1) and are well-known for their cellular antioxidant defense role in neuron protection [81] , liver protection [82] and tumor suppression [83] . However, in recent researches, an evil side www.impactjournals.com/oncotarget of NRF2 gradually surfaced involving in the pathogenesis of various types of tumors [84, 85] , such as skin cancer, esophageal cancer, lung cancer [86] , and ovarian cancer [87] . Although the evidence of the relationship between SDH mutation and NRF2 activation is insufficient, SDH inhibition is more likely to induce NRF2 production [88] , and this may depend on increased ROS production.\n\n Tumor-promoting inflammation is now an emerging hallmark of cancer, which sounds unanticipated and paradoxical but proved to be virtual in its tumorigenesis journey. Succinate is widely accepted as an inflammatory signal and induces interleukin-1\u03b2 (IL-1\u03b2) through HIF-1\u03b1 [89] while IL-1\u03b2 has been demonstrated to be elevated in colorectal cancer [90] , oral cancer [91] and colon cancer [92] .", "qa": [["61_54587163_3_1", "How does succinate contribute to tumorigenesis?\n", "Succinate contributes to tumorigenesis by upregulating vascular endothelial growth factor (VEGF) expression in a HIF-independent way, leading to neovascularization. This is achieved through the activation of extracellular regulated kinase (ERK) 1/2 and signal transducer and activator of transcription 3 (STAT3) via the specific succinate receptor GPR91. The ERK1/2 signaling pathway is associated with angiogenesis, proliferation, differentiation, apoptosis, and oncogenesis. STAT3 is a major oncogenic contributor in various cancers. The accumulation of succinate stimulates downstream activation, resulting in biochemical events and tumorigenesis."], ["61_54587163_3_2", "What is the role of TRAP1 in oncogenesis?\n", "TRAP1, an evolutionarily conserved chaperone of the heat shock protein 90 (Hsp90) family, is upregulated in various cancers. TRAP1 can decrease succinate dehydrogenase (SDH) enzymatic activity in the respiratory chain, leading to high concentrations of succinate. The accumulated succinate contributes to oncogenesis by stabilizing HIF-1\u03b1, producing reactive oxygen species (ROS), and stimulating the succinate receptor GPR91. Additionally, TRAP1 promotes cellular migration and invasion through the STAT3/MMP2 pathway and antioxidant defenses."], ["61_54587163_3_3", "How does succinate affect nuclear related factor 2 (NRF2) activation?\n", "Although the evidence of the relationship between SDH mutation and NRF2 activation is insufficient, SDH inhibition is more likely to induce NRF2 production. Succinate accumulation resulting from SDH inhibition may increase reactive oxygen species (ROS) production, which can activate NRF2. NRF2 is a transcription factor involved in cellular antioxidant defense and has been implicated in the pathogenesis of various types of tumors."]]}, {"passage_id": "57_55922497_1", "passage": "Percent score was calculated for the total attitude score as well as for each domain of knowledge.\n\n A pilot study was carried out on 30 physicians and nurses (not included in the final study). This study was formulated to test the clarity, applicability of the study tools, accommodate the aim of the work to actual feasibility, identify the difficulties that may be faced during the application, as well as study all the procedures and activities of the administrative aspects. Also, the time of interviewing the health staff was estimated during this pilot study. The necessary modifications according to the results obtained were done, so some statements were reworded. Also, the structure of the questionnaire sheet was reformatted to facilitate data collection. The average time needed for filling the questionnaire was 15 min.\n\n A pre-coded sheet was used. All questions were coded before data collection. This facilitates both data entry and verification as well as reduces the probability of errors during data entry. Data were fed to the computer directly from the questionnaire without intermediate data transfer sheets. The Excel program was used for data entry. A file for data entry was prepared and structured according to the variables in the questionnaire. After data were fed to the Excel program; several methods were used to verify data entry. These methods included simple frequency, cross-tabulation, as well as manual revision of entered data.\n\n All the necessary approvals for carrying out the research were obtained. The Ethics Committee of the Kuwaiti Ministry of Health approved the research. A written format explaining the purpose of the research was prepared and signed by the physician before filling the questionnaire. In addition, the purpose and importance of the research were discussed with the director of the health center.\n\n Before analysis; data were imported to the statistical package for social sciences (SPSS) which was used for both data analysis and tabular presentation. Descriptive measures were utilized (count, percentage, arithmetic mean and standard deviation) as well as analytic measures (Chi square for qualitative variables and Student t test for normally distributed quantitative variables). Mann-Whitney test was used for non parametric variables. Multiple linear regression was used to identify significant factors after controlling for the confounding effect of other variables. The level of significance selected for this study was P 6 0.05.\n\n Multiple logistic regression analysis was utilized to identify the significant factors correlating with the screening for domestic violence against women. Age, duration at work, nationality, gender, and marital status were used as co-variates. A score of one was used for screening and a score of zero was used for being a nurse. Table 1 shows socio-demographic characteristics of studied PHC staff. Medical staff screening for DV against women was slightly older than those not screening (37.2 \u00b1 8.5 years compared with 35.83 \u00b1 8.33 years old, P = 0.14) and spent nearly similar years at the current job (11.5 \u00b1 7.5 years compared with 10.50 \u00b1 7.81 years, P = 0.25). Also, the marital status and educational qualification of both groups did not differ significantly. Males were significantly more likely to screen for violence (36.2% compared with 18.8%, P < 0.001). Physicians also, tended to screen for violence more than nurses as they constituted 51.2% of those screening as compared with 26.4% of those not screening for violence, P < 0.001. Table 2 shows knowledge of PHC staff about violence. Those screening for violence had a significantly higher mean percent overall knowledge score than those who were not used to screen (73.8 \u00b1 9.5 compared with 70.9 \u00b1 11.2%, P = 0.006). The medical staff practicing screening tended to have a slightly higher or similar mean percent score for the deprivation/neglect (53.9 \u00b1 17.1 compared with 51.3 \u00b1 18.7%, P = 0.097), physical (94.3 \u00b1 9.5 compared with 94.5 \u00b1 8.9%, P = 0.948), and sexual (92.4 \u00b1 9.4 compared with 90.9 \u00b1 10.5%, P = 0.194) sub-domains. The only sub-domain showing significant difference was the psychological sub-domain (78.4 \u00b1 20.3 compared with 69.4 \u00b1 26.3%, P = 0.004). Table 3 demonstrates the attitude of PHC staff toward screening for domestic violence against women. Although no significant differences were detected for each of the questions of this domain yet, those not screening for violence had a significantly higher mean percent score than those screening for violence (70.1 \u00b1 18.6 compared with 65.5 \u00b1 16.5%, P = 0.015).", "qa": [["57_55922497_1_1", "What are the factors that influence the screening for domestic violence against women among primary healthcare staff?\n", "Factors that influence the screening for domestic violence against women among primary healthcare staff include age, duration at work, nationality, gender, and marital status. Males and physicians are more likely to screen for violence compared to nurses. The educational qualification and marital status of the staff do not significantly affect the screening. "], ["57_55922497_1_2", "How is knowledge about violence related to the screening practices of primary healthcare staff?\n", "Primary healthcare staff who screen for violence have a higher overall knowledge score compared to those who do not screen. The difference in knowledge is particularly significant in the psychological sub-domain. However, there is no significant difference in knowledge scores for the deprivation/neglect, physical, and sexual sub-domains between the two groups. "], ["57_55922497_1_3", "What is the attitude of primary healthcare staff towards screening for domestic violence against women?\n", "The attitude of primary healthcare staff towards screening for domestic violence against women is generally positive. Although there are no significant differences in the attitude scores for each question, those who do not screen for violence have a slightly higher mean percent score compared to those who screen. This suggests that there may be some reservations or concerns among healthcare staff regarding the screening process."]]}, {"passage_id": "86_70378503_0", "passage": "Family studies is a broad and fascinating area. In this book, we set out to offer what we hope is a thoughtful overview of the key concepts through which family lives may be explored, and to provide clear and even-handed signposts to the main debates at stake in many of these concepts, and associated readings. As an area of academic interest, however, family studies is not easy to define, not least because the core term 'family' has become a matter of considerable controversy and dispute. Although the word itself continues to be widely evident and generally unquestioned in everyday lives as well as in political debates and professional practices, researchers may ponder how to use it, or whether to use it at all. Many academics have grown wary of using the signifier 'the family' as this draws on stereotypes that fail to take account of, and marginalize, the realities of diverse family lives that do not fit the implicit model in 'the family', of a heterosexual two-parent nuclear family with breadwinning husband and father and home-making wife and mother. There are a variety of responses to these dilemmas within family studies.\n\n \u2022 Some researchers continue to use the term 'the family' unproblematically, often in practice referring to interrelated issues of residence, close ties based on blood or marriage, and the care of children. Talk about 'the family', in this way, is most likely to occur in discussions of broad patterns and structures, perhaps looking across different societies or examining how 'the family' as an institution relates to other major social institutions such as economic, employment or key concepts in family studies 2 educational systems. There are many questions about social life that seem to require the concept of 'the family' as an object that exists and can be studied. Similarly, policy makers may feel the need for a clear model or benchmark of what 'the family' is, in order to develop legislation and general procedures.\n\n \u2022 A different solution is to use the term in the plural and refer to 'families'. This acknowledges the diversity of lifestyles and relationships that might be referred to as 'family', offering a way forward which is widely accepted in family studies.\n\n \u2022 Other solutions have been to use the word 'family' as an adjective, as in 'family lives', or even as a verb, as in 'doing family ' (Morgan, D.H.J., 2003) . This takes us away from the idea that 'family' is a noun -an object that can be named as such -suggesting rather that it is a descriptive term which is applied to a wide variety of experiences and interactions and to different aspects of living.\n\n \u2022 Yet another approach is to turn the difficulty into a source of new questions, interrogating the word and asking how the term 'family' is used, in what contexts, and with what consequences? Various empirical studies have sought to do this (for an overview, see Ribbens McCarthy, 2008) . This way of thinking also opens up the possibility that 'family' may be found in all kinds of social setting, not just domestic sites.\n\n \u2022 Some writers find the concept of family so limiting and politically charged that they prefer to use other ideas altogether, such as 'intimacy', or broader terms within which 'family' is seen as one form of living alongside other relationships and experiences, and which may be captured by a notion such as 'personal life' (Smart, 2007) .\n\n As an area of scholarship, family studies is more fully recognized and academically organized in the USA than many other countries, and major overview textbooks are often authored from there (such as Boss et al., 2009; Coleman and Ganong, 2004; Collins and Coltrane, 2001; Lloyd et al., 2009 ). This is not to say that the field of family studies is not recognized as a discipline in its own right in other countries. While this recognition may be more or less explicit, academics in societies around the world produce important work relevant to the field, although there may be some associated differences of emphasis. Besides theorizing the term 'family' itself, and how it may be used, family studies generally covers an interconnected set of topics, including:\n\n \u2022 partnering and childbearing \u2022 household formations and demographic trends\n\n \u2022 daily living arrangements and decision making, including resources and provisioning \u2022 parenting and other forms of care\n\n \u2022 close relationships and their dynamics, in the context of various dimensions of age, generation, gender and sexuality \u2022 kinship and community relationships \u2022 domestic lives and their interrelationships with other areas of social life, such as education, health and employment \u2022 aspects of social policy, the law and professional practices related to these topics \u2022 diversity, inequality and cross-cultural and global issues.\n\n The last theme raises a further question, about how far any of these topics can be studied by applying the same concepts across all global, social and historical contexts?", "qa": [["86_70378503_0_1", "How has the concept of 'family' evolved in family studies?\n", "The concept of 'family' in family studies has evolved to acknowledge the diversity of lifestyles and relationships that can be referred to as 'family'. Researchers have moved away from using 'the family' as a singular noun and instead use 'families' in the plural form to encompass the various experiences and interactions that fall under the umbrella of family. Some scholars even use 'family' as an adjective or a verb to emphasize its descriptive nature rather than treating it as a fixed object."], ["86_70378503_0_2", "What are some alternative terms used in family studies to describe relationships and experiences similar to 'family'?\n", "Some scholars in family studies prefer to use alternative terms such as 'intimacy' or 'personal life' to describe relationships and experiences that are similar to what is traditionally understood as 'family'. These terms allow for a broader understanding of different forms of living and relationships, acknowledging that 'family' is just one aspect of personal life and can coexist with other types of relationships."], ["86_70378503_0_3", "How does the field of family studies differ in recognition and organization across different countries?\n", "The field of family studies is more fully recognized and academically organized in the USA compared to many other countries. Major overview textbooks in family studies are often authored from the USA. However, family studies is recognized as a discipline in its own right in other countries as well, and academics from around the world contribute important work to the field. While there may be some differences in emphasis, the interconnected topics covered in family studies, such as partnering and childbearing, household formations, parenting, and social policy, are relevant globally."]]}, {"passage_id": "68_1496846_1", "passage": "Platelets were found to be reduced on blood smear. In the differential leukocyte count, neutrophils showed a mild shift to the left. Therefore, an overall picture of leukoerythroblastosis was considered. A bone marrow aspirate revealed that the marrow was infiltrated by tumors composed of nests of poorly differentiated cells. A total of 30 Gy RT was planned in 10 fractions for the painful left shoulder region. On the 6th day of RT, the urinary output decreased suddenly and dyspnea developed. Biochemical analysis revealed the values shown in Table 1 .\n\n The patient had previous coronary bypass anamnesis and an ejection fraction of 50% on echocardiography. The central venous pressure catheter was opened. Central venous pressure levels were measured, and the patient was administered a control fluid. Sodium bicarbonate was added to treat for urinary alkalinization. Daily biochemical follow-up was planned. On the 9th day of follow-up, LDH, urea, creatinine, and uric acid regressed ( Table 1 ). The patient, who improved in overall status and had no requirement for hemodialysis up to this time, developed sudden impairment in overall status; dyspnea and hypotension developed on the 11th day of follow-up. Thirty minutes after the development of these symptoms, the patient had a cardiopulmonary arrest and died.\n\n Tumor lysis syndrome is seen in patients with hematologic malignancies sensitive to chemotherapy, within days of receiving chemotherapy. TLS following RT for solid tumors is a very rare complication. In the published reports, only 3 cases of TLS following RT for solid tumors have been reported to occur among adults. The first case was described by Tomlinson in a patient with medulloblastoma 9 ; the second was described by Rostom in a patient with metastatic breast cancer 10 ; Figure 1 . Pretreatment whole body bone scintigraphy. and, finally, the third case was described by Noh in a patient with non-small cell lung cancer. 11 In the published reports, this is the fourth case of TLS during RT for solid tumors in adults.\n\n RT is generally used in the treatment of localized targets, which includes cancer. Recent studies indicate that RT recruits biological effectors outside the treatment field and has systemic effects. Investigations suggest that systemic effects are associated with the immune system and cytokines.\n\n 12 TLS in our patient may be explained by the systemic effects of local RT.\n\n The occurrence of TLS in prostate carcinoma is also extremely rare. Sorscher 5 reported the first case of TLS associated with docetaxel chemotherapy for metastatic prostate cancer. Another case of TLS was reported by Wright in a patient with metastatic prostate cancer, after treatment with paclitaxel chemotherapy. 6 Only one case of prostate cancer complicated by TLS after 6 days of combined androgen blockage has been reported, 7 and one case of spontaneous TLS in metastatic prostate cancer has been reported. 8 In the published reports, this is the first case of TLS during RT for prostate cancer and the fifth among total cases of prostate cancer. In all of these cases, there was evidence for solid organ metastasis together with prevalent bone metastases (one had pulmonary metastasis and the other had hepatic metastasis). Our patient is the first one to develop TLS without solid organ metastasis among all patients with prostate cancer. This case demonstrates that TLS may develop with RT in solid tumors and prostate cancers, even if rare. As is the case in our patient, one should note that prophylaxis may be required in high-risk patients, even in the absence of solid organ metastasis, primarily in those with a very short PSA half-life.", "qa": [["68_1496846_1_1", "What is tumor lysis syndrome and how does it typically occur in patients with hematologic malignancies?\n", "Tumor lysis syndrome (TLS) is a condition that occurs in patients with hematologic malignancies, usually after receiving chemotherapy. It is characterized by the rapid breakdown of cancer cells, leading to the release of intracellular contents into the bloodstream. This release can overwhelm the body's ability to eliminate these waste products, resulting in metabolic abnormalities. TLS is typically seen within days of chemotherapy and is more common in hematologic malignancies that are sensitive to chemotherapy."], ["68_1496846_1_2", "How does radiation therapy (RT) for solid tumors contribute to the development of tumor lysis syndrome (TLS)?\n", "While TLS is a rare complication of radiation therapy (RT) for solid tumors, recent studies suggest that RT can have systemic effects on the body. These systemic effects are believed to be associated with the immune system and cytokines. In the case of TLS, it is hypothesized that the systemic effects of local RT can contribute to the breakdown of tumor cells and the release of intracellular contents, leading to the development of TLS."], ["68_1496846_1_3", "What are the risk factors for developing tumor lysis syndrome (TLS) in patients with prostate cancer undergoing radiation therapy (RT)?\n", "In the published reports, TLS in prostate cancer patients undergoing RT is extremely rare. However, there are some risk factors that have been identified. These include the presence of solid organ metastasis, particularly bone metastases, and a very short prostate-specific antigen (PSA) half-life. It is important to note that TLS can still occur in prostate cancer patients even in the absence of solid organ metastasis, highlighting the need for prophylaxis in high-risk patients."]]}, {"passage_id": "40_58608635_0", "passage": "Oral squamous cell carcinoma (OSCC) is the leading cause of cancer morbidity and mortality, especially among men in Taiwan [1] . Despite new advances in the diagnosis and therapeutic approaches, the 5-year survival remains low [1, 2] . While relapse of OSCC remains a major clinical challenge, the incidence of relapse among patients varies, even for those with a similar stage of disease at diagnosis or those who undergo the same treatment [3] . This implies that other factors, such as genetic variations, may play an important role in disease prognosis.\n\n Most patients with OSCC are diagnosed at an advanced stage of the disease [4] . For these patients, the treatment options are limited to mainly systemic therapy, often as concurrent chemoradiotherapy (CCRT) with platinum-based DNA damaging agents as either primary treatment or adjuvant postoperative therapy [5] [6] [7] . However, the overall survival (OS) for these patients remains poor because most of them experience recurrence or distance metastases [8] [9] [10] . Genetic variations in DNA repair genes affect susceptibility to the efficacy and survival outcome of a certain treatment [11, 12] . Increased DNA repair capacity may affect the sensitivity of the tumor cells to chemotherapy and radiotherapy (RT) by allowing cancer cells to repair DNA that has been damaged by these agents. Single nucleotide polymorphism (SNP) in genes involved in the nucleotide excision repair (NER) pathway may modulate DNA repair capacity by influencing gene expression or activity, thereby affecting the anticancer effects of therapeutic agents and treatment response [13, 14] .\n\n The excision repair cross-complementation genes, including groups 1 (ERCC1), 2 (ERCC2), and 5 (ERCC5) and xeroderma pigmentosium complementation group A (XPA) and C (XPC) encode proteins that are involved in the NER pathway; and together with other proteins, operate to recognize and repair damaged DNA [15] . The XPC together with XPF initially recognize the DNA lesion that is unwound and remodeled by helicase proteins ERCC3 and ERCC2 that binds to XPA and replication protein A (RPA). The ERCC1 and ERCC5 proteins are involved in the incision of the identified DNA lesion. The difference in treatment response and clinical outcome have been attributed to SNPs in genes that code of the above proteins [13, 14] . Therefore, identifying genetic markers in the NER pathway may help develop personalized management strategies, thereby maximizing treatment success and improving survival.\n\n Thus, we conducted a retrospective cohort study to test whether SNPs in genes involved in the NER pathway are associated with prognosis in male patients with OSCC treated with adjuvant CCRT. A total of 13 SNPs in ERCC5, ERCC2, ERCC1, XPC, and XPA genes, which have been found to affect the risk and/or survival of cancers, were selected in the present study [13, 14, [16] [17] [18] [19] [20] . Their associations with clinical outcomes were evaluated using alternative genetic models, including additive, dominant, and recessive models.\n\n \n\n In total, 360 male participants newly diagnosed with histopathological confirmed advanced OSCC who received surgery plus adjuvant CCRT were recruited from the Head and Neck Surgery Department's Cancer Registry at Chang Gung Memorial Hospital, LinKou, Taiwan, from 1999 to 2016. A total of 41 participants were excluded, including 13 of aboriginal ethnicity, 23 with early-stage oral cancer (TNM stages I and II), and 5 with missing information on clinicopathologic variables (TNM stage, vascular invasion, and extracapsular spread). A final sample of 319 was included for analysis. Information on demographic characteristics (age, education, occupation, and ethnicity), lifestyle habit (cigarette smoking, alcohol drinking, and betel nut chewing), and family cancer history were collected through an interviewer-administered questionnaire. Lifestyle habits were categorized as either never (if the person never engaged in the habit continuously for more than a year) or ever (if the person ever engaged in the habit for more than a year). From the weight and height measurements, body mass index (BMI) was calculated as weight/height 2 (kg/m 2 ). Clinical information was also collected before treatment through a detailed medical history, physical examination, completed blood count, routine blood chemistry, computed tomography (CT) or magnetic resonance imaging (MRI) of the head and neck, abdominal ultrasound, and whole body bone scan or positron emission tomography scan. This study was approved by the Chang Gung Memorial Hospital (IRB No.", "qa": [["40_58608635_0_1", "What are the treatment options for patients diagnosed with advanced oral squamous cell carcinoma (OSCC)?\n", "For patients diagnosed with advanced oral squamous cell carcinoma (OSCC), the treatment options are limited to mainly systemic therapy, often as concurrent chemoradiotherapy (CCRT) with platinum-based DNA damaging agents as either primary treatment or adjuvant postoperative therapy. This approach aims to target the tumor cells throughout the body and is commonly used due to the limited surgical options for advanced cases of OSCC."], ["40_58608635_0_2", "How do genetic variations in DNA repair genes affect the prognosis of patients with oral squamous cell carcinoma (OSCC)?\n", "Genetic variations in DNA repair genes can affect the prognosis of patients with oral squamous cell carcinoma (OSCC). Increased DNA repair capacity may affect the sensitivity of tumor cells to chemotherapy and radiotherapy by allowing cancer cells to repair DNA that has been damaged by these agents. Single nucleotide polymorphisms (SNPs) in genes involved in the nucleotide excision repair (NER) pathway may modulate DNA repair capacity by influencing gene expression or activity, thereby affecting the anticancer effects of therapeutic agents and treatment response. Therefore, identifying genetic markers in the NER pathway may help develop personalized management strategies, maximizing treatment success and improving survival."], ["40_58608635_0_3", "What factors contribute to the low 5-year survival rate of patients with oral squamous cell carcinoma (OSCC)?\n", "The low 5-year survival rate of patients with oral squamous cell carcinoma (OSCC) can be attributed to several factors. Most patients with OSCC are diagnosed at an advanced stage of the disease, limiting the treatment options available. Additionally, the overall survival for these patients remains poor due to recurrence or distant metastases. The incidence of relapse among patients varies, even for those with a similar stage of disease at diagnosis or those who undergo the same treatment, suggesting that other factors, such as genetic variations, may play a role in disease prognosis. Therefore, improving early detection and developing personalized management strategies based on genetic markers in the NER pathway may help improve the prognosis and survival outcomes for patients with OSCC."]]}, {"passage_id": "12_9631605_1", "passage": "The PubMed, Cochrane Library, Science Direct and Embase databases were searched on May 10 th 2016, with the following keywords: \"oxidative stress\" or \"oxidant stress\" or \"nitrative stress\" or \"oxidative damage\" or \"nitrative damage\" or \"antioxidative stress\" or \"antioxidant stress\" or \"antinitrative stress\" and \"glaucoma\". The search was not limited to specific years. No minimal sample size and no language restrictions were applied. To be included, articles needed to be case-control studies describing our primary outcome variable, which was the measurement of oxidative or antioxidative stress markers in glaucoma patients and healthy controls. We imposed no limitation on the regional origin or the nature of the control group. Studies needed to be primary research. In addition, reference lists of all publications meeting the inclusion criteria were manually searched to identify any further studies that were not found with the electronic search. Ancestry searches were also completed on previous reviews to locate other potential eligible primary studies. The search strategy is presented in Fig 1. One author (CBDA) conducted all literature searches and collated the abstracts. Two authors (CBDA and FD) separately reviewed the abstracts and based on the selection criteria, decided the suitability of the articles for inclusion.\n\n A third author (BP) was asked to review the articles where consensus on suitability was debated. All authors then reviewed the eligible articles.\n\n Although not designed for quantifying the integrity of studies [18] , the \"STrengthening the Reporting of OBservational studies in Epidemiology\" (STROBE) criteria were used to check the quality of the reporting [19] . The STROBE Statement consists of a checklist of 22 items, which relate to the title, abstract, introduction, methods, results and discussion sections of articles. Eighteen items are common to cohort studies, case control studies and cross-sectional studies and four are specific to each of the three study designs. Among the 22 items, six are split into several sub-items. One point was attributed per item or sub-item when the study fulfilled the criteria. The maximum score achievable was 32, then converted into percentage. \n\n Statistical analysis was conducted using Comprehensive Meta-analysis software (version 2, Biostat Corporation) [20, 21, 22, 23] and Stata software (version 13, StataCorp, College Station, US). Baseline characteristics were summarized for each study sample and reported as mean (standard-deviation) and number (%) for continuous and categorical variables respectively. Heterogeneity in the study results was evaluated by examining forest plots, confidence intervals (CI) and using formal tests for homogeneity based on the I statistic, which is the most common metric for measuring the magnitude of between-study heterogeneity and is easily interpretable. I values range between 0% and 100% and are typically considered low for <25%, modest for 25-50%, and high for >50%. This statistical method generally assumes heterogeneity when the p-value of the I test is <0.05. For example, a significant heterogeneity may be due to the variability between the characteristics of the studies such as those of the participants (age, sex, etc), the type of biomarkers, the type of glaucoma, or the origin of the sample (aqueous humor or serum). Random effects meta-analyses (DerSimonian and Laird approach) were conducted when data could be pooled [24] . P values less than 0.05 were considered statistically significant.\n\n We conducted meta-analysis on the levels of oxidative and antioxidative stress markers in chronic glaucoma patients and healthy controls. We stratified these meta-analyses on the type of biomarkers, the type of glaucoma, and the sample origin (aqueous humor or serum). We described our results by calculating the effect size (ES, standardized mean differences-SMD) of the oxidative and antioxidative stress markers for each dependent variable [24] . An ES is defined as a unitless measure of the levels of the stress markers centered at zero if the stress marker levels in chronic glaucoma patients are not different from those in healthy controls. A positive ES denoted improved performance. A scale for ES has been suggested with 0.8 reflecting a large effect, 0.5 a moderate effect, and 0.2 a small effect [25] .\n\n For rigor, funnel plots of these meta-analyses were used to search for potential publication bias.", "qa": [["12_9631605_1_1", "How were the databases searched and what were the inclusion criteria for selecting articles related to oxidative stress and glaucoma?\n", "The databases PubMed, Cochrane Library, Science Direct, and Embase were searched using specific keywords related to oxidative stress and glaucoma without limiting the search to specific years. Articles needed to be case-control studies focusing on measuring oxidative or antioxidative stress markers in glaucoma patients and healthy controls to be included. There were no restrictions based on sample size, language, regional origin, or the nature of the control group."], ["12_9631605_1_2", "What criteria were used to assess the quality of reporting in the selected studies, and what method was employed for statistical analysis in the meta-analysis conducted?\n", "The quality of reporting in the selected studies was assessed using the \"STrengthening the Reporting of OBservational studies in Epidemiology\" (STROBE) criteria, which consists of a checklist of 22 items related to various sections of articles. Statistical analysis in the meta-analysis was conducted using Comprehensive Meta-analysis software and Stata software. Baseline characteristics of study samples were summarized, and heterogeneity in study results was evaluated using forest plots, confidence intervals, and the I statistic."], ["12_9631605_1_3", "How were the results of the meta-analysis on oxidative and antioxidative stress markers in chronic glaucoma patients and healthy controls described, and what scale was used to interpret the effect size?\n", "The results of the meta-analysis were described by calculating the effect size (ES, standardized mean differences-SMD) of oxidative and antioxidative stress markers for each dependent variable. The ES is a unitless measure centered at zero, with positive values denoting improved performance. A scale for ES was used, with 0.8 indicating a large effect, 0.5 a moderate effect, and 0.2 a small effect. Funnel plots were also utilized to search for potential publication bias in the meta-analyses."]]}, {"passage_id": "0_16153140_3", "passage": "Within sites, LA participants reported significantly more misuse of any hydrocodone than any oxycodone (87% vs 71%; McNemar \u03c7 2 (1)= 22.0, P<0.001). Misuse of any opioid substitution medications, such as methadone or buprenorphine, was reported by less than half of all participants, while NY participants reported significantly more misuse of Suboxone (34% vs 17%, P<0.001) and Subutex (14% vs 6%, P<0.01) than LA.\n\n Xanax was the most frequently misused tranquilizer, followed by Valium and Klonopin. NY participants reported significantly more misuse of Klonopin (60% vs 41%, P<0.001), while LA participants reported significantly more misuse of Seroquel (50% vs 38%, P<0.05). Adderall was the most frequently misused stimulant followed by Ritalin, Concerta, and Dexedrine. NY participants reported significantly more misuse of Adderall (75% vs 60%, P<0.001), Ritalin (51% vs 41%, P<0.05), and Concerta (23% vs 15%, P<0.05) than LA.\n\n *There are notable differences in the potencies of prescription opioids. For instance, oxycodone is seven to twelve times stronger than codeine, while hydrocodone is two to eight times stronger than codeine assuming similar modes of administration. 23 [ \n\n Frequencies of lifetime modes of administering specific categories of prescription drugs and illicit drugs are presented in Table 5 . Participants administered prescription drugs via a range of modalities other than swallowing: snorting was more commonly reported than either injecting or smoking. Opioids were more frequently sniffed, smoked, and injected than either stimulants or tranquilizers. NY participants were significantly more likely to sniff opioids (68% vs 53%, P<0.001) and stimulants (58% vs 43%, P<0.01) than LA. LA participants more commonly smoked all three types of drugs compared to NY participants, but only opioids exhibited a significant difference (27% vs 14%, P<0.001). No site differences regarding injecting prescription drugs were observed; overall, approximately one-quarter of participants ever injected a prescription opioid.\n\n Comparing histories of injecting illicit drugs revealed more site differences. NY participants reported significantly greater frequency of injecting heroin (41% vs 30%, P<0.05), cocaine (32% vs 17%, P<0.001), and crack (16% vs 9%, P<0.05), while LA participants reported significantly greater frequency of injecting methamphetamine (27% vs 12%, P<0.001). Comparing injecting heroin and opioids within sites, NY participants reported significantly greater frequency of injecting heroin than opioids (41% vs 29%, P<0.01), whereas no significant differences in LA were observed.\n\n Polydrug use, or combining drugs during a drug-using event, was a common feature of prescription drug misuse: a majority of misusers of both opioids and tranquilizers reported that combining these drugs with other drugs was typical in the past 12 months. No site differences were observed. Substituting with prescription drugs, e.g., prescription opioids, when other drugs, e.g., heroin, could not be located was commonly reported: half of the sample's opioid users reported using an opioid as a substitute, though fewer tranquilizer and stimulant users reported this practice. No site differences were found. Substituting with other drugs when prescription drugs could not be found was less frequently reported. However, among those that did, LA participants reported significantly greater frequency of using another drug as a substitute for opioids (36% vs 27%, P<0.05), tranquilizers (28% vs 19%, P<0.05), and stimulants (22% vs 13%, P<0.05) than NY participants.\n\n Frequencies of 90-day misuse of prescription and illicit drugs are presented in Table 6 . All participants misused at least one prescription drug within the past 90-days (an enrollment criterion for the study). Opioids and tranquilizers were the most frequently misused, followed by stimulants. No significant differences were found by site. Participants also reported frequent use of illicit drugs in the past 90 days.", "qa": [["0_16153140_3_1", "What are the differences in misuse of opioid substitution medications between participants in LA and NY?\n", "Less than half of all participants reported misuse of any opioid substitution medications, such as methadone or buprenorphine. However, NY participants reported significantly more misuse of Suboxone and Subutex compared to LA participants."], ["0_16153140_3_2", "How do the participants in LA and NY differ in terms of the misuse of tranquilizers?\n", "Xanax was the most frequently misused tranquilizer, followed by Valium and Klonopin. NY participants reported significantly more misuse of Klonopin, while LA participants reported significantly more misuse of Seroquel."], ["0_16153140_3_3", "What are the differences in the modes of administering prescription drugs between participants in LA and NY?\n", "Participants administered prescription drugs via a range of modalities other than swallowing, with snorting being more commonly reported than injecting or smoking. NY participants were significantly more likely to sniff opioids and stimulants compared to LA participants. LA participants more commonly smoked all three types of drugs compared to NY participants, but only opioids exhibited a significant difference."]]}, {"passage_id": "27_2063232_1", "passage": "Now consider the variant positions in that gene one position at a time from left to right or using some other ordering. For the first position, all those samples with a 0 at the position are put on the left branch of the root, and all those with a 1 are put on the right branch. The two leaves of this tree now contain BMGs of length one 1. Now step through all the other variable positions for each leaf. If there is any variation at the current position among the individuals at a leaf, the leaf is split in two, with all individuals with a 0 on the left branch and all individuals with a 1 on the right branch. Repeat for all the variable sites at the gene. After k sites the leaves contain BMGs of length k. This procedure is illustrated in Figure 2 . The multilocus genotypes that map to multilocus genotype codes for our example data are shown in Table 1 .\n\n Obtaining a tree test statistic is a two-stage process. First, we require values of partial test statistics defined on the leaves and internal nodes of our tree. A variety of test statistics are available, but we are restricted to those that depend only on values of a trait at a node and its descendants. Using information at ancestral nodes or on nodes on other branches of the tree (such as other individuals from the same population) is not possible within this framework. We use the term disjoint here for a set of nodes in which none of the nodes is the ancestor of another. For further details see Sevon et al. [6] .\n\n Although many partial test statistics are possible, we take a simple one, the z score: \n\n The example data set is shown in Figure 2 .\n\n where x ij , j = 1, \u2026, n i , are the values of the trait at node i and x and s are the sample mean and standard deviation, respectively, of the trait over all individuals. Two trees with the respective z scores at the nodes are shown in Figure 3 .\n\n The QTLTree test statistic over the whole tree, S k , is defined as the maximum value of:\n\n where the summation is over m disjoint nodes where m \u2264 k, and f is some function. For our analyses, we take:\n\n that is, f y y ( ) = , but other approaches are possible and implemented in our program. As a side effect of the calculation, we obtain intermediate values for\n\n Typically for our tests, we take k = 10. \n\n The null distribution of S k is not available. Because the GAW17 data were sampled from different populations, a straightforward randomization was not appropriate and individuals were randomized within populations; that is, the traits were randomly relabeled within each population so that the mean and standard deviation of the traits stayed the same within populations across replicate permutations. The seven different populations used were Luhya, Yoruba, Japanese, Denver Chinese, Han Chinese, CEPH (European-descended residents of Utah), and Tuscan. We calculate statistical significance with 10 6 randomized replicates per gene for the phenotype data set. We perform power calculations over multiple data sets using 10 5 replicate simulations over all 200 data sets. One hundred thousand replicate permutations for all 3,205 genes of a single data set typically takes about 60 minutes, and these calculations are easy to perform in parallel, making them feasible for whole-genome data. The R package QTLTree [8] is available from IJW's website (http://www.staff.ncl.ac.uk/i.j.wilson).\n\n \n\n The backwards model selection results in three additional derived phenotypes: Q1A, the residuals after fitting Age and Smoke; Q1B, the residuals after fitting Age + Smoke + PC1 + PC4; and Q4A, the standardized residuals after fitting a linear model with predictors Age + Sex + Smoke to Q4. No nonconstant terms were kept in models for Q2, and no extra PC terms were kept for Q4.\n\n Analysis of data set 1 Table 2 gives the genes with the highest significance levels for analyses of the three Q1-related traits and Q2. Although for the uncorrected trait the gene with rank 1 is true, the rest of the top 10 ranked genes are all unrelated to the trait and are significant after Bonferroni correction (p < 5 \u00d7 10 Figure 2 Example of multilocus genotype tree. This tree is constructed by considering sites left to right along the binary multilocus genotype (BMG). The root of the tree contains all 100 individuals. As we consider successive SNPs, all nodes containing both 0 and 1 individuals at the SNP are split, with individuals carrying a 1 put on the top branch and those carrying a 0 on the lower branch.", "qa": [["27_2063232_1_1", "How does the QTLTree test statistic calculate the maximum value over the whole tree?\n", "The QTLTree test statistic, S_k, calculates the maximum value by summing the values of a function, f, over m disjoint nodes, where m is less than or equal to k. The function, f, is typically taken as f(y,y) = y^2, but other approaches are possible. The QTLTree test statistic is used to assess the significance of genetic associations in the data."], ["27_2063232_1_2", "What is the purpose of the backwards model selection in the analysis of the derived phenotypes?\n", "The backwards model selection is used to derive additional phenotypes by fitting linear models with different predictors. The residuals after fitting these models are used to create new phenotypes, such as Q1A, Q1B, and Q4A. This process helps to identify the effects of specific predictors on the traits of interest and allows for further analysis and interpretation of the data."], ["27_2063232_1_3", "How is statistical significance calculated in the analysis of the phenotype data set?\n", "Statistical significance is calculated by performing randomized replicates per gene for the phenotype data set. The traits are randomly relabeled within each population, while keeping the mean and standard deviation of the traits the same within populations across replicate permutations. The null distribution of the QTLTree test statistic is not available, so significance is determined by comparing the observed test statistic to the distribution of test statistics obtained from the randomized replicates."]]}, {"passage_id": "7_53721989_0", "passage": "During the last 40 years, China has undergone rapid urbanization, with the urban population increasing from 17.92% in 1978 to 57.35% in 2016 [1] . In the process of rapid urbanization, land issues, characterized by the decrease in quantity and quality, have been one of the most noticeable challenges [2] . The quantity and quality of cultivated land is closely related to national food security, sustainable agricultural production and public health [3, 4] . Hence, in response to these concerns, the Chinese central government launched two principal campaigns with the aim of maintaining the quantity and quality of cultivated land across China [5] . Cultivated land protection has thus become a pressing concern.\n\n As the basic decision-making units that could directly control land use and management, farm households play an important role in cultivated land protection [6] , especially in raising the quality of cultivated land [7] . As an actor in the process of economic development, their decision on land use has been affected by the external context, e.g., economic policies relating to urbanization. In other words, economic policies relating to urbanization do not result in land quality change directly. Instead, they may affect land quality change by exerting influence on farmers' land-use behavior.\n\n A small amount of literature has studied the effects of urbanization and the driving forces of farmers' land-use behavior and cultivated land quality change [7] [8] [9] [10] [11] [12] [13] . For example, using spatial analysis from the perspective of ecology and econometric analysis, respectively, Liang et al. and Deng et al. analyzed the impacts of urbanization on farmland changes [2, 14] . They found that rapid urbanization, characterized by the changes of economic structure, social structure, employment structure and rural land institution, was one of the driving forces of farmland loss and fragmentation. By designing a conceptual framework, Kong et al. analyzed the mechanism of farmers' land use decision-making. They concluded that farmers' land-use behavior, including land use pattern and land quality protection, was determined by the land use target (farmers' demand for food production, profit or both) [8] . Farmers' land-use behavior has been widely regarded as a key influencing factor of household welfare [9] [10] [11] . As the human activities' intervention on land increases, the effect of farmers' land use behavior, especially plantation structure and land-related inputs [4] , on land quality and the agro-ecological system has received much attention [7, 12, 13, 15] . Take the study of Chen et al., for example: based on household survey and the economic statistical method, they found that farmers' land-use behavior, including the choice of land-use type, the use of fertilizers and crop residue management, had significant impacts on the soil nutrient balances [7] .\n\n These studies have provided insights into the relationship between urbanization, farmers' land-use behavior and cultivated land quality. However, there is room for improvement. First, rare studies have clarified the mechanism of how farmers' land-use behavior may affect land quality in the context of urbanization. Second, to the best of our knowledge, no study has yet distinguished the direct and indirect effects of urbanization, farmers' land-use behavior and cultivated land quality. Third, most of the extant literature employs spatial analysis or econometric methods to examine the links among the three factors. However, the inter-correlations among urbanization, farmers' land-use behavior and cultivated land quality involve multi-variable causal effects. Those mentioned methods neglect the possibility that sociological factors may also affect household economic behavior and land quality and thus may not address the complexity sufficiently. A structural equation model (SEM) may cover this shortage.\n\n To fill the gaps in this study, a SEM was constructed to capture the inter-links among urbanization, farmers' land-use behavior and land quality. This was achieved by using a household survey and soil sampling. The conceptual framework of the study is summarized in the next section.\n\n \n\n Originally developed by the United Nations to assess and monitor sustainability (the pressure-state-response framework), an extended 'driver-pressure-state-impact-response' (DPSIR) framework is a tool for detailed analysis that integrates economic, social and natural systems into a systemic approach. The DPSIR method presents mechanisms for analyzing and depicting environmental problems in an integrative way [16] [17] [18] [19] . Extracting from the DPSIR framework, we build a 'pressure-response-impact' (PRI) framework (see Figure 1) which could be applied to analyze an individual household's behavior and is more suitable to our research question.", "qa": [["7_53721989_0_1", "How has rapid urbanization in China impacted the quantity and quality of cultivated land?\n", "Rapid urbanization in China has led to a decrease in both the quantity and quality of cultivated land. As the urban population has increased over the past 40 years, the availability of land for agriculture has decreased. This has raised concerns about national food security, sustainable agricultural production, and public health. The decrease in cultivated land quantity and quality is a significant challenge that needs to be addressed."], ["7_53721989_0_2", "What role do farm households play in the protection of cultivated land?\n", "Farm households are crucial decision-making units that directly control land use and management. They play an important role in the protection of cultivated land, particularly in raising its quality. Economic policies related to urbanization can influence the decision-making of farm households regarding land use. While economic policies do not directly cause changes in land quality, they can indirectly impact land quality by influencing farmers' land-use behavior."], ["7_53721989_0_3", "How does farmers' land-use behavior affect land quality in the context of urbanization?\n", "Farmers' land-use behavior, including land use patterns and land quality protection, can have significant impacts on land quality in the context of urbanization. Studies have shown that farmers' choices regarding land-use types, the use of fertilizers, and crop residue management can affect soil nutrient balances. As human activities intervene in land use, the impact of farmers' land-use behavior on land quality and the agro-ecological system becomes increasingly important. Understanding the relationship between farmers' land-use behavior and land quality is crucial for addressing the challenges posed by rapid urbanization."]]}, {"passage_id": "28_28403965_0", "passage": "remaining respondents were self-taught or learned by observation only.\n\n Wang et al. evaluated EUS trainees' evolution prospectively. Compared with pretraining, the proportion of trainees who succeeded in locating each structure after the training were, respectively, celiac axis (36% vs. 80.5%), pancreatic body and tail (51.5% vs. 80.5%), splenic vein and artery (48.5% vs. 84%), left kidney (60% vs. 83%), and spleen (47% vs. 83%). They concluded that a structured training program signifi cantly improved the successful localization of structures. [3] A survey of practicing endosonographers in various parts of the Asia-Pacifi c region outside Japan was conducted in 2006. Seventy one of 87 physicians surveyed responded. They had performed a median of 500 procedures in their career; 49.3% were self-taught and only 22.5% had undergone a formal EUS fellowship of at least 6 months. Ninety percent believed that a formal EUS fellowship was needed to acquiring competence, with a minimum number of supervised procedures performed over a minimum amount of time (median 6 months). [4] A survey of Latin American endosonographers ENDOSCOPIC ULTRASOUND / JAN-FEB 2016 / VOL 5 | ISSUE 1 demonstrated that 48.6% of respondents had more than 6 months of training. Thirty-seven percent of respondents thought at least 6 months of formal training was necessary to acquire competence. Additionally, the majority of respondents (64%) felt that more than 50 procedures for pancreatic-biliary lesions were necessary. [5] \n\n There are currently no Canadian guidelines for EUS credentialing. Current Canadian guidelines require 150 gastroscopies [100 unassisted, 20 nonvariceal bleeding, 20 variceal bleeding, 20 esophageal dilatation, and 20 percutaneous endoscopic gastrostomy (PEG) tube placement], [6] 150 colonoscopies, (100 unassisted), [7] 30 flexible sigmoidoscopies for competency, [8] and 200 endoscopic retrograde cholangiopancreatographies (including 80 sphincterotomies and 60 stent placements). [9] EUS training guidelines have been adopted in the United States (US) by the American Society for Gastrointestinal Endoscopy (ASGE) and in the United Kingdom (UK) by the British Society of Gastroenterology (BSJ) [ Table 1 ]. In the US, 150 cases are required, including 75 pancreato-biliary cases, 75 mucosal tumors, and 40 submucosal abnormalities. The US guidelines also recommend 50 EUS fine needle aspiration (FNA) cases (25 pancreatic). [10] The UK guidelines recommend that EUS trainees perform 250 supervised procedures, including 80 luminal cancers, 20 submucosal lesions, and 150 pancreatobiliary cases (at least half of which are likely pancreatic adenocarcinomas). A total of 75 EUS-FNA procedures should be performed, of which 45 likely should be pancreatic adenocarcinomas. [11] A thorough review on training in EUS-FNA was published by Paquin in 2013. It concluded that formal training in EUS-FNA is recommended in order to maximize profi ciency, \"hands-on\" training in humans should produce the best results, and that current EUS-FNA guidelines be tested to determine whether current minimal training thresholds need upgrading. [12] \n\n As stated previously, ASGE recommendations for EUS include 150 supervised cases. However, recent studies have demonstrated that the learning curve for mastery may be much more than previously thought. A study by Wani et al. evaluated the performance of fi ve advanced endoscopic trainees (who had between 175 and 402 EUS procedures during training). The study observed substantial variability in the numbers needed to achieve competency, with only two trainees showing acceptable performance after 225 and 196 cases. None of the trainees achieved training guideline goals after the recommended minimal 150 procedures. [13] Thus, some experts question the numbers required to obtain competency. [14] A study by Eloubeidi and Tamhane showed that after 1 year of formal EUS training (300 supervised cases and 45 EUS-FNA) the median number of EUS-FNA passes needed to achieve a diagnosis decreased significantly after 100 additional FNA procedures and that complication rates decreased after 200 additional cases.", "qa": [["28_28403965_0_1", "What are the recommended guidelines for EUS training in the United States and the United Kingdom?\n", "In the United States, the American Society for Gastrointestinal Endoscopy (ASGE) recommends a minimum of 150 supervised cases for EUS training, including 75 pancreato-biliary cases, 75 mucosal tumors, and 40 submucosal abnormalities. Additionally, 50 EUS fine needle aspiration (FNA) cases, with 25 of them being pancreatic, are recommended. In the United Kingdom, the British Society of Gastroenterology (BSG) suggests that EUS trainees should perform 250 supervised procedures, including 80 luminal cancers, 20 submucosal lesions, and 150 pancreatobiliary cases, with at least half of them being pancreatic adenocarcinomas. A total of 75 EUS-FNA procedures, with 45 of them being pancreatic adenocarcinomas, should also be performed."], ["28_28403965_0_2", "What is the learning curve for mastery in EUS and how many procedures are needed to achieve competency?\n", "Recent studies have shown that the learning curve for mastery in EUS may be more extensive than previously thought. The number of procedures needed to achieve competency varies among individuals. A study observed that advanced endoscopic trainees required between 175 and 402 EUS procedures to show acceptable performance. None of the trainees achieved the recommended minimal 150 procedures to meet training guidelines. Another study found that after 1 year of formal EUS training, the median number of EUS-FNA passes needed to achieve a diagnosis decreased significantly after 100 additional FNA procedures. Complication rates also decreased after 200 additional cases."], ["28_28403965_0_3", "Are there any Canadian guidelines for EUS credentialing?\n", "Currently, there are no Canadian guidelines for EUS credentialing. However, Canadian guidelines for other endoscopic procedures exist. These guidelines require a certain number of gastroscopies, colonoscopies, flexible sigmoidoscopies, and endoscopic retrograde cholangiopancreatographies to demonstrate competency in those procedures. EUS training guidelines have been adopted in the United States by the ASGE and in the United Kingdom by the BSG."]]}, {"passage_id": "21_8318063_1", "passage": "As shown by the micro-CT reconstructions, treatment with 1 ng of rhTNF led to improved healing and earlier remodeling as evidenced by a more compact and mineralized fracture callus ( Fig 1D) .\n\n We also found that augmented fracture healing was only evident when rhTNF at 1 ng was administered at the fracture site over the first 24 h (Fig 1B) . This would be particularly relevant for clinical translation as this would enable treatment at the time of reduction and stabilization of the fracture.\n\n To confirm the role of TNF in fracture healing in vivo, we inhibited endogenous TNF by either systemic administration of a neutralizing antibody to TNF, TN3, or local injection of recombinant murine IL-10 (rmIL-10), which also inhibits TNF expression and release (Smallie et al, 2010) , at the fracture site. As shown in Fig 1C, the relative callus mineralization was reduced by both treatments at day 28. The micro-CT reconstructions showed that systemic anti-TNF led to poor bridging across the fracture site and an incomplete and poorly mineralized callus, whereas local rmIL-10 treatment led to a large, unmineralized callus, the hallmarks of an immature callus (Fig 1D) . These observations are consistent with the augmented callus maturation seen in mice treated with 1 ng of TNF.\n\n TNF is expressed during the early inflammatory response by innate immune cells TNF is released as part of the early inflammatory response to the bone injury as it is for other injuries and stresses (Kon et al, 2001) and is an important mediator in fracture repair (Gerstenfeld et al, 2003a; Glass et al, 2011) . However, the precise quantities, and spatial and temporal sequences of release as well as its role in fracture healing remain unclear. We found that circulating serum levels of TNF did not differ significantly from no injury controls up to 72 h post-fracture ( Supplementary Fig S1A) , indicating that the level of trauma induced by the isolated tibial fracture in our murine model is insufficient to lead to a systemic inflammatory response. To assess the local cytokine environment at the fracture site, murine fracture supernatants were produced by incubating fractured tibiae in media as described previously (Glass et al, 2011) . Consistent with our published findings in human fracture supernatants (Glass et al, 2011) , the levels of TNF were very low (< 2 pg/ml, the level of detection of the MSD chemiluminescent system).\n\n Our observation that TNF inhibition impaired fracture healing in vivo suggests that endogenous TNF is expressed locally, albeit at a low level. Hence, we employed in situ hybridization on histological sections of the murine fracture site (Fig 1E-G) to enable identification of the cellular sources of TNF in vivo. We found that TNF was expressed within 15 min of injury, co-localizing first with endothelial cells and neutrophils (Fig 1F) . The neutrophils were identified by their polymorphonuclear morphology as well as by positive staining with anti-neutrophil elastase or anti-Ly6G (Fig 2B) . From day 3 onwards, TNF expression co-localized with cells of the monocyte/macrophage lineage (F4/80 + ) ( Fig 1G) . Neutrophils were the predominant cell type present before day 3 (at 3 h, 24 h, and 3 days) with no F4/80 + cells identified at this stage, while the latter were the predominant cell type after day 3 (day 5 and day 7) as shown by the representative sections in Fig 1G. Neutrophil recruitment occurs following fracture and promotes fracture repair\n\n As recruitment of neutrophils represents a key early event during the inflammatory response (Nathan, 2006) , we investigated their role in fracture healing. First, we assessed the systemic mobilization of neutrophils in our murine fracture model. Blood neutrophil count increased within 30 min of injury and peaked at 3 h following fracture (Fig 2A) . Next, mice were treated with a validated and specific Ly6G-blocking antibody (Daley et al, 2008) . This effectively inhibited the mobilization of neutrophils into the systemic circulation as well as the local recruitment of neutrophils to the fracture site (Fig 2B and C) . Anti-Ly6G treatment was associated with significant impairment of fracture healing.", "qa": [["21_8318063_1_1", "What is the role of TNF in fracture healing?\n", "TNF, or tumor necrosis factor, is expressed during the early inflammatory response to bone injury and is an important mediator in fracture repair. It is released by innate immune cells and plays a role in the healing process. In the provided passage, it is shown that treatment with rhTNF (recombinant human TNF) leads to improved healing and earlier remodeling of the fracture callus. Inhibition of endogenous TNF, either through systemic administration of a neutralizing antibody or local injection of recombinant murine IL-10, results in reduced callus mineralization and poor bridging across the fracture site. These observations suggest that TNF is necessary for proper fracture healing."], ["21_8318063_1_2", "What are the cellular sources of TNF in fracture healing?\n", "In the provided passage, in situ hybridization on histological sections of the murine fracture site is used to identify the cellular sources of TNF in vivo. It is found that TNF is expressed within 15 minutes of injury, initially co-localizing with endothelial cells and neutrophils. Neutrophils are the predominant cell type present before day 3 of fracture, while cells of the monocyte/macrophage lineage become the predominant cell type after day 3. This suggests that endothelial cells, neutrophils, and monocytes/macrophages are the cellular sources of TNF during fracture healing."], ["21_8318063_1_3", "How does the inhibition of neutrophil recruitment affect fracture healing?\n", "Neutrophils play a key role in the early inflammatory response and are recruited to the fracture site. In the provided passage, it is shown that systemic mobilization of neutrophils increases following fracture, and inhibiting their recruitment through treatment with a Ly6G-blocking antibody impairs fracture healing. This suggests that neutrophils are important for proper fracture healing."]]}, {"passage_id": "80_23609746_1", "passage": "A probability value less than 0.05 was considered significant.\n\n \n\n There were 55 men and 17 women whose mean ages at surgery were 61 and 68 years, respectively. Approximately 85% of the patients were older than 50 years of age. Most of the men were in their seventh decade of life; this was followed by those in their sixth decade and those in their eighth decade. Most of the women, however, were in their seventh and eighth decades of life. The most common initial symptom was a tingling sensation, numbness, or pain in the lower extremities, which was present in 49% of the patients. Twenty-five percent of patients complained of gait disturbance due to lower-limb weakness or spasticity, and 11% complained of back pain. The mean preoperative duration of symptoms was 22 months ( Table 1) .\n\n The mean preoperative JOA score was 5.1 (range 0-9). The relationships between the preoperative neurological status and various factors are shown in Table 2 . There were no statistically significant differences between the preoperative JOA score and sex, age, or preoperative duration of symptoms, although the scores documented in the patients in whom symptom duration was shorter than 6 months tended to be lower in patients in whom symptoms had been present for a longer duration. Of the 25 patients in whom symptoms had been present for 6 months or less, 40% had severe myelopathy whereas in the other symptom-duration groups, 14 to 18% of the patients suffered severe myelopathy.\n\n Surgically decompressed levels considered to be responsible for OLF-induced myelopathy are shown in Fig. 1 . There were 104 affected intervertebral disc levels in total: the T10-11 and T11-12 segments in 62%, the T9-10 level or lower in 75%. In the upper thoracic spine, OLF was mostly located at the T2-3 level, which accounted for 10% of all the decompressed ligamenta flava.\n\n The choice of surgical procedure was based on the CT classification of OLF; the lesion was categorized as lateral, extended, enlarged, fused, or tuberous (Fig. 2) . 15, 17 In the first three types, the ossifications in the bilateral ligamentum flavum did not fuse at the middle of the spinal canal or exist unilaterally. Thus, the ossified ligament could be removed by either fenestration or French-door laminectomy. On the other hand, in the latter two types, the ossifications of both sides fused so that they were removed by en bloc laminectomy. Through fenestration, the entire ligamentum flavum was removed through partial laminectomy and partial resection of the medial margin of the facet joint. 19 The laminectomy procedure was most common followed by fenestration (Table 1) . Before 1992, decompression in all 13 patients was accomplished via a laminectomy. Thereafter, fenestration was increasingly used and accounted for approximately half of all OLF surgeries. In nine patients, dural tears occurred during surgery. Eight of these had an ossified dura mater that could not be dissected from the ossified ligamentum flavum (Fig. 3) . The disrupted dura mater was repaired by either primary suture or by placing an artificial dural patch. No patient needed additional treatment for cerebrospinal fluid leakage.\n\n Postoperatively, the JOA scores improved to 7.9 (range 0-11) and the recovery rate averaged 47% (range \u03ea38 to 100%) at the last follow-up examination, which was, on average, 46 months (range 3 months-14 years) after surgery. The relationships between the postoperative neurological conditions and the recovery rate and various patient factors are shown in Table 3 . The postoperative JOA scores obtained in patients with severe preoperative myelopathy were significantly lower than those documented in patients with moderate and mild myelopathy. Patients in whom the duration of myelopathy was longer as well as elderly male patients tended to have lower postoperative scores. Scores in 66 patients (92%) improved, whereas in three (4%) the score either did not change or had decreased (Fig. 4) . One patient suffered complete paralysis because of a postoperative epidural hematoma. The score in two patients decreased by one because they required support for walking on a level plane or on stairs after surgery. Four patients underwent further spinal surgery: two for OLF myelopathy at different thoracic levels, one for cervical spondylotic myelopathy, and one for lumbar spinal canal stenosis.", "qa": [["80_23609746_1_1", "What are the common initial symptoms experienced by patients with OLF-induced myelopathy?\n", "The most common initial symptoms experienced by patients with OLF-induced myelopathy are tingling sensation, numbness, or pain in the lower extremities, gait disturbance due to lower-limb weakness or spasticity, and back pain."], ["80_23609746_1_2", "What factors were considered in the choice of surgical procedure for OLF-induced myelopathy?\n", "The choice of surgical procedure for OLF-induced myelopathy was based on the CT classification of OLF. The lesion was categorized as lateral, extended, enlarged, fused, or tuberous. For the first three types, the ossified ligament could be removed by either fenestration or French-door laminectomy. For the latter two types, the ossifications of both sides fused and were removed by en bloc laminectomy. Fenestration involved removing the entire ligamentum flavum through partial laminectomy and partial resection of the medial margin of the facet joint."], ["80_23609746_1_3", "What were the postoperative outcomes for patients with OLF-induced myelopathy?\n", "Postoperatively, the JOA scores improved and the recovery rate averaged 47%. The postoperative JOA scores obtained in patients with severe preoperative myelopathy were significantly lower than those documented in patients with moderate and mild myelopathy. Patients with longer duration of myelopathy and elderly male patients tended to have lower postoperative scores. The majority of patients showed improvement in their scores, while a small percentage either did not experience any change or had a decrease in their scores."]]}]