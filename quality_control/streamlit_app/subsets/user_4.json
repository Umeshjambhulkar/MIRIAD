[{"passage_id": "68_406582_8", "passage": "70 In contrast, SNI potentiates the synaptic transmission between parabrachial nucleus-central nucleus of amygdala 71 and PFC, 69 leading to memory deficit and depressive behaviors. It has been proposed that the reduced excitatory synaptic transmission in both hippocampus-and PFC-NAcc pathways, leading to a dysfunction of corticomesolimbic reward circuitry that underlies many of the symptoms of depression. 72 Consistently, optogenetic activation of the PFC-NAcc pathway inhibits neuropathic pain and the affective symptoms produced by SNI. 73 Several lines of evidence show that proinflammatory cytokines, including IL-1b and TNFa, regulate synaptic strength also in a region-dependent manner. Both IL-1b 74 and TNF-a 75 are necessary for induction of LTP at C-fiber synapses in SDH. 76, 77 While the cytokines at pathological concentration inhibit LTP in hippocampus [78] [79] [80] and in frontal cortex. 70 Taken together, peripheral nerve injury and the resultant upregulation of IL-1b may lead to the neuropathic pain, memory deficit, and depression-like behavior via the region-dependent changes in synaptic strength. As neuropathic pain was dissociated with STMD and depression-like behavior in SNI and IL-1b injected rats, we proposed that the changes of synaptic connections in different regions may be variable in a given animals. Further studies are needed for elucidate the mechanisms underlying region-dependent regulation of synaptic strength induced by proinflammatory cytokines.\n\n The upregulation of IL-1b is a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. Hence, IL-1b may be a target for prevention of neuropathic pain and the accompanied cognitive and emotional disorders.\n\n Authors' Contributions WSG, LJW, LJZ, and XGL conceived of the project, designed the experiments. WSG, XW, CLM, and LJZ carried out all experiments. WSG, XW, and MM analyzed the data and prepared the figures. LJZ and XGL supervised the overall experiment. MM, LJW, LJZ, and XGL revised the manuscript. All authors read and approved the final manuscript.\n\n The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\n\n The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work was supported by grants from the National Natural Science Foundation of China (U1201223 and 8137119), Guangdong Province University Outstanding Young Teachers' Training Program (S2013010011889), and from Natural Science Foundation of Guangdong Province, China (Yq2013008).", "qa": [["68_406582_8_1", "How does the upregulation of IL-1b contribute to chronic pain, memory deficits, and depressive behavior in neuropathic conditions?\n", "The upregulation of IL-1b, a proinflammatory cytokine, has been found to be a common cause for chronic pain, memory deficits, and depressive behavior in neuropathic conditions. It is believed that the increased levels of IL-1b lead to changes in synaptic strength in different regions of the brain, such as the hippocampus and frontal cortex, which are involved in the regulation of pain, memory, and mood. These changes in synaptic connections may contribute to the development of neuropathic pain and the accompanying cognitive and emotional disorders."], ["68_406582_8_2", "What is the role of the PFC-NAcc pathway in inhibiting neuropathic pain and affective symptoms?\n", "The PFC-NAcc pathway, which connects the prefrontal cortex (PFC) and the nucleus accumbens (NAcc), has been found to play a role in inhibiting neuropathic pain and affective symptoms. Optogenetic activation of this pathway has been shown to reduce neuropathic pain and the associated emotional symptoms in animal models. This suggests that the PFC-NAcc pathway may be a potential target for the treatment of neuropathic pain and the accompanying affective disorders."], ["68_406582_8_3", "How do proinflammatory cytokines, such as IL-1b and TNF-a, regulate synaptic strength in a region-dependent manner?\n", "Proinflammatory cytokines, including IL-1b and TNF-a, have been found to regulate synaptic strength in a region-dependent manner. For example, IL-1b and TNF-a have been shown to be necessary for the induction of long-term potentiation (LTP) at C-fiber synapses in the spinal dorsal horn (SDH). However, at pathological concentrations, these cytokines can inhibit LTP in the hippocampus and frontal cortex. This suggests that the effects of proinflammatory cytokines on synaptic strength can vary depending on the specific brain region. Further research is needed to fully understand the mechanisms underlying this region-dependent regulation of synaptic strength by proinflammatory cytokines."]]}, {"passage_id": "67_6965586_2", "passage": "1663.51 \u00b1326.83 pg/ml, respectively, P <0.001) and CD (2146.91 \u00b1470.39 pg/ml vs. 1674.55\n\n The Mann-Whitney U test was then used where applicable. Associations between the variables with normal distribution were assessed using the Pearson correlation coefficient, while those between the variables without normal distribution were assessed using the Spearman's rank correlation coefficient. All statistical analyses were conducted using the Statistica 8.0 software (StatSoft Inc., Tulsa, Oklahoma, United States). A P value less than 0.05 was considered statistically significant.\n\n results The study was conducted on 105 patients with IBDs: 50 subjects with CD and 55 with UC, and in controls. The characterisitics of the groups are presented in tAble 1.\n\n Patients with CD were characterized by a lower mean age compared with those with UC (P = 0.008) and controls (P = 0.03). No significant age difference was observed between patients with UC and controls.\n\n In the majority of patients with CD (66%), disease-associated lesions were located both in the small intestine and in the colon. Such complications as enterocutaneous and enteroenteric fistulas and abscesses were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses. The majority of patients (60%) did not undergo any CD-associated surgical procedures. In 52% of patients with UC, disease-associated lesions extended to the splenic flexure (L1), while in 35% of the patients, the lesions involved the colon, Abbreviations: BMI -body mass index, CD -Crohn's disease, CRP -C-reactive protein, SD -standard deviation, sTNFR1 and sTNFR2 -soluble tumor necrosis factor membrane receptors 1 and 2, TNF-\u03b1 -tumor necrosis factor-\u03b1, UC -ulcerative colitis, WBC -white blood cells dIscussIon To our knowledge, there is a limited number of studies on the correlations of TNF-\u03b1 with sTNFR1 and sTNFR2. A positive correlation between serum concentrations of those markers was reported in patients with impaired glucose tolerance and diabetes, 25,26 but we have not found any data concerning correlations between those markers in IBDs.\n\n In the present study, sTNFR1 and sTNFR2 levels were higher in patients with CD and UC compared with controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls.\n\n Other investigators also demonstrated the higher values of sTNFR1 and sTNFR2 in patients with CD and UC compared with controls.\n\n Hadziselimovic et al. 10 showed a correlation between urinary sTNFR1 and sTNFR2 concentrations and the activity of CD and UC as well as therapeutic effects in these diseases. 10 Higher urinary sTNFR1/2 levels were observed in patients with active CD and UC compared with subjects in remission, which was correlated with the CDAI and CAI. the levels of sTNFR1 and sTNFR2 were higher in patients with active CD compared with those with nonactive disease and controls. However, in patients in remission, sTNFR1 and sTNFR2 levels were comparable to those in controls. Similar results were reported by Spoettl et al. 9 and Hudson et al. 10 In contrast, Noguchi et al. 27 performed \u00b1319.35 pg/ml, respectively, P <0.001) compared with the subgroups in remission. There were no differences in TNF-\u03b1, sTNFR1, and sTNFR2 levels depending on disease location and duration\u00b8 smoking status, development of exacerbated or recurrent disease in the follow-up period, and the type of therapy either in CD or UC.\n\n Positive correlations were demonstrated between disease activity, expressed by the CDAI and CAI scores, and sTNFR1 and sTNFR2. The correlation coefficients for both receptors were higher in UC compared with CD. For TNF-\u03b1, a positive correlation with disease activity was noted only in CD (tAbles 3-5, FIGure) .\n\n We also assessed correlations between routine inflammatory markers and disease activity. In the CD group, we found statistically significant correlations with platelet count (r = 0.45), CRP (r = 0.69) and fibrinogen (r = 0.44).", "qa": [["67_6965586_2_1", "What are the potential complications associated with Crohn's disease?\n", "In the majority of patients with Crohn's disease (CD), complications such as enterocutaneous and enteroenteric fistulas and abscesses can occur. These complications were present in 62% of patients with exacerbated CD, while subjects in remission showed no active fistulas or abscesses."], ["67_6965586_2_2", "Are there any correlations between TNF-\u03b1 and soluble tumor necrosis factor membrane receptors 1 and 2 (sTNFR1 and sTNFR2) in inflammatory bowel diseases (IBDs)?\n", "There is limited data on the correlations between TNF-\u03b1 and sTNFR1 and sTNFR2 in IBDs. However, in the present study, sTNFR1 and sTNFR2 levels were found to be higher in patients with CD and ulcerative colitis (UC) compared to controls. TNF-\u03b1 levels were also higher in patients with CD and UC, but a significant difference was observed only between patients with CD and controls."], ["67_6965586_2_3", "What routine inflammatory markers are correlated with disease activity in patients with CD?\n", "In patients with CD, statistically significant correlations were found between disease activity and platelet count, C-reactive protein (CRP), and fibrinogen levels. These markers showed positive correlations with disease activity, indicating their potential as indicators of disease severity."]]}, {"passage_id": "74_5985777_1", "passage": "As an induction agent, it produces a profound depletion of lymphocytes and is associated with more frequent and severe adverse effects, such as neutropenia, thrombocytopenia, thyroid disease, autoimmune hemolytic anemia and other autoimmune diseases [16] [17] [18] . It is hoped that alemtuzumab induction could permit patients to be maintained on unconventional strategy with less intensive immunosuppression, such as tacrolimus monotherapy [19] , steroid-free [20] , steroid and calcineurin inhibitor (CNI) free regimen [21] .\n\n Rituximab is a chimeric monoclonal Ab against CD20, which is expressed on the majority of B cells. It was first approved in 1997 for refractory B cell lymphomas and it is increasingly applied for autoimmune diseases. In the realm of kidney transplant, rituximab has been used in combination with plasmapheresis and IVIG to treat antibody-mediated rejection (AMR), and to desensitize patients with preformed antibodies for ABO-and/or HLAincompatible kidney transplant [22, 23] .\n\n Induction Therapy\n\n Antibody selection should be guided by a comprehensive assessment of immunologic risk, patient comorbidities, financial burden, and the maintenance immunosuppressive regimen. Clinical trials comparing different antibody induction in various patient populations and with different maintenance immunosuppression are recently reviewed by the author [2] . The published data remain in line with the 2009 KDIGO guideline [24] . Lymphocytedepleting antibody is recommended for those with high immunologic risk as outlined in the 2009 KDIGO clinical practice guidelines (sensitized patient, presence of donor specific antibody, ABO incompatibility, high HLA mismatches, DGF, cold ischemia time >24 hours, African-American ethnicity, younger recipient age, older donor age), though it increases the risk of infection and malignancy [24] . For low or moderate risk patients, IL-2R Ab induction reduces the incidence of acute rejection and graft loss without much adverse effects, making its balance favorable in these patients [25] [26] [27] . IL-2R Ab induction should also be used in the high risk patients with other comorbidities (history of malignancy, viral infection with HIV, HBV or HCV, hematological disorder of leucopenia or thrombocytopenia and elderly) that may preclude usage of lymphocyte-depleting antibody safely [28] [29] [30] . Many patients with very low risk (nonsensitized, Caucasian, Asian, well HLA matched, living related donor transplant) may be induced with intrave-nous steroids without using any antibody, as long as combined potent immunosuppressives are kept as maintenance. In these patients, benefits with antibody induction may be too small to outweigh its adverse effects and the financial cost [2, 24, 31] . Clinical comparison trials have not demonstrated any graft or patient survival benefit of using T-cell depleting Ab induction in patients with low immunological risk [2, 24] . Rituximab induction is useful in desensitization protocols for ABO and/or HLA incompatible transplants. Alemtuzumab induction might be more successful for adopting less intensive maintenance protocols. However, the long-term safety and efficacy of unconventional strategy remain to be determined.\n\n \n\n Glucocorticoids have been used for preventing and treating graft rejection since the early 1960s. They have multiple actions. In addition to the nonspecific anti-inflamematory actions, glucocorticoids have critical immunosuppressive effect by blocking T-cell and antigen-presenting cell (APC) derived cytokine expression. Glucocorticoids bind to cytoplasmic receptor to form a complex, which translocates into the nucleus and binds to glucocorticoid response elements (GRE) in the promoter regions of cytokine genes. Glucocorticoids also inhibit the translocation of transcription factor AP-1 and NF-\u03baB into the nucleus. Therefore, production of several cytokines (IL-1, 2, 3, 6, TNF-\u03b1, gamma-interferon) are inhibited [32, 33] . Large dose of glucocorticoids can be given in the perioperative period as induction therapy (methylprednisolone 250 to 500 mg IV), which is usually followed by oral prednisone 30 to 60 mg/day. The dose is tapered over 1 to 3 months to a typical maintenance dose of 5 to 10 mg/day.", "qa": [["74_5985777_1_1", "How do different types of antibody induction therapies in kidney transplant patients vary based on immunologic risk factors and comorbidities?\n", "The selection of antibody induction therapies in kidney transplant patients is influenced by factors such as immunologic risk, patient comorbidities, financial considerations, and the planned maintenance immunosuppressive regimen. High-risk patients, as defined by criteria like sensitization, donor-specific antibodies, ABO incompatibility, and others, are recommended lymphocyte-depleting antibodies despite the increased risk of infections and malignancies. In contrast, low or moderate-risk patients may benefit from IL-2R antibody induction due to reduced rejection rates and graft loss without significant adverse effects. Patients with very low risk profiles, such as nonsensitized individuals with well-matched donors, may not require antibody induction and can be managed with intravenous steroids alongside potent maintenance immunosuppressives."], ["74_5985777_1_2", "What are the mechanisms of action of glucocorticoids in preventing graft rejection in kidney transplant patients?\n", "Glucocorticoids have been utilized for graft rejection prevention and treatment since the 1960s due to their diverse actions. Apart from their general anti-inflammatory properties, glucocorticoids exert critical immunosuppressive effects by inhibiting T-cell and antigen-presenting cell (APC) derived cytokine expression. Upon binding to cytoplasmic receptors, glucocorticoids form complexes that translocate into the nucleus and bind to glucocorticoid response elements (GRE) in cytokine gene promoters. Additionally, glucocorticoids impede the nuclear translocation of transcription factors like AP-1 and NF-\u03baB, leading to the inhibition of cytokine production, including IL-1, IL-2, IL-6, TNF-\u03b1, and gamma-interferon. In kidney transplant settings, glucocorticoids are typically administered in high doses perioperatively as induction therapy, followed by a gradual tapering to a maintenance dose over several months."], ["74_5985777_1_3", "How do rituximab and alemtuzumab differ in their mechanisms of action and clinical applications in kidney transplant patients?\n", "Rituximab is a chimeric monoclonal antibody targeting CD20 on B cells, initially approved for refractory B cell lymphomas and increasingly used in autoimmune diseases. In kidney transplant, rituximab is employed in combination with plasmapheresis and IVIG for treating antibody-mediated rejection and desensitizing patients with preformed antibodies for ABO and/or HLA incompatible transplants. On the other hand, alemtuzumab acts as a lymphocyte-depleting induction agent associated with severe adverse effects like neutropenia, thrombocytopenia, and autoimmune diseases. The use of alemtuzumab induction in kidney transplant aims to enable less intensive immunosuppression strategies, such as tacrolimus monotherapy or steroid-free regimens, though the long-term safety and efficacy of such approaches remain to be fully understood."]]}, {"passage_id": "2_46447229_3", "passage": "To this effect hepcidin has been seen to bind, internalize and inactivate ferroportin 1 at duodenal mature enterocytes (51) . Intestinal iron absorption is thus blocked (Fig. 3) . Whatever the mechanism of action of hepcidin, its absence favors intestinal iron absorption and the release of iron stored in the reticuloendothelial system (RES). This is seen in all situations where this hepatic hormone is low (iron-deficient diet, bleeding, hypoxia, types I, II, III hemochromatosis, etc). On the contrary, increased hepcidin (inflammation, infection, exogenic iron overload, liver adenomatosis, etc.) (52) results in decreased intestinal iron absorption and iron retention in RES cells. During inflammation and infection hepatic hepcidin synthesis increases (52) , which translates into decreased intestinal iron absorption (53, 54) , iron retention within macrophages (55) , and anemia (45, 53, 56) .\n\n A number of mutations in the HAMP gene have been found in some patients with JH (57, 58) . A change G\u2192A in the sequence +14 at the 5'-untranslated end (5'-UTR) has been reported in a Portuguese family, which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA, and probably results in the formation of a new, abnormal, unstable and degradable peptide (59) . Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin by convertases (60) , particularly by furin, and 212G\u2192A (G71D), which alters this peptide's structure and function (61) .\n\n In most patients with JH the disorder is linked to chromosome 1q (57) , but the gene involved has remained unknown until very recently. In 2004, Papanikolaou et al. (62) published the results of a thorough study of chromosome 1q, where they unveiled a locus of previously un- Hepcidin is a peptide expressed by gene HAMP in liver cells in response to infection and iron overload. Hemojuvelin, protein HFE, and transferrin receptor 2 (TfR2) also contribute to increase hepcidin production. This slows the passage of iron through enterocytes (intestinal absorption) and the release of iron from macrophages. In these cells iron stems from the degradation of phagocyted old red blood cells. Hepcidin has been suggested to exert these effects by internalizing ferroportin 1 (FP-1) within cells.\n\n known function, LOC148738, which was associated with JH. The gene involved was initially designated HFE2, and more recently HJV. In this gene, which was made up of four exons separated by three introns, they found numerous mutations, and one of them, G320V, was present in all patients of Greek, Canadian, and French descent with JH (62) (62) . The mechanism of action of hemojuvelin is unknown, but seems to be closely linked to that of hepcidin. It is known not to be a hepcidin receptor (62) , as it is not expressed in organs where hepcidin acts (intestine, spleen) (62) . When mutations exist in the HJV gene, urine hepcidin decreases (62) . In JH urine hepcidin is deeply reduced despite the fact that body iron is strongly elevated. Hemojuvelin is therefore thought to be a hepcidin-modulating protein, so that the former's decreased levels or inactivity results in the latter's reduced presence. Such decreases would be responsible for the increased intestinal iron absorption and iron overload found in patients with JH (62).\n\n Since Most of them were located in exons 3 and 4, particularly within the molecular region corresponding to the von Willebrand-like domain (66) , and many were determinant of transcription termination. These mutations included a deletion of 13 base-pairs (CGGGGCCCCGCCC), which may be expected to result in a nil phenotype. They found two mutations in another patient -220delG, which creates a transcription end signal at 113, and 806-807insA, which leads to molecule truncation at position 331 and the formation of a 310-aminoacid molecule.", "qa": [["2_46447229_3_1", "What is the role of hepcidin in iron absorption and retention?\n", "Hepcidin is a peptide expressed by the HAMP gene in liver cells in response to infection and iron overload. It binds to and inactivates ferroportin 1, a protein involved in the transport of iron. This blocks intestinal iron absorption and promotes the retention of iron in macrophages. In situations where hepcidin levels are low, such as iron-deficient diet or certain types of hemochromatosis, intestinal iron absorption is increased. Conversely, increased hepcidin levels, such as during inflammation or exogenic iron overload, result in decreased intestinal iron absorption and iron retention in macrophages."], ["2_46447229_3_2", "What are some mutations in the HAMP gene associated with Juvenile Hemochromatosis (JH)?\n", "Several mutations in the HAMP gene have been found in patients with JH. These include a change in the sequence +14 at the 5'-untranslated end (5'-UTR), which creates a new AUG sequence that inhibits the translation of normal hepcidin mRNA. Other mutations reported include R56X, which creates a \"stop codon\", the deletion of guanine 93, 175G\u2192C (R59G), which precludes prohepcidin activation into hepcidin, and 212G\u2192A (G71D), which alters the structure and function of the peptide. These mutations can lead to decreased levels or inactivity of hepcidin, resulting in increased intestinal iron absorption and iron overload in patients with JH."], ["2_46447229_3_3", "What is the role of hemojuvelin in the regulation of hepcidin?\n", "Hemojuvelin is a protein that contributes to the increase in hepcidin production. It is closely linked to the mechanism of action of hepcidin but is not a hepcidin receptor. When mutations exist in the HJV gene, urine hepcidin decreases. Hemojuvelin is thought to be a hepcidin-modulating protein, and its decreased levels or inactivity result in reduced hepcidin presence. This decrease in hepcidin levels is responsible for the increased intestinal iron absorption and iron overload found in patients with Juvenile Hemochromatosis (JH)."]]}, {"passage_id": "0_1332430_2", "passage": "[3] [4] [5] Currently, substantiated indications for iNO include the treatment of hypoxic respiratory failure of the newborn (PPHN), 6 -9 and the assessment of pulmonary vascular reactivity in patients with pulmonary hypertension. 10 To date, the U.S. Food and Drug Administration has approved nitric oxide only for the treatment of term and near-term (more than 34 weeks of gestational age) neonates with hypoxic respiratory failure associated with pulmonary hypertension. Inhaled NO clearly is effective for this indication and reduces the severity of subsequent lung disease and the necessity for extracorporeal membrane oxygenation in these infants. Off-label clinical use is widespread, and includes using inhaled NO to treat acute respiratory distress syndrome (ARDS); complications of lung and cardiac transplantation; pulmonary hypertension associated with congenital and acquired heart disease, as well as chronic pulmonary diseases; and to produce desirable direct effects on blood elements, specifically during the treatment of acute chest syndrome in sickle cell disease. 11 Lowson describes several alternatives to inhaled NO, and focuses his review on inhaled prostacyclin (PGI 2 ). Why do we need additional drugs if we have nitric oxide? Expense is only one criterion for drug selection. Efficacy, safety, availability, and ease-of-use are other important considerations.\n\n Efficacy of inhaled NO for its off-label uses has been difficult to demonstrate. Placebo-controlled trials of iNO to treat ARDS have been disappointing, demonstrating only transient improvements in oxygenation and no effect on outcome. 12, 13 While in many patients inhaled NO provides selective pulmonary vasodilation, large multicenter trials examining the effect of inhaled NO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed.\n\n Physiologically, it seems reasonable that a selective pulmonary vasodilator might be effective in treating ARDS. Reduced pulmonary capillary pressure should decrease the extent of pulmonary edema; should improve lung compliance; and might speed resolution of lung injury. Improved oxygenation should permit a reduction of the inspired oxygen concentration and airway pressure. But these effects may be insufficient to alter outcome. Usually, pulmonary artery pressure is only modestly elevated in ARDS. Even in severe cases, the mean pulmonary artery pressure is usually about 30 mmHg. 14 This degree of pulmonary hypertension is well tolerated, and few patients with ARDS die of their pulmonary hypertension. Rather, the survival of patients with ARDS appears to depend more on the occurrence of sepsis and multiple organ failure than on blood gas tensions or pulmonary artery pressure. [15] [16] [17] This Editorial View accompanies the following article: Lowson SM: Inhaled alternatives to nitric oxide. ANESTHESIOLOGY 2002; 96:1504 -13.\n\n The effect of iNO varies among patients. Approximately one-third of patients fail to demonstrate improved oxygenation or decreased pulmonary artery pressure. 12, 18 The cause of hyporesponsiveness remains under investigation. We cannot predict which patients may benefit and why pulmonary vasodilation does not occur in others.\n\n Consequently, the search for ways of improving the efficacy of iNO and designing effective alternative therapies continues. Combinations of therapies have been developed that aim to improve the matching of ventilation-to-perfusion or increase the biologic activity of inhaled NO. Alternative therapies have been suggested that may provide equivalent pulmonary vasodilation. While such therapies are attractive, whether they will affect clinical outcome is unknown.\n\n Ventilatory techniques that increase alveolar recruitment, such as the use of high-frequency oscillation in neonates, 7 or prone positioning of ARDS patients, 19 may improve the response to inhaled NO. Recruiting lung volume, by adding PEEP 20 or by the use of partial liquid ventilation with perfluorocarbons, 21 has been used to augment the response to iNO. The coadministration of vasoconstrictors, such as almitrine and norepinephrine, may enhance pulmonary vasoconstriction and accentuate the improvement in PaO 2 observed during inhaled NO therapy, presumably by improving the matching of ventilation to perfusion. 22, 23 Inhibition of the phosphodiesterase (PDE) enzymes that hydrolyze cGMP can also increase the efficacy and duration of action of iNO. 24, 25 Even if efficacy were improved, however, iNO therapy still has several drawbacks. It is expensive, cumbersome devices are necessary to administer the drug safely, and continuous administration is required. Especially for chronic treatment of pulmonary hypertension, therapies that are inexpensive, available in convenient forms (such as a tablet or simple multidose inhaler), and allow for intermittent dosing would be advantageous.\n\n Does inhaled prostacyclin fulfill these goals?", "qa": [["0_1332430_2_1", "What are some off-label uses of inhaled nitric oxide (iNO) in clinical practice?\n", "Off-label uses of iNO include treating acute respiratory distress syndrome (ARDS), complications of lung and cardiac transplantation, pulmonary hypertension associated with congenital and acquired heart disease, chronic pulmonary diseases, and acute chest syndrome in sickle cell disease."], ["0_1332430_2_2", "What are some factors that contribute to the difficulty in demonstrating the efficacy of iNO for its off-label uses?\n", "Placebo-controlled trials of iNO for off-label uses have been disappointing, showing only transient improvements in oxygenation and no effect on outcome. Additionally, large multicenter trials examining the effect of iNO therapy on clinical course and outcome of patients with diverse causes of pulmonary hypertension have not been performed."], ["0_1332430_2_3", "What are some alternative therapies or techniques that have been suggested to improve the efficacy of iNO?\n", "Some alternative therapies or techniques that have been suggested to improve the efficacy of iNO include ventilatory techniques that increase alveolar recruitment, such as high-frequency oscillation in neonates or prone positioning of ARDS patients, recruiting lung volume by adding positive end-expiratory pressure (PEEP) or using partial liquid ventilation with perfluorocarbons, coadministration of vasoconstrictors to improve the matching of ventilation to perfusion, and inhibition of phosphodiesterase (PDE) enzymes to increase the efficacy and duration of action of iNO."]]}, {"passage_id": "36_5070306_0", "passage": "Breathing is a systemic act, involving the whole body, the viscera, the nervous system, and emotions. The diaphragm muscle is the main breathing muscle, influencing with its contractions the respiratory activity. 1 The diaphragm collaborates to various processes such as expectoration, vomiting, swallowing, urination, and defecation. 1 It facilitates the venous and lymphatic return and helps the viscera above and below the diaphragm to work properly. 1 Diaphragm's activity is fundamental in the maintenance of posture and body position changes and influences the pain perception, usually decreased during the inspiratory apnoea. 1, 2 Diaphragmatic movements also change the body pressure, as it facilitates the venous and lymphatic return. 2 This pressure modulation influences the blood redistribution, which could be probably correlated with the response of baroreceptors and the reduction of pain perception, although there are not scientific studies supporting this hypothesis yet. 2 The most important stimulus for the respiratory acts is provided by chemoreceptors, whose task is to maintain the biochemical balance of the body. 2 Breathing is also influenced by internal and external conditions, with other ways of neural stimulation beyond the chemoreceptorial stimulation. 2 The diaphragmatic activity is not only controlled by metabolic mechanism but also by emotional states such as sadness, fear, anxiety, and anger. 2 Breathing stimulates mechanoreceptors of the diaphragm and the visceroceptors of viscera (moving during the respiratory acts), constituting the mechanism of interoception. 2 Interoception is the awareness of the body condition obtained from information coming directly from the body itself. 2 Diaphragmatic movements also stimulate the skin and the mediastinum; this complex of afferent information determines the central representation of breathing. 2 The amygdala, which is part of the limbic system, is reciprocally connected to each of the respiratory areas, just as the medulla oblongata, and is considered the most important area that manages emotive breathing. 2 A respiratory disorder certainly alters the emotional framework, such as depression and anxiety, as well as the emotional state can negatively affect the respiratory activity. 2 In case of systemic disease, the diaphragm is always involved, negatively contributing to the set of symptoms. In chronic heart failure, the diaphragm is weaker, more commonly placed in expiratory state, with more frequent movements. 3, 4 The pathological changes are seen in patients with chronic obstructive pulmonary disease (COPD). 5 The progressive limitation of the airflow in COPD patients causes a pathological adaptation of the diaphragm, although the reasons for these changes are not fully clear. These changes in position adversely affect the exercise tolerance; more in detail, the dome of the diaphragm is lowered, in inspiratory position. 6 The contractile force is decreased, with electrical and metabolic alterations. The muscle thickness is increased, especially on the left side, with decreased mechanical excursion, probably due to fibers' shortening. 7, 8 A decrease of anaerobic type fibers (type II) and an increase in aerobic fibers (type I) are observed; this process progressively increases with the pathology worsening. 8 The increase in the oxidative process, however, does not correspond to an improvement of the diaphragmatic function. The rate of detectable myosin decreases, resulting in altered sarcomeric organization and further decreasing of the contractile strength. 8 The phrenic activity is abnormal, presumably due to the nerve stretching caused by the chronic lowering of the diaphragm, resulting in such a neuropathy. 9 The exercise intolerance in patients with congestive heart failure and COPD does not correlate with the common functional indexes (ejection frequency and forced expiratory volume in 1 second); rather it is the peripheral muscle adaptation, including that of the diaphragm, to have a heavy influence on the symptomatic scenario. 10, 11 As mentioned in the article, the diaphragm influences the patient's emotional state. In patients with COPD, the incidence of depression varies from 8% to 80%, according to different studies. 12 Depression may be considered a predictor of mortality during hospitalization for acute respiratory events. 13 Depression and anxiety negatively affect the rehospitalization, but only 33% of patients are treated with a pharmacological process taking into account these psychiatric symptoms. 13 Depression affects the physical status of the patient, as demonstrated by some authors who observed a worsening in the test of Cooper (12 minutes run) and an increased mortality rate. 13 Anyway, there are not enough data exhaustively explaining this correlation. 13 The copresence of depression and anxiety in patients with COPD increases the mortality rate (of 83% according to some authors). 14, 15 The incidence of depression/anxiety increases with COPD worsening.", "qa": [["36_5070306_0_1", "How does the diaphragm muscle contribute to various bodily functions beyond respiration?", "The diaphragm muscle plays a role in processes such as expectoration, vomiting, swallowing, urination, and defecation. It also facilitates venous and lymphatic return and helps the proper functioning of the viscera above and below the diaphragm. Additionally, the diaphragm's activity is important for maintaining posture, body position changes, and influencing pain perception."], ["36_5070306_0_2", "What factors influence breathing besides chemoreceptorial stimulation?", "Breathing is influenced by internal and external conditions, as well as emotional states such as sadness, fear, anxiety, and anger. Mechanoreceptors of the diaphragm and visceroceptors of the viscera also play a role in breathing through interoception. The skin and mediastinum are stimulated by diaphragmatic movements, contributing to the central representation of breathing."], ["36_5070306_0_3", "How does respiratory disorder affect emotional well-being, and how does emotional state impact respiratory activity?", "Respiratory disorders can alter the emotional framework, leading to conditions such as depression and anxiety. Conversely, emotional states can negatively affect respiratory activity. In patients with chronic obstructive pulmonary disease (COPD), the incidence of depression varies, and depression may be considered a predictor of mortality during hospitalization for acute respiratory events. The copresence of depression and anxiety in COPD patients increases the mortality rate."]]}, {"passage_id": "32_13908762_1", "passage": "Similarly, publications on OrthoK lenses used as overnight or daytime wear modalities were both included in the review.\n\n As a large proportion of previously published OrthoK-related complications were from East Asia, especially from China, the literature published both in English and Chinese were identified from the Cochrane Library, MEDLINE, EMBASE, CNKI, CQVIP, and WANFANG DATA using the following strategies.\n\n (1) orthokeratolog* OR orthok* OR corneal reshaping OR reverse geometry lens (2) myopia AND correct* OR control OR retardation OR therap* OR treatment* (3) keratitis OR safety OR side effects OR adverse effects OR complications OR risk (4) (1) AND (2) AND (3) The publication type is restricted to clinical studies and the material of the OrthoK lens was limited to gas-permeable material only.\n\n The titles and abstracts were assessed and full copies of all potentially or definitively relevant studies were obtained to determine whether the studies met the criteria for inclusion in this review. References of all included publications were also reviewed.\n\n Owing to the retrospective nature of the studies reporting treatmentrelated side effects, most reviewed studies were subject to some level of biases such as selection bias, performance bias, attrition bias, and/or detection bias. As a result, none of the relevant publications were excluded from the review based on the risks of bias.\n\n The original electronic searches identified 378 abstracts, of which 133 were in English language and 245 were in Chinese. For further assessment, 269 potentially relevant publications were retrieved, and 99 were subsequently excluded, leaving a total of 58 English and 112 Chinese literature in the final review. \n\n \n\n Microbial keratitis (MK) remains as the most serious and sightthreatening complication of OrthoK. Van Meter et al. 66 provided a comprehensive review of the MK cases published in English since 1998, with most cases reported in Taiwan, Hong Kong, and Mainland China and presented as sporadic pattern without significant association with the baseline level of myopia, gender, or the specific brand of the OrthoK lenses. The sporadic pattern of MK was similarly reported in earlier Chinese publications and the attributable factors of the cases included lack of training of practitioners and wearers, improper fitting procedures, poor compliance to lens care regimens, and lost to routine follow-ups. 38, 41, 49, 58, 189 A more recent large-scale multicentered retrospective study reported the estimated incidence rate of MK as 7.7 cases per 10,000 patient years (95% CI, 0.9;27.8), and risk of MK with overnight OrthoK was similar to other overnight modalities. 74 Since the publication of the aforementioned two major reviews, there had been few sporadic cases of MK reported, mostly in a tertiary eye care hospital in Hong Kong. 76 Corneal Staining, Lens Binding, and Tear Film Stability\n\n Corneal staining was commonly reported in patients wearing OrthoK lenses. 37, 55, 61, 65, 96, 103, 107, 130, 149, 164, 185, 187 Commonly reported grading systems included Efron scale, Cornea and Contact Lens Research Unit scale, and Oxford scheme. Although mild corneal staining was also a common ocular finding in non-contact lens wearers, OrthoK has been reported to increase both the frequency and the severity of staining. Higher baseline myopia was reported to be positively associated with the level of staining 103, 107, 130, 149, 164, 185, 187 ; however, age did not seem to be a significant factor in observed corneal staining after OrthoK treatment. Lens binding was another most commonly seen complication in overnight OrthoK and was significantly associated with central corneal staining. 130, 149, 185, 187 Chronic wear of OrthoK lenses was also significantly associated with reduced basal tear secretion 187 and tear film stability, however with limited information reported dry eye symptoms. 185, 187, 190 Epithelial Iron Deposit/White Lesion/ Fibrillary Lines Pigmented iron ring or arcs and adjacent white linear lesions had often been reported as a result of chronic wear of OrthoK lenses, and the incidences of the lesions were significantly associated with the duration of OrthoK treatment. 24, 31, 34, 40, 45, 54, 59 The findings were reported to be in subepithelial layer and usually were clinically insignificant. Prominent fibrillary white lines were also reported in long-term OrthoK treatment and were thought to represent nerve fibers in the subbasilar plexus.", "qa": [["32_13908762_1_1", "What are the most serious complications associated with OrthoK lenses?\n", "The most serious and sight-threatening complication of OrthoK is microbial keratitis (MK). It is the most commonly reported complication, particularly in East Asia, including Taiwan, Hong Kong, and Mainland China. MK cases have been reported sporadically and are not significantly associated with the baseline level of myopia, gender, or the specific brand of OrthoK lenses. Factors contributing to MK cases include lack of training of practitioners and wearers, improper fitting procedures, poor compliance to lens care regimens, and lost routine follow-ups."], ["32_13908762_1_2", "How does OrthoK treatment affect corneal staining?\n", "Corneal staining is commonly reported in patients wearing OrthoK lenses. OrthoK has been found to increase both the frequency and severity of corneal staining compared to non-contact lens wearers. Higher baseline myopia is positively associated with the level of staining. However, age does not seem to be a significant factor in observed corneal staining after OrthoK treatment. Lens binding, another common complication in overnight OrthoK, is significantly associated with central corneal staining."], ["32_13908762_1_3", "What are the effects of chronic wear of OrthoK lenses on the eyes?\n", "Chronic wear of OrthoK lenses is associated with several effects on the eyes. It is significantly associated with reduced basal tear secretion and tear film stability. However, there is limited information reported on dry eye symptoms. Chronic wear of OrthoK lenses also leads to the development of pigmented iron rings or arcs and adjacent white linear lesions. The incidence of these lesions is associated with the duration of OrthoK treatment. Additionally, long-term OrthoK treatment can result in the appearance of prominent fibrillary white lines, which are thought to represent nerve fibers in the subbasilar plexus."]]}, {"passage_id": "81_52132785_3", "passage": "An increase in RI is also seen with pressure on the transducer; the poor compliance of the subarachnoid space leads to an impaired autoregulatory response and failure to accommodate to the increase in ICP [51] .\n\n RI values in the anterior cerebral artery have been positively correlated with increased ICP in hydrocephalic infants [52] [53] [54] [55] . Studies have demonstrated both elevated intracranial RIs in infants with hydrocephalus, and subsequent decreases in RI after ventricular tap or shunt [56, 57] . \n\n Ventriculomegaly is associated with an increased risk for both cognitive and motor sequelae due to associated acute ischemia, hypoxia, and inflammation of both important local periventricular as well as distally related white matter structures. When chronic, ventriculomegaly is associated with gliosis, demyelination, and axonal degeneration [58] . Periventricular brain structures, such as corticospinal tracts, are involved in perceptual-motor integration, sensory integration, and quality of movement. Periventricular white matter damage reduces cortical volume and can damage areas involved in memory, executive function, and language [59] .\n\n Larger lateral ventricles are independently related to decreased motor score at 2 years (fourfold increased risk with moderate/severe ventriculomegaly per visual template) [59] , and to progressive increases in risk per each additional 1 mm in lateral ventricle parameters such as AHW and midbody height [60] . In PHVD, higher rates of gross motor abnormalities like CP as well as decreased fine motor manipulative abilities are even more frequent [28, 61] , and likely secondary to cumulative risks from ventriculomegaly, IVH, and additional white matter injury.\n\n Cystic white matter injury, ventriculomegaly, and IVH are strongly and significantly associated with quadriplegia (risk ratio: 24, 17, 5.1), hemiplegia, (risk ratio: 29, 17, and 5.8), and diplegia (risk ratio: 5, 5.7, and 2.3), respectively [41] . Importantly for children with PHVD and white matter injury, these risks seem to be additive; preterm infants with IVH both with larger extent of hemorrhage (two lobes involved on the worst side) and PHHP requiring shunt placement [31, 32] , have higher rates of CP. Preterm infants with PHVD and a higher burden of periventricular lesions, especially bilateral, are at further increased risk for CP/severe motor impairment [29, 31, 40, 41] .\n\n Parenchymal involvement may be the main factor in determining motor risk for infants with PHVD. In one study, there was an 80% prevalence of CP in a group of shunted preterm infants with PVHI, but no cases of CP in those shunted for grade III IVH without PVHI [31] . Extensive PVHI is independently associated with CP, and risk for severe CP increases with concomitant GMH and cystic PVL [31] . The risk of severe CP also increases with grade of PVL; 10% of children with grade I PVL develop spastic diplegia by school age, increasing to almost 50% of children with cystic PVL [44] . The location and size of the cysts are important; cystic lesions of \u22653 mm in the parietooccipital periventricular white matter are highest risk for motor delay [62, 63] .\n\n Cognitive sequelae IVH, ventriculomegaly, and white matter disease are also important risk factors for cognitive delay in preterm infants. Although some studies analyze these pathologies separately, many combine them to assess risk, making prediction for individual infants difficult.\n\n Moderate/severe ventriculomegaly is independently associated with a significant increase in risk for cognitive delay and later decrease in intelligence quotient [60, [62] [63] [64] . Infants with ventriculomegaly (without IVH) have a two-to threefold higher risk of both neurodevelopmental and cognitive impairment and the composite outcome of death or neurodevelopmental impairment [65] .\n\n Presence of both ventriculomegaly and white matter disease on HUS (PVL, PVHI) multiplies risks for cognitive disabilities. Large proportions (50-80%) of children with PVHI are diagnosed with intellectual disability at school age [66] and are at higher risk for clinical or subclinical behavior problems [28] .", "qa": [["81_52132785_3_1", "What are the potential cognitive and motor sequelae associated with ventriculomegaly?\n", "Ventriculomegaly is associated with an increased risk for both cognitive and motor sequelae. This is due to associated acute ischemia, hypoxia, and inflammation of both important local periventricular as well as distally related white matter structures. When chronic, ventriculomegaly is associated with gliosis, demyelination, and axonal degeneration. Periventricular brain structures, such as corticospinal tracts, are involved in perceptual-motor integration, sensory integration, and quality of movement. Periventricular white matter damage reduces cortical volume and can damage areas involved in memory, executive function, and language."], ["81_52132785_3_2", "How are larger lateral ventricles related to motor impairment in infants?\n", "Larger lateral ventricles are independently related to decreased motor score at 2 years. There is a fourfold increased risk of motor impairment with moderate/severe ventriculomegaly per visual template. Additionally, there is a progressive increase in risk for motor impairment with each additional 1 mm in lateral ventricle parameters such as AHW and midbody height. In infants with post-hemorrhagic ventricular dilatation (PHVD), higher rates of gross motor abnormalities like cerebral palsy (CP) as well as decreased fine motor manipulative abilities are even more frequent, likely due to cumulative risks from ventriculomegaly, intraventricular hemorrhage (IVH), and additional white matter injury."], ["81_52132785_3_3", "What are the risk factors for quadriplegia, hemiplegia, and diplegia in infants?\n", "Cystic white matter injury, ventriculomegaly, and IVH are strongly and significantly associated with quadriplegia, hemiplegia, and diplegia, respectively. The risk ratios for quadriplegia, hemiplegia, and diplegia are 24, 17, and 5.1 for cystic white matter injury; 17, 5.8, and 5.7 for ventriculomegaly; and 5.1, 5.8, and 2.3 for IVH, respectively. Importantly, for children with post-hemorrhagic ventricular dilatation (PHVD) and white matter injury, these risks seem to be additive. Preterm infants with IVH and larger extent of hemorrhage, as well as PHHP requiring shunt placement, have higher rates of cerebral palsy (CP). Preterm infants with PHVD and a higher burden of periventricular lesions, especially bilateral, are at further increased risk for CP/severe motor impairment."]]}, {"passage_id": "15_16600701_6", "passage": "The data entry screen includes a table where each row represents an individual container and where the numbers of pupae collected by mosquito taxon are entered in columns that are created dynamically from a list of taxa defined under a term tree root (default list is Ae. aegypti, Ae. albopictus, and Aedes spp.). The corresponding query builder includes a separate section for each of these taxa with options for summary numerical data and a set of pre-defined custom calculations. The inclusion of Runway SDK to drive system operations allows for an automatic, adaptive process where the user only needs to go into the term tree and inactivate a default taxon or add a new taxon in order for the system to automatically 1) update the dynamic columns in the table in the data entry screen and 2) add or remove the section for the affected taxon from the query builder.\n\n All query builders also include options to 1) export query results as .csv or .xls files, 2) save and re-use specific querying field combinations that are executed on a regular basis and 3) upload pre-configured BIRT report templates and use these to produce standardized reports (see buttons at the bottom of the query builder shown in Figure 6 ). Mapping is directly linked to the query builders in that the map generation process makes use of information that is saved in the query builders as specific named query results. Importantly, mapping supports multiple layer views from different query results that may have been produced through a single query builder or several different ones, for example combining results for entomological surveillance, disease case surveillance and intervention monitoring in a single map. The system also supports export of spatial data in commonly used formats such as shapefile or Keyhole Markup Language (KML) file.\n\n The multi-disease platform includes functionalities that are entirely or in large part re-used across diseases. This includes the administration functionalities, stock management, GIS, case surveillance (re-used in large part across dengue and malaria), and most of the functionalities relating to entomological surveillance. Because the platform at this point only includes two diseases, some of the functionalities are relevant only for dengue or malaria. However, as more vector-borne diseases are added to the platform, these functionalities also will become re-used across diseases. For example, container surveillance of mosquito immatures would be directly applicable to other arboviral diseases where the causative agent is transmitted by Ae. aegypti, such as chikungunya or yellow fever. Intervention monitoring provides other examples of functionalities that will be re-used when additional vector-borne diseases where similar control methods are employed are added to the system platform.\n\n Some data in the system are shared between diseases because they are relevant across diseases. This includes universal terms and human population data recorded against geo entities representing administrative boundary units or health facilities. Other data are shared across diseases but can be made active or inactive by disease; this includes, for example, the terms in the term tree.\n\n To avoid cluttering the menu for a given disease with functionalities that are unlikely to be relevant for that disease, the system comes with a default set of functionalities by disease. Functionalities which in the default system for dengue and malaria that inhabit non-container aquatic habitats, which may range in size from cattle hoof prints or small puddles to rice fields and lake shores. Functionalities which are included only for the dengue menu include 1) container-based surveillance of immatures of key dengue virus vectors, such as Ae. aegypti and Ae. albopictus, which exploit a wide range of containers (e.g., water storage containers, tires, bottles, cans, flower pots, etc.) as larval development sites [46] [47] and 2) capture of summary data, by individual premises or Data Management System for Vector-Borne Diseases www.plosntds.orgaggregated to larger spatial units such as blocks or neighborhoods, for intervention methods used in a given geographical area during a specific time period.\n\n Our multi-disease system incorporates a broad range of information including entomological, epidemiological, stock and spatial data. This sets the stage for using the system to support integrated vector management (IVM) which uses a wide range of interventions, often in combination and synergistically [48] [49] . For example, the functionality for intervention monitoring in the dengue menu allows for capture of data, in space and time, for different implemented intervention methods (the methods are defined by the user through the term tree) used as parts of an IVM program.", "qa": [["15_16600701_6_1", "How does the multi-disease platform incorporate various functionalities to support integrated vector management (IVM) and what are the advantages of using this approach?", "The multi-disease platform includes functionalities such as entomological, epidemiological, stock, and spatial data management. These functionalities support IVM, which involves using a combination of interventions to manage vectors. By capturing data on different implemented intervention methods and their spatial and temporal distribution, the platform allows for a comprehensive understanding of the effectiveness of IVM programs. This integrated approach enables synergistic interventions that can enhance vector control efforts."], ["15_16600701_6_2", "How does the mapping feature of the system utilize information from the query builders and what are the benefits of using this feature?", "The mapping feature of the system uses information saved in the query builders as specific named query results. This allows for the generation of maps that represent multiple layers of data from different query results. For example, entomological surveillance, disease case surveillance, and intervention monitoring data can be combined in a single map. The system also supports the export of spatial data in commonly used formats, facilitating further analysis and interpretation. This mapping functionality provides a visual representation of data trends and spatial distribution, aiding in decision-making and planning of vector control strategies."], ["15_16600701_6_3", "What are the advantages of reusing functionalities across diseases in the multi-disease platform and how does it contribute to scalability and adaptability?", "Reusing functionalities across diseases in the multi-disease platform offers several advantages. Firstly, it eliminates duplication of efforts and resources by leveraging existing functionalities that are relevant to multiple diseases. This scalability allows for easy integration of additional vector-borne diseases into the platform, as the shared functionalities can be adapted for different diseases. For example, container surveillance of mosquito immatures can be applied to other arboviral diseases transmitted by Ae. aegypti, such as chikungunya or yellow fever. This reuse of functionalities promotes efficiency, standardization, and flexibility in managing a range of vector-borne diseases."]]}, {"passage_id": "43_207939201_2", "passage": "In previous studies, factors such as age, gender, BT at admission, potassium, and lactate were considered mortality predictors [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15] [16] [17] [18] [19] [20] . Although serum potassium and lactate had relatively good discrimination abilities as mortality predictors, as shown in our study, the SOFA score was slightly better than others ( Table 2) . Serum lactate and potassium were mainly and only reflected the hemodynamic state, whereas the SOFA score is a comprehensive assessment of multiple organ failure including six domains; respiratory, cardiovascular, hepatic, coagulation, renal, and neurological systems. In addition, organ failure caused by hypo-perfusion to vital organ or sepsis is considered to be the possible cause of mortality in patients with moderate to severe AH. Therefore, we believe that the SOFA score can assess the severity more appropriately than serum lactate or potassium.\n\n The discrimination abilities of the qSOFA and SIRS scores were not as high as that of the SOFA score (Fig. 2) , possibly because the items, such as respiratory rate, consciousness, and BT, of these scores are not sensitive for the mortality in patients with AH. With regard to the respiratory rate, patients with AH with lower BT tend to experience bradypnea [2] . However, in the qSOFA and SIRS scores, the respiratory condition is only assessed by the presence of tachypnea. Therefore, these scores cannot evaluate the respiratory condition appropriately in patients with severe AH. In contrast, the SOFA score uses PaO 2 /F I O 2 for the respiratory condition; this rate is independent from the respiratory rate. Thus, the SOFA score can more accurately assess the respiratory condition in patients with AH than the qSOFA and SIRS scores. Regarding consciousness, the change in mental status is evaluated in the qSOFA; however, only binary variables (yes or no) are required as answers, and qSOFA cannot discriminate the minor and severe disturbances of consciousness in patients with AH. Conversely, the SOFA score includes five grades by using the GCS; thus, it enables to assess consciousness more exactly than qSOFA. In the SIRS score, BT is an item evaluated as more than 38\u00b0C or lower than 36\u00b0C, but in patients with AH, BT is basically lower than 35\u00b0C; thus, it cannot distinguish the severity. Therefore, the qSOFA and SIRS scores underestimated the severity of AH in this study, and their discrimination abilities for mortality were low.\n\n The SOFA score and 5A severity scale ( Table 3) had almost similar discrimination ability for predicting in-hospital mortality after AH. However, SOFA score is widely accepted; thus, it may be more useful and generalized than 5A severity scale.\n\n This study indicated that the SOFA score may be validated to predict in-hospital mortality and assess the severity objectively among the patients with AH admitted to ICU. Therefore, it may be helpful in selecting the appropriate patients for ICU admission and shareddecision making with the patients/their families. Generally, a scoring system is useful to generalize the severity for comparing the quality of the care in different settings or for selecting patients in clinical research [25] . Thus, in patients with AH, the SOFA score may also be useful in quality management and research.\n\n This study has several limitations. First, it is a retrospective cohort study. Considering that patients were selected according to the ICD-10, possibly not all patients with BT of 35\u00b0C or less could be incorporated into this study. Second, trauma patients were also included in this study. We considered that in many cases, elderly people became accidental hypothermia because they could not move after they got injury due to fall, however the detail of trauma was unknown. Third, we obtained SOFA score by using the worst value for each physiological variable within the past 24 h after admission to ICU. Therefore, the time of scoring SOFA was not strictly uniform. Forth, although the target case was a patient with AH requiring ICU management, there was an absence of a protocol for care which was used consistently and contents of the treatment were left to the individual physicians. Furthermore, regarding the details of the cause of death, although there was a record, most of these were inadequate or missing data. Hence, setting a unified treatment indication and contents for patients with AH and considering further research are necessary.\n\n This study indicated that the SOFA score may be validated for predicting in-hospital mortality among patients with AH admitted to ICU. Therefore, we believe that SOFA score may be useful for risk stratification in order to select appropriate patients for ICU admission.", "qa": [["43_207939201_2_1", "What are some factors that have been considered as predictors of mortality in patients with moderate to severe AH?", "Factors such as age, gender, BT at admission, potassium, and lactate have been considered as predictors of mortality in patients with moderate to severe AH."], ["43_207939201_2_2", "How does the SOFA score compare to serum lactate and potassium in assessing the severity of AH?", "The SOFA score is a comprehensive assessment of multiple organ failure, including six domains, while serum lactate and potassium mainly reflect the hemodynamic state. The SOFA score is slightly better than serum lactate and potassium in assessing the severity of AH."], ["43_207939201_2_3", "Why were the qSOFA and SIRS scores found to have lower discrimination abilities for mortality in patients with AH?", "The qSOFA and SIRS scores were found to have lower discrimination abilities for mortality in patients with AH because they do not adequately assess respiratory condition, consciousness, and body temperature, which are important factors in AH. The SOFA score, on the other hand, includes more accurate assessments for these factors."]]}, {"passage_id": "69_6525908_3", "passage": "Corticosteroids are usually used as an adjunctive treatment for ADAMTS13 deficiency-related TMA or other forms of TTP. However, there is no definitive evidence of the efficiency of steroids in this setting.\n\n Plasma exchanges or fresh frozen plasma infusions may fail to induce or maintain TMA remission, particularly in the presence of high-titer inhibitory autoantibodies (26) . As already outlined, the B cell-depleting antibody rituximab is probably the optimal second-line therapy. However, the use of rituximab during pregnancy raises the issue of its potential fetal toxicity. Like all IgG1 antibodies, rituximab undergoes an active transplancental transport through Fc receptors mainly during the third trimester of pregnancy, leading to the drug accumulation in the fetus. Rituximab is usually cleared from the newborn circulation within 3-4 months postpartum (44) . In a recent review of 153 pregnancies in women with malignant hemopathies or severe systemic disorders treated with rituximab during gestation (45), 60% live births, 21% first-trimester abortions, and 2.2% congenital abnormalities were reported. Thrombocytopenia, neutropenia, and B cell depletion were noted in ,10% of the neonates, but the incidence of these complications in neonates is clearly underestimated in this retrospective study. No clear conclusions can be drawn in this highly selected population. Moreover, although the shortterm outcome of these infants seems rather good (45, 46) , the long-term impact of rituximab on the immune system of neonates exposed to rituximab during fetal life remains to be assessed. The Food and Drug Administration has given rituximab a pregnancy label C, and its use during pregnancy should be decided on a case by case basis depending on the potential benefits and risks of such treatment.\n\n The other clinical challenge is in the case of patients with known acquired or constitutional ADAMTS13 deficiency who start a pregnancy while in TMA remission. ADAMTS13 deficiency is associated with an overall risk of TMA relapse around 30% (26, 39) . The estimation of the risk of TTP relapse specifically during pregnancy varies widely from 23% to 50% (47, 48) . This discrepancy may be caused by a possible bias in the selective publication of severe cases and the heterogeneity of patients included in small retrospective series. The management of these patients during pregnancy remains ill-codified. For instance, the usefulness of the monitoring of ADAMTS13 activity and/or autoantibodies titer in patients with acquired ADAMTS13 deficiency is still a matter of debate, most particularly during pregnancy. Preliminary data suggest that the monitoring of ADAMTS13 levels during pregnancy may help identify patients at high risk of TMA relapse (49, 50) . Some authors have even advocated the use, early in pregnancy, of plasma exchanges in pregnant women with ADAMTS13 deficiency to maintain an enzymatic activity .10% (50). However, there are no sufficient data for the establishment of clear evidence-based guidelines for a prophylactic treatment of ADAMTS13 deficiency TMA during pregnancy.\n\n P-TMA may also be associated with alternative C3 convertase dysregulation. In a recent review of 21 pregnant aHUS (P-aHUS) cases from the French aHUS registry (24), 80% of patients had abnormal CAP dysregulation. In contrast to ADAMTS13 deficiency-related TMA, P-TMA caused by CAP dysregulation occurred mainly (80% of cases) during the postpartum period. Infections and bleeding, which frequently complicate the postpartum, may trigger complement activation leading to TMA. Interestingly, P-aHUS and non-P-aHUS cases shared the same risk factors and outcome: 80% of patients in each group had CAP dysregulation with FH and FI encoding gene (CFH and CFI, respectively) mutations accounting for more than one-half of the cases. Similarly, 50% and 80% of patients in each group reached ESRD during the first aHUS episode or last follow-up, respectively. Thus, P-aHUS is most probably a complement dysregulationassociated TMA precipitated by pregnancy.\n\n The counseling of patients with complement genes abnormalities who wish to start a pregnancy remains a difficult issue.", "qa": [["69_6525908_3_1", "What are the potential risks associated with using rituximab during pregnancy?\n", "The use of rituximab during pregnancy raises concerns about potential fetal toxicity. Rituximab, like all IgG1 antibodies, can cross the placenta and accumulate in the fetus, particularly during the third trimester of pregnancy. A review of pregnancies in women treated with rituximab showed that 21% resulted in first-trimester abortions and 2.2% had congenital abnormalities. Thrombocytopenia, neutropenia, and B cell depletion were observed in some neonates exposed to rituximab. While the short-term outcomes of these infants seem favorable, the long-term impact on the immune system remains unknown. The Food and Drug Administration has given rituximab a pregnancy label C, indicating that its use during pregnancy should be decided on a case-by-case basis, weighing the potential benefits and risks."], ["69_6525908_3_2", "What is the estimated risk of relapse of thrombotic microangiopathy (TMA) specifically during pregnancy in patients with ADAMTS13 deficiency?\n", "The risk of relapse of TMA, specifically during pregnancy, in patients with ADAMTS13 deficiency varies widely, with estimates ranging from 23% to 50%. This discrepancy may be due to a possible bias in the selective publication of severe cases and the heterogeneity of patients included in small retrospective series. The management of these patients during pregnancy is not well-defined. Some preliminary data suggest that monitoring ADAMTS13 levels during pregnancy may help identify patients at high risk of TMA relapse. Plasma exchanges have been advocated as a prophylactic treatment in pregnant women with ADAMTS13 deficiency to maintain enzymatic activity, but there is insufficient data to establish clear evidence-based guidelines."], ["69_6525908_3_3", "What is the association between pregnancy-associated hemolytic uremic syndrome (P-aHUS) and complement dysregulation?\n", "Pregnancy-associated hemolytic uremic syndrome (P-aHUS) may be associated with alternative C3 convertase dysregulation. In a review of P-aHUS cases, 80% of patients had abnormal complement activation pathway (CAP) dysregulation. P-aHUS caused by CAP dysregulation primarily occurred during the postpartum period and may be triggered by infections and bleeding that commonly occur during this time. Both P-aHUS and non-P-aHUS cases shared the same risk factors and outcomes, with 80% of patients in each group having CAP dysregulation. Mutations in genes encoding complement regulatory proteins FH and FI accounted for more than half of the cases. The counseling of patients with complement gene abnormalities who wish to start a pregnancy is challenging."]]}, {"passage_id": "87_42356408_3", "passage": "Instead of relying on the paper requisition form, the tech nologists carried an electronic mobile device with them to verify patient information. An electronic tablet and a smart phone, both existing property of the IT section, were tested for this purpose.\n\n Before the application of lean principles, the technologist performing the examination would greet the patient in the waiting room and escort her to the changing room. While the patient was changing, the technologist would search for an open mammography room and prepare it for the patient. This often led to the patient hav ing to wait for the technologist or vice versa. A patient wait time trial was created in which an aide would greet the patient and escort her to the changing room and adjacent waiting area. This allowed time for the technologist to prepare the mammography room and then greet the patient in the waiting area, reducing unnecessary motion and wait time. The aide was not an additional hire for the department; the duties of the aide were added to those of an existing file room assis tant. Her computer was moved to the technolo white board lists all procedures and meetings for the day so that others can anticipate when a radi ologist will be unavailable.\n\n The layout and content of each of these white boards has evolved since their initial implementa tion. Each version of the white boards was tested for a month. Feedback and suggestions were col lected from all staff members, not just those on the lean team. Improvements to the boards were made on the basis of these suggestions. . (a) Photograph shows the technologist white board, created to demonstrate which examination rooms are available and where patients are located within the department. The \"Time\" column was added to allow technologists to better anticipate when patients or rooms might become available. (b) Photograph shows a technologist \"batting order\" dry erase board, created for use with the original white board to ensure a more even distribu tion of work. (c) Photograph shows the physician white board, which displays which staff are working in the department on that particular day, tracks his or her location within the department, and specifies scheduled procedures and meetings.\n\n Previously, upon completing a patient's screening examination, the technologist would place the pa per requisition form and any previously obtained hardcopy images in a film jacket and place this jacket in a slot in the technologist work area. An assistant would wait for a batch of completed ex aminations to accumulate and then take them to the screening reading room. She would then write all of the patients' names on a clipboard and note whether the comparison images were digital or hardcopy images. Hardcopy comparison images would be hung on a film alternator, and the panel number would be indicated on the clipboard next to the patient's name. The resident and the faculty radiologist would then locate each patient listed on the clipboard on the reading work list in the mam mography reporting system and open the exami nation. (The reading work list in the reporting sys tem is electronically linked with the image display workstation.) Once the images had been read, the patient's name was crossed off the clipboard and the film jackets were moved to a cart for filing.\n\n To combat the wasted motion, wasted trans portation, and overprocessing in this reading workflow, an electronic work list was imple mented. Screening mammographic studies with no comparison images or with only digital com parison images were assigned a specific status (\"AutoTrack\") on the reading work list by the technologist upon completion of the examination. This label indicated that the study was available for immediate review without requiring a paper requisition form, a film jacket, or the clipboard. This process allowed sorting of the studies that were ready to be read as indicated on the report ing system and eliminated time wasted by the radiologist in searching for the patient's name on the reading work list. The average read time per case for both the resident and the staff radiologist before and after this trial was recorded. Statistical analysis of the difference in average read time was performed using the twotailed t test.\n\n The wasted time, motion, and transportation caused by hanging hardcopy comparison im ages on an alternator were eliminated when the section purchased a digitizer. In anticipation of upcoming appointments for screening mam mography, an aide digitized previously obtained hardcopy images before the patient arrived. If the patient arrived with hardcopy images from an outside institution, these images were digitized before the examination was made avail able for the radiologist to read. Once the images were digitized and sent to the mammography workstation, the study was assigned AutoTrack status in the mammography reporting system, alerting the radiologist that it was ready to be interpreted.\n\n Because of limited local memory on the image display workstations, studies awaiting receipt of comparison images from an outside institution would often \"drop off\" the workstation before they were interpreted.", "qa": [["87_42356408_3_1", "What are some improvements made to the workflow in the radiology department?\n", "Some improvements made to the workflow in the radiology department include the use of electronic mobile devices to verify patient information, the implementation of a patient wait time trial to reduce unnecessary motion and wait time, the creation of white boards to track procedures and meetings, the use of an electronic work list to streamline the reading workflow, and the purchase of a digitizer to eliminate the need for hanging hardcopy comparison images."], ["87_42356408_3_2", "How did the implementation of lean principles affect the workflow in the radiology department?\n", "The implementation of lean principles in the radiology department led to several improvements in the workflow. These included reducing unnecessary motion and wait time by implementing a patient wait time trial, streamlining the reading workflow by implementing an electronic work list, and eliminating wasted time, motion, and transportation by purchasing a digitizer for hardcopy comparison images."], ["87_42356408_3_3", "What was the purpose of the patient wait time trial in the radiology department?\n", "The purpose of the patient wait time trial in the radiology department was to reduce unnecessary motion and wait time. By having an aide greet the patient and escort them to the changing room and waiting area, the technologist had time to prepare the mammography room and then greet the patient in the waiting area, reducing the need for the patient to wait for the technologist or vice versa. This trial aimed to improve efficiency and patient satisfaction in the department."]]}, {"passage_id": "0_73085123_0", "passage": "Allergic rhinitis (AR) is a major illness and disability worldwide, emerging as a global health problem and affects approximately 40 million people in the United States of America (USA) [1, 2] . There has been an increase in the overall prevalence of AR since the early 1980s across all age, sex, and racial groups and is accounted as one of the most common chronic diseases among all age groups in the USA [1, 3] .\n\n The symptoms of allergic rhinitis are mainly nasal with complaints of rhinorrhea, nasal congestion, and sneezing [2, 4] . The patients also tends to experience *Address correspondence to this author at the Department of Pharmacology, Gian Sagar Medical College and Hospital, Village Ram Nagar, Tehsil Rajpura, District Patiala, Punjab, 140601, India; Mob: +91-9855001847; Fax: +91-1762-520024; E-mail: drpsmatreja@yahoo.co.in non-nasal symptoms which are troublesome, including headache, thirst, and disturbed sleep with fatigue, mood changes, depression, anxiety and impairments of work, school performance, and cognitive function [2, 4] . Only 12.4% of patients consult a physician, and instead choose to self-treat with home remedies and over-the-counter (OTC) medications; although they experience unpleasant symptoms with allergic rhinitis, they do not seek medical advice and [5, 6] . Increases in direct and in direct cost is associated with lack of treatment, under treatment, or non adherence. The direct, indirect, and hidden cost associated with allergic rhinitis is expensive as well as debilitating [5] . Reinforcement is needed for patient education and for physicians to implement existing evidence-based guidelines for prevention and treatment [5] . The total estimated cost of allergic rhinitis was between 1.2 and 1.5 billion dollars in 1994 [7] with more than 6 million missed work days, 2 million missed school days, and 28 million reduced-activity days [5] . Almost half of patients experience symptoms for more than 4 months in a year and one-fifth have symptoms for at least 9 months per year [5] .\n\n It's recognized that AR frequently has substantial impairment in adultsand children; and a significant impact on QOL from 1990's [8] . The finding of a direct relationship between AR symptoms and cognitive functioning strongly suggests implications of AR daily life functioning, safety and workplace productivity. As compared to general population, more people with AR complain of difficulty getting to sleep, waking up during the night, lack of a good night's sleep, or a combination of these, as a result of their nasal symptoms. More than half of individuals with AR describe their symptoms as impacting daily life a lot or to a moderate degree and report that their health limits them from doing well at work compared with adults without nasal allergies, and their estimated productivity drops by an average of 20% on days when their nasal symptoms are at their worst as driving a car or operating machinery. Allergic rhinitis has been described as a disease that \"may appear quite bearable to the non sufferer\" [9] .\n\n There have been reports of problems with social activities, difficulties with daily activities, and decreased feelings of mental well-being than people without AR in a study evaluating the impact of AR and asthma on QOL [4] .\n\n There is a disconnect between clinicians' perceptions of AR as a chronic but non serious medical condition that causes a limited range of symptoms and patients' perceptions of it as a limiting and disabling presence in their lives [10] and has a substantial impact on public health and the economy. Hence we designed this study to assess the quality of life of patients suffering from allergic rhinitis.\n\n This prospective, observational, cross sectional study was conducted on patients visiting the Department of Otorhinolaryngology, Gian Sagar Medical College and Hospital, Patiala, India for 2 months between April 2013 to August 2013. Patients suffering from allergic rhinitis were recruited in the study. The study was approved by the Institutional Ethics Committee and only those patients were recruited those who gave written informed consent.\n\n Patients between the age group of 18-55 years with a history of allergic rhinitis and were otherwise healthy were included in the study. Patients with history of chronic nasal or upper respiratory tract symptoms or disorders other than allergic rhinitis, chronic sinusitis or severe asthma, a nasal condition likely to affect the outcome of the study and currently taking regular medication, whether prescribed or not, including corticosteroids, vitamins, macrolides, anti-fungal agents and herbal remedies were excluded from the study.", "qa": [["0_73085123_0_1", "What are the common symptoms of allergic rhinitis?\n", "The common symptoms of allergic rhinitis include nasal complaints such as rhinorrhea (runny nose), nasal congestion, and sneezing. Patients may also experience non-nasal symptoms such as headache, thirst, disturbed sleep with fatigue, mood changes, depression, anxiety, and impairments of work, school performance, and cognitive function."], ["0_73085123_0_2", "How does allergic rhinitis impact the quality of life of patients?\n", "Allergic rhinitis can have a significant impact on the quality of life of patients. It can cause difficulties in daily activities, problems with social activities, decreased feelings of mental well-being, and limitations in daily life. Patients with allergic rhinitis may also experience sleep disturbances, which can affect their overall well-being and productivity."], ["0_73085123_0_3", "What are the economic implications of allergic rhinitis?\n", "Allergic rhinitis has both direct and indirect costs associated with it. The direct costs include medical expenses for treatment, while the indirect costs include missed work days, missed school days, and reduced-activity days. The total estimated cost of allergic rhinitis was between 1.2 and 1.5 billion dollars in 1994, with millions of missed work and school days. Lack of treatment, under treatment, or non-adherence to treatment can lead to increased costs and disability."]]}, {"passage_id": "87_56477889_6", "passage": "Furthermore, As the permeability of vorinostat is also a major contributing factor which limits its oral application [37] , we determined the permeability efficiency of vorinostat alone or vorinostat encapsulated within MCM-41-VOR, MCM-41-NH2-VOR and MCM-41-PO3-VOR particles in the Caco-2 cell monolayer model. Consistent with our solubility data, encapsulation within all three type of silica resulted in significantly higher Papp values compared to free drug ( Figure 6 ). Furthermore, Figure 5 . Solubility of vorinostat encapsulated MSNs in water (n = 3 \u00b1 SD). **** p < 0.0001, ANOVA and Tukey's post hoc test.\n\n As the permeability of vorinostat is also a major contributing factor which limits its oral application [37] , we determined the permeability efficiency of vorinostat alone or vorinostat encapsulated within MCM-41-VOR, MCM-41-NH 2 -VOR and MCM-41-PO 3 -VOR particles in the Caco-2 cell monolayer model. Consistent with our solubility data, encapsulation within all three type of silica resulted in significantly higher P app values compared to free drug ( Figure 6) . Furthermore, the analysis revealed that vorinostat encapsulated within amino-modified particles displayed the highest permeability (~4-fold) at the highest concentration (50 \u00b5g/mL), compared with pre-dissolved vorinostat. To assess the integrity of our monolayer we performed a recovery experiment where after 4 h treatment all particles were removed, the monolayer was washed and replaced with fresh media, and TEER measured over 24 h. As shown in Figure S1 , TEER was fully recovered in all samples by 12 h suggesting that the decrease in TEER was transient and reversible.\n\n the analysis revealed that vorinostat encapsulated within amino-modified particles displayed the highest permeability (~4-fold) at the highest concentration (50 \u03bcg/mL), compared with pre-dissolved vorinostat. To assess the integrity of our monolayer we performed a recovery experiment where after 4 h treatment all particles were removed, the monolayer was washed and replaced with fresh media, and TEER measured over 24 h. As shown in Figure S1 , TEER was fully recovered in all samples by 12 h suggesting that the decrease in TEER was transient and reversible. Figure 6 . Permeability studies across the Caco-2 monolayer of vorinostat and vorinostat loaded MSNs (n = 3 \u00b1 SD) at different concentrations. **** p < 0.0001, #### p < 0.0001, &&&& p < 0.0001, &&& p <0.001, * p < 0.04, one way ANOVA and Tukey's post hoc test.\n\n Having determined that vorinostat encapsulated within MCM-41-NH2 nanoparticles (MCM-41-NH2-VOR) have the highest permeability and a 3.9-fold increase in solubility, we next compared the HDAC inhibitory activity, effect on gene expression and apoptotic activity of vorinostat encapsulated within MCMI-41-NH2 particles, with vorinostat dissolved in media (DMEM) or DMSO. Empty MCM-41-NH2 particles served as an additional control.\n\n Treatment of HCT116 colorectal cancer cells with MCMI-41-NH2-VOR resulted in significantly greater induction of histone H3 acetylation compared to vorinostat dissolved in media (DMEM), and was similar to the effect induced by equimolar concentrations of vorinostat dissolved in DMSO. As expected, treatment with empty MCM-41-NH2 particles had no effect on histone H3 acetylation (Figure 7a ). Having demonstrated that MCM-41-NH2-VOR inhibited HDAC activity to a similar extent as vorinostat dissolved in DMSO, we next compared their ability to induce mRNA expression of the established HDACi target genes, ATF3 and JUN in HCT116 cells. Consistent with the effects on histone H3 acetylation, MCM-41-NH2-VOR induced ATF3 and JUN mRNA to a similar extent as equimolar concentrations of vorinostat dissolved in DMSO (Figure 7b ).", "qa": [["87_56477889_6_1", "How does encapsulation within silica particles affect the permeability of vorinostat compared to the free drug?\n", "Encapsulation within silica particles, specifically MCM-41-VOR, MCM-41-NH2-VOR, and MCM-41-PO3-VOR, significantly increases the permeability of vorinostat compared to the free drug. This is evidenced by higher Papp values observed in the Caco-2 cell monolayer model when vorinostat is encapsulated within these silica particles."], ["87_56477889_6_2", "What is the impact of encapsulating vorinostat within amino-modified particles on its permeability?\n", "Encapsulation of vorinostat within amino-modified particles, specifically MCM-41-NH2-VOR, results in the highest permeability among the different types of silica particles tested. At the highest concentration (50 \u03bcg/mL), vorinostat encapsulated within amino-modified particles displayed approximately a 4-fold increase in permeability compared to pre-dissolved vorinostat."], ["87_56477889_6_3", "How does vorinostat encapsulated within MCM-41-NH2 particles compare to vorinostat dissolved in media (DMEM) or DMSO in terms of HDAC inhibitory activity and gene expression?\n", "Vorinostat encapsulated within MCM-41-NH2 particles (MCM-41-NH2-VOR) exhibits greater induction of histone H3 acetylation and mRNA expression of HDACi target genes (ATF3 and JUN) compared to vorinostat dissolved in media (DMEM). The effect of MCM-41-NH2-VOR on histone H3 acetylation and gene expression is similar to that induced by equimolar concentrations of vorinostat dissolved in DMSO."]]}, {"passage_id": "52_11827182_1", "passage": "In hypoxia-induced pulmonary hypertension in rats, decreased activity of the Tie2 pathway contributed to right ventricular load, and this effect was antagonized by Ang-1 [23] . On the other hand, a causative role for Ang-1 in pulmonary hypertension has also been suggested [24] . In hyperoxic lung injury, Ang-2 is involved in lung permeability and inflammation [25] .\n\n Ang/Tie also may contribute to critical illness in patients with pulmonary conditions. Ang-1 and Ang-2 concentrations in sputum from asthma patients correlated with airway microvascular permeability [26] . In patients with exudative pleural effusion, the Ang-2 level was increased whereas Ang-1 was unchanged [27] . Ang-2 levels are associated with pulmonary vascular leakage and the severity of acute lung injury. Plasma from patients with acute lung injury and high Ang-2 concentrations disrupts junctional architecture in vitro in human microvascular ECs [28, 29] .\n\n Patients with cardiovascular disorders also exhibit changes in the Ang/Tie system. Circulating Ang-1 concentrations are stable in patients with atrial fibrillation, but Ang-2 concentrations are increased, along with markers of platelet activation, angiogenesis and inflammation [30] . Patients with hypertension resulting in end-organ damage have increased levels of circulating Ang-1, Ang-2, Tie2 and VEGF [31] . Congestive heart failure is associated with elevated plasma levels of Ang-2, Tie2 and VEGF, but normal levels of Ang-1 [32] . A similar pattern is seen in acute coronary syndrome [33] .\n\n Circulating levels of components of the Ang/Tie system have been measured in patients admitted to the critical care unit. In trauma patients plasma Ang-2, but not plasma Ang-1 or VEGF, was increased early after trauma, and the level correlated with disease severity and outcome [34] . In children with sepsis and septic shock, Ang-2 levels in plasma were increased and once again correlated with disease severity, whereas Ang-1 levels were decreased [35] . The same Ang-1/ Ang-2 pattern is seen in adults with sepsis [28, 29, [36] [37] [38] [39] . The results of studies of the Ang/Tie system in humans are summarized in Table 1 . In sepsis, VEGF and its soluble receptor sFLT-1 (soluble VEGFR-1) are also increased in a disease severity-dependent manner [40] [41] [42] .The picture that emerges from these studies is that the Ang/Tie signalling system appears to play a crucial role in the symptoms of MODS. Findings in animal models and in patients suggest that Ang-1 stabilizes ECs and Ang-2 prepares them for action. The close relation with VEGF is also apparent.\n\n \n\n The angiopoietin signalling system consists of four ligands and two receptors (Figure 1 ). The ligands are Ang-1 to Ang-4, the best studied being Ang-1 and Ang-2 [17, [43] [44] [45] . The roles of Ang-3 (the murine orthologue of Ang-4) and Ang-4 are much less clear [18] . Angiopoietins are 70-kDa glycoproteins that contain an amino-terminal angiopoietinspecific domain, a coiled-coil domain, a linker peptide and a carboxyl-terminal fibrinogen homology domain [17, 44, 46, 47] . Ang-1 and Ang-2 bind to Tie2 after polymerization of at least [53] [54] [55] . Tie2 is shed from the EC and can be detected in soluble form in normal human serum and plasma; soluble Tie2 may be involved in ligand scavenging without signalling [56] . Tie2 shedding is both constitutive and induced; the latter can be controlled by VEGF via a pathway that is dependent on phosphoinositide-3 kinase (PI3K) and Akt [57] . Shed soluble Tie2 can scavenge Ang-1 and Ang-2 [56] . Tie1 does not act as a transmembrane kinase; rather, it regulates the binding of ligands to Tie2 and modulates its signalling [58] [59] [60] .\n\n Ang-1 is produced by pericytes and smooth muscle cells ( Figure 1 ). In the glomerulus, which lacks pericytes, Ang-1 is produced by podocytes [61] .", "qa": [["52_11827182_1_1", "How does the Ang/Tie signaling system contribute to critical illness in patients with pulmonary conditions?\n", "The Ang/Tie signaling system has been found to contribute to critical illness in patients with pulmonary conditions. In asthma patients, the concentrations of Ang-1 and Ang-2 in sputum correlated with airway microvascular permeability. Additionally, in patients with exudative pleural effusion, the level of Ang-2 was increased while Ang-1 remained unchanged. Ang-2 levels are associated with pulmonary vascular leakage and the severity of acute lung injury. Plasma from patients with acute lung injury and high Ang-2 concentrations disrupts junctional architecture in vitro in human microvascular endothelial cells."], ["52_11827182_1_2", "How do patients with cardiovascular disorders exhibit changes in the Ang/Tie system?\n", "Patients with cardiovascular disorders show changes in the Ang/Tie system. In patients with atrial fibrillation, circulating Ang-1 concentrations remain stable, but Ang-2 concentrations are increased, along with markers of platelet activation, angiogenesis, and inflammation. Patients with hypertension resulting in end-organ damage also have increased levels of circulating Ang-1, Ang-2, Tie2, and VEGF. Congestive heart failure and acute coronary syndrome are associated with elevated plasma levels of Ang-2, Tie2, and VEGF, but normal levels of Ang-1."], ["52_11827182_1_3", "What is the role of the angiopoietin signaling system in the symptoms of MODS (Multiple Organ Dysfunction Syndrome)?\n", "The angiopoietin signaling system appears to play a crucial role in the symptoms of MODS. Animal models and studies in patients suggest that Ang-1 stabilizes endothelial cells (ECs) while Ang-2 prepares them for action. The close relation with VEGF is also apparent. The angiopoietin signaling system consists of four ligands (Ang-1 to Ang-4) and two receptors (Tie1 and Tie2). Ang-1 and Ang-2 bind to Tie2 after polymerization. Tie2 shedding, which can be controlled by VEGF, is both constitutive and induced. Shed soluble Tie2 can scavenge Ang-1 and Ang-2. Tie1 regulates the binding of ligands to Tie2 and modulates its signaling."]]}, {"passage_id": "27_14174975_3", "passage": "GPS and accelerometer data were integrated with GIS to map each participant's neighborhood to identify the main locations of moderate-vigorous bouts of activity as well as to describe typical activity patterns [30] . Overall results showed that during weekdays, activity was primarily located within the individual's school and neighborhood environments, whereas activity patterns were more disparate on weekend days. These findings mirror that of a U.S. pilot study [32] which found there was much less variability in travel patterns on weekdays with more time spent within the vicinity (one km) of the home. Results showed that adolescents traveled further from home in the evenings and early mornings on the weekends.\n\n The second study titled Project CAPABLE (Children's Activities, Perceptions And Behavior in the Local Environment) [31] combined GPS units (Garmin Foretrex; Garmin Ltd., Olathe, KS) with RT3 triaxial accelerometers and self-report travel diaries in children aged 8-11 years to determine the nature (speed, intensity, and direction) of children's physical activity behaviors in the presence or absence of an adult or other children. Findings indicated that children's travel behaviors differed depending on whether they were accompanied by an adult or not. Approximately 56% of children were allowed to go out on their own, with boys being allowed out more often than girls. Children who were allowed to go out alone were more likely to visit a friend's house after school. Children generally walked slower when accompanied by an adult than when unaccompanied. Moreover, participants walked in a more exploratory way when not accompanied by an adult. The study also showed that walking trips on pavements tended to be more energetic and purposefully on roads than in open spaces. This study presents a novel approach for using GPS and accelerometry with selfreported behavior to assess not only how children interact with their environment, but also how others (adults, peers etc) affect that interaction.\n\n Others have investigated the feasibility of combining GPS and heart rate monitoring to measure physical activity in primary school children (n = 39) [33] . In New Zealand, spatial data were collected using a GPS unit and heart rate receiver during a school lunch break. Results showed that GPS could discriminate the velocity of play-related activity. Heart rate was used to quantify the energy expenditure associated with different movement speeds, such that children who moved at slower speeds expended less energy than those moving at faster speeds.\n\n A component of free-living physical activity is active transport in which people walk or cycle to school or their place of work. A number of research studies have incorporated GPS to assess travel routes in urban environments [34] . Generally such research has shown that GPS can be used to differentiate travel mode such as riding a bicycle or traveling by car [8, 35] . Moreover, recent research [36] , has found that GPS measured traveled distance compared well with GIS-estimated travel distance. In an Australian study, primary school children (n = 75) carried a Garmin (Garmin Ltd., Olathe, KS) etrex GPS device during the journey to and from school on a single occasion, with home and school addresses reported by parents geocoded in GIS. Children were instructed to travel their normal route to and from school. An interesting finding from this study was that the data from the GPS travel route revealed that students avoided busy streets and intersections, thereby providing interesting insight into how environmental factors can inhibit or possibly promote physical activity. Another GPS study with adults in the U.S. showed that equal amounts of bicycling time took place on roads with and without cycling infrastructure (such as streets with cycle lanes or separate pathways [34] . This study highlighted the utility of GPS to not only assess a physical activity behavior (e.g., bicycling) but how the built environment can have an impact.\n\n Recent research has combined GPS and accelerometry in an attempt to discriminate physical activities (walking, jogging/running, bicycling, and in-line skating) [37] . The combined data (accelerometer counts, steps, and GPS speed) were able to correctly classify the activity mode for 91% of observations. A similar study was conducted [38] to differentiate daily activities and sports performed in supervised and unsupervised settings. Participants wore triaxial accelerometers on their hip and wrist and GPS loggers during 21 hours of supervised and 47 hours of unsupervised activities, which included lying down, sitting and standing, walking, running, cycling with an exercise bike, rowing with a rowing machine, playing football, Nordic walking, and cycling with a regular bike. Activity recognition was conducted using signal features derived from the triaxial accelerometers and GPS information.", "qa": [["27_14174975_3_1", "How can GPS and accelerometer data be used to understand the activity patterns of adolescents in different environments?", "GPS and accelerometer data can be integrated with GIS to map the neighborhoods of participants and identify the main locations of moderate-vigorous activity. This allows researchers to determine where adolescents are most active during weekdays and weekends. The data can also reveal patterns of travel and variability in activity levels based on the presence or absence of adults or other children."], ["27_14174975_3_2", "What insights can GPS provide about the impact of the built environment on physical activity behaviors?", "GPS can be used to assess travel routes and differentiate travel modes, such as walking, cycling, or driving. It can also reveal how environmental factors, such as busy streets and intersections, can influence physical activity. For example, GPS data from a study with primary school children showed that they tended to avoid busy streets and intersections, providing insight into how the built environment can either inhibit or promote physical activity."], ["27_14174975_3_3", "How can GPS and accelerometry be combined to classify different types of physical activities?", "GPS and accelerometry data can be combined to discriminate between different physical activities, such as walking, jogging/running, bicycling, and in-line skating. By analyzing accelerometer counts, steps, and GPS speed, researchers can accurately classify the activity mode for a high percentage of observations. This approach can also be used to differentiate between daily activities and sports performed in supervised and unsupervised settings, providing valuable information about activity recognition and behavior."]]}, {"passage_id": "4_6583088_8", "passage": "In vitro tests with model stones have shown that even the first fracture can be detected in real time and that breakage is more evident with the signal converted in the frequency domain. The EnD system can discriminate between fragments that differ in size by just 1-2 mm. Proof of concept is well demonstrated and the system requires further refinement before in vivo testing.\n\n A similar system developed by Leighton and co-workers 95 utilizes an acoustic sensor to detect emissions generated by each shot at the focal point of the lithotripter. This passive listening device monitors cavitation at the target area. The quality of the cavitation signal is affected by the immediate fluid environment, and was found to correlate with the degree of breakage of the stone. A computer display tells the operator if the shock wave hits the stone, and whether fragmentation is progressing. A clinical trial with the device showed promise, predicting the outcome in 95% of cases in which therapy was successful. 95 Acoustic tracking for stone targeting Respiratory motion can move stones 5 cm or more with each breath, and this movement is not in line with the acoustic axis of the lithotripter. Thus, the stone is a moving target that is carried in and out of the focal zone of the lithotripter. Depending on respiratory rate, the length of excursion, and the focal width and shock wave rate of the lithotripter, the stone can be outside the focal zone when 50% or more of the shots are fired. 53, 84 Thus, many shots miss the intended target, but hit the surrounding tissue. If a means to track the moving stone and to trigger the lithotripter only when the stone is on target were available, then it would shorten treatment time and reduce exposure to shock waves. Several targeting systems have been developed to track stones during treatment. These include the use of sophisti cated ultrasound imagers and tracking algorithms, and a system built into a piezoelectric lithotripter to actively steer the beam to hit the moving stone. [96] [97] [98] [99] none of these systems is currently in clinical use, but they demonstrate proof of concept that tracking can improve the hit rate by about 50%.\n\n owen and colleagues 100 have reported a real-time tracking and triggering system in which short ultrasonic pulses are delivered to the focal point of the lithotripter, and the scattered pulse-scattered by the stone when on target-is detected by a receiver-transducer. Signal scattered by a stone is much higher in amplitude than that scattered by tissue, and a threshold for stone above background is used to trigger the lithotripter. In vitro tests using a motorized positioner to simulate 4 cm of respiratory excursion through the test tank of an HM3-clone lithotripter showed that the system improved stone breakage approximately two-fold. 100 Clearance of residual stone fragments one of the recognized limitations of SWL is the retention of stone fragments within the kidney, particularly the lower pole. Fortunately, the majority of fine particles clear fairly well, but larger fragments, of the order of one to several millimeters, can be slow to wash out or can be retained. As such fragments can be symptomatic or act as a nidus for stone formation, there has long been interest in finding ways to remove them. In some instances ureteroscopy may be an option, but non invasive methods such as percussion, diuresis, or inversion of the patient have broader appeal. Recently, a method has been described in which stone fragments in the renal pelvis can be moved using transcutaneous focused ultrasound. 101, 102 The system employs a focused ultrasound therapy probe, which generates acoustic radiation forces and acoustic streaming sufficient to push stone fragments over a distance of several centimeters. The therapy probe has an inline ultrasound imaging probe, which is used to localize the fragments and to help the operator move them in a desired direction. The system is independent of the lithotripter and operates below the threshold for thermal injury. Such a device holds considerable promise not only for moving and clearing stone fragments, but also for dispersal of clusters of fragments to help in determining if a stone is adequately broken to completion.\n\n Some additional issues in SWL seem well suited to being addressed through new technology. These problems include ensuring adequate acoustic coupling, and the difficulty posed by obese patients.\n\n As discussed previously, acoustic coupling with modern dry-head lithotripters is inefficient and highly variable. Defects (air pockets) at the coupling interface arise when coupling is first established and worsen if the patient is moved or contact is broken and hastily reinitiated. Such defects interfere with the transmission of shock wave energy to the target and reduce the efficiency of stone REvIEWS breakage.", "qa": [["4_6583088_8_1", "How do tracking systems in lithotripsy aim to improve treatment outcomes for patients with kidney stones?", "Tracking systems in lithotripsy are designed to address the challenge of stone movement during treatment due to respiratory motion, ensuring that shock waves are accurately targeted at the stone. These systems utilize ultrasound imaging, tracking algorithms, and active steering mechanisms to monitor stone position in real-time and trigger the lithotripter only when the stone is within the focal zone. By enhancing targeting accuracy, these systems can reduce treatment time, minimize exposure to shock waves, and improve the hit rate on the stone by about 50%."], ["4_6583088_8_2", "What are the potential benefits of using transcutaneous focused ultrasound to address residual stone fragments in the kidney?", "Transcutaneous focused ultrasound offers a non-invasive method for moving and clearing stone fragments within the kidney. By generating acoustic radiation forces and acoustic streaming, this technology can push stone fragments over several centimeters, aiding in their removal. The system includes an ultrasound imaging probe to localize fragments and guide their movement, independent of the lithotripter and operating below the threshold for thermal injury. This approach not only helps clear symptomatic or retained stone fragments but also assists in dispersing clusters of fragments to assess the completeness of stone breakage."], ["4_6583088_8_3", "How do tracking and triggering systems in lithotripsy utilize ultrasonic pulses to enhance stone breakage during treatment?", "Tracking and triggering systems in lithotripsy employ short ultrasonic pulses delivered to the focal point of the lithotripter, with scattered pulses detected by a receiver-transducer. By setting a threshold for stone signal above background noise, the system triggers the lithotripter when the stone is accurately targeted. In vitro tests have shown that this system significantly improves stone breakage, approximately doubling the effectiveness compared to traditional methods. This approach enhances treatment outcomes by ensuring that shock waves are delivered precisely to the stone, optimizing fragmentation and clearance of stone fragments."]]}, {"passage_id": "85_18833600_1", "passage": "Patients detained overnight were detained either on account of geographic distance (3 of LS group) or parental concerns (1 each in the LS and OS group). Complication rates were similar (P\u03ed0.96). Trivial peritoneal bleeding was observed in 2 cases performed laparoscopically due to needle injury. Transient hydroceles (lasting a few days) were observed in 2 cases performed laparoscopically and in 1 performed conventionally. Mild scrotal edema was observed in 2 cases following OS, which resolved spontaneously in a few days. Erythema over the suture line was observed in 2 cases performed conventionally, which resolved with oral antibiotics. Cosmesis in LS was superior to that in OS. Twenty-two percent of children undergoing LS had CPPV, which were repaired during the same sitting.\n\n Inguinal hernia is a common problem in children, and herniotomy is its standard treatment 4 against which all alternative modalities of treatment are evaluated. It is credited with being easy to perform, having a high success rate and low rate of complications. 4 Despite that, in tune with the explosion of minimally invasive surgery in all fields of surgery, laparoscopy is gaining popularity in pediatric hernia surgery as well. 5 However, opinion is divided on its wider adoption as the procedure of choice. 1,3 \n\n As in our study, a significant number of children (\u03fe20%) presenting with UL hernias have CPPV. 6 -9 The options for detection of CPPV are many, namely routine bilateral explorations, 10 use of ultrasonography, 11 laparoscopy, 12 and the wait and watch policy. 13 Although laparoscopy proves advantageous over OS by precise detection and simultaneous repair of CPPV, its management remains a contentious issue. The current consensus amongst surgeons practicing OS favors operating on the symptomatic side alone 13 as the rate of metachronous hernia is so low that it only necessitates subsequent surgery in less than a twentieth of patients. 13 Therefore, this advantage of LS may not be very significant in clinical practice.\n\n In open surgery, time is consumed in gaining access, obtaining adequate exposure, in localizing and in isolating the sac from the cord structures. 14 In LS, approaching from within makes the area of interest bloodless, and the magnification renders anatomy splendidly clear, making surgery precise. 6 -9 But the time-limiting step remains intracorporeal suturing that places considerable demands on the requirement of hand-eye coordination, especially while negotiating the posterior and medial hemi-circumference of the internal ring, over the iliac and inferior epigastric vessels. 6, 7 With growing experience 6,7 and use of refinements, such as hydro-dissection and needle sign, 15 operative time does come down. We found LS marginally quicker (5 min), but this difference appears insignificant, both statistically and in practice.\n\n The difference in postoperative pain following OS and LS is subject to controversy. Some report less pain while others report greater pain in the immediate postoperative period following LS compared with OS. 16 We found pain perception following either procedure to be similar. One reason for this could be that neither the size of the incision nor the amount of muscle cutting/retraction vastly differs in either CIH surgeries.\n\n Parietal pain predominates in OS, in general, which can well be controlled by caudal analgesia. On the other hand, pain perception is multimodal and multifactorial in LS. 17 In addition to parietal pain caused by port placement, capnoperitoneum causes visceral pain due to stretching (peritoneal and diaphragmatic) and acidosis. 17 Neither the use of smaller ports nor the use of caudal analgesia would completely obliterate pain following laparoscopy. 17 Therefore, the decrease in the size of the incision does not necessarily translate into a proportionate decrease in pain. Hence, the difference in postoperative pain between LS and OS is not significant enough to rate either surgery superior.\n\n Recovery from the effects of anesthesia was delayed in a greater proportion of patients undergoing LS. This may be due to deeper anesthesia and muscle relaxation needed for intubations in LS, in addition to the effects of capnoperitoneum described above. 17 OS can well be performed with the patient under a face mask, especially when caudal analgesia is administered simultaneously. Even when a patient is intubated, the degree of anesthesia and relaxation needed is less.\n\n There was no significant difference in duration of hospital stay, as in both groups the majority was discharged within 10 hours of surgery. Hence, both procedures are essentially outpatient.\n\n Complication rates of both procedures were similar and minor in nature (Table 2 ). In LS, trivial ooze from peritoneal vessels, which ceased spontaneously, occurred while the surgeon was negotiating the needle around the internal ring. It is the magnification in LS that renders them conspicuous, which would otherwise go unnoticed in OS.\n\n We observed transient hydroceles more commonly in LS, perhaps due to thicker than peritoneum bites leading to lymphatic embarrassment. 18 Wound erythema was minimal in OS, and none at all occurred in LS.\n\n Although LS has been blamed for higher recurrences, 3 we did not observe any recurrence in our patients during our limited follow-up. No metachronous hernia occurred in patients treated unilaterally by OS.\n\n Five-millimeter incisions in LS were, indeed, cosmetically more appealing 1 compared with 2-cm incisions in OS. However, this significance gets lost because the scar in OS, by virtue of its position, gets concealed by clothing.\n\n The medical facilities and monetary affluence are unevenly distributed in rural and urban areas in developing countries. 19, 20 Hence, the need is to find the apt treatment that is both scientifically/ethically correct while being cost effective. 19, 20 Laparoscopic PIH surgery is, no doubt, novel, safe, elegant and in some situations advantageous too. But the cost of setting up and running it may make it an unviable option in rural settings, where the majority of the developing world resides.\n\n Well-performed conventional herniotomy does yield equally good results and, therefore, needs to continue as the standard of care.\n\n Well-performed conventional herniotomy yields results similar to those of laparoscopic repair. Cosmesis and the ability to detect and simultaneously repair CPPV are the 2 main advantages of LS over OS. Keeping in view the low incidence of meta-chronicity in UL hernias, relative insignificance of cosmesis over the groin, and the constraints of the developing world, conventional open herniotomy can justly be performed for unilateral hernias, as the standard of care, in centers lacking laparoscopy.", "qa": [["85_18833600_1_1", "What are the advantages of laparoscopic hernia repair over open surgery?\n", "The advantages of laparoscopic hernia repair over open surgery include superior cosmesis and the ability to detect and simultaneously repair concurrent contralateral patent processus vaginalis (CPPV). Laparoscopy provides a clear view of the anatomy and allows for precise surgery. However, the significance of these advantages may not be very significant in clinical practice, especially considering the low incidence of metachronous hernias and the constraints of the developing world."], ["85_18833600_1_2", "What are the potential complications of laparoscopic and open hernia repair?\n", "The potential complications of both laparoscopic and open hernia repair are minor in nature. Trivial peritoneal bleeding and transient hydroceles may occur in laparoscopic cases. Mild scrotal edema and erythema over the suture line may occur in open surgery. However, the overall complication rates are similar between the two procedures."], ["85_18833600_1_3", "What factors should be considered when deciding between laparoscopic and open hernia repair?\n", "When deciding between laparoscopic and open hernia repair, factors such as cosmesis, the ability to detect and repair concurrent contralateral patent processus vaginalis (CPPV), and the availability and cost of medical facilities should be considered. Laparoscopic hernia repair offers better cosmesis and the ability to detect and repair CPPV, but it may not be a viable option in rural settings due to the cost of setting up and running the procedure. Well-performed conventional herniotomy can yield equally good results and should continue as the standard of care in centers lacking laparoscopy."]]}, {"passage_id": "21_57762033_3", "passage": "Data were plotted as the mean \u03ee SEM.\n\n \n\n First, we examined tissue damage in male and female rats at 7 dpi in this SCI model (Gaudet et al., 2017; Fig. 1 ). As expected, substantial tissue loss was observed at the T8 lesion epicenter (Fig. 1D) ; moving rostrocaudally away from the epicenter, there was progressively more tissue sparing (Fig. 1E ). There were no significant differences in lesion size or tissue sparing in females versus males (lesion volume: females, 8.15 \u03ee 0.70 mm 3 ; males, 7.48 \u03ee 0.46 mm 3 ; p \u03fe 0.05). Locomotor recovery after sham/SCI was assessed ( Fig. 1F) . At 1 dpi, average BBB scores indicated that SCI rats had movement of one hindlimb joint. By 42 dpi, SCI rats recovered frequent hindlimb stepping with no (or little) coordination (females: BBB score, 10.6 \u03ee 0.6; males: BBB score, 11.0 \u03ee 1.4).\n\n CORT release is regulated in a circadian manner; this steroid hormone maintains metabolic homeostasis across the day and helps to entrain extra-SCN circadian rhythms (Nicolaides et al., 2014) . Here, we assessed whether SCI dysregulated plasma CORT levels and rhythms (Fig. 2) . Before surgery, female and male rats showed peak trough patterns in plasma CORT ( Fig. 2A ; D'Agostino et al., 1982) : CORT had cycle peak (acrophase) near early to mid-active phase (at approximately ZT12; females, ZT12: 1.4 \u03ee 0.3 ng/ml; males, ZT12: 0.6 \u03ee 0.1 ng/ml), and was lowest at the start of the inactive phase (ZT0; females: 0.6 \u03ee 0.2 ng/ml; males: 0.4 \u03ee 0.1 ng/ml). CORT levels were higher overall in presurgery females than males (Cavigelli et al., 2005) . In females, CORT was unusally high at ZT6, which could have been related to a handling-elicited CORT increase (G\u00e4rtner et al., 1980) . CORT was expressed rhythmically before injury in both females (F (2,37) \u03ed 3.465, p \u03fd 0.05) and males (F (2,33) \u03ed 6.647, p \u03fd 0.005).\n\n SCI disrupted typical rhythms and significantly increased CORT levels at acute postinjury times (females: main effect of injury: F (3,62) \u03ed 3.606, p \u03fd 0.05; males: main effect of injury: F (3,70) \u03ed 22.584, p \u03fd 0.001). Females with SCI had increased CORT at 7 dpi (vs presurgery; at ZT0; p \u03fd 0.05); males with SCI showed significant CORT increases at 2 dpi (vs presurgery; at ZT0 and ZT6; p \u03fd 0.001) and 7 dpi (at ZT0; p \u03fd 0.05; Fig. 2B ). For average CORT concentration across the day, SCI in female and male rats caused significant increases in average CORT at 2 d postsurgery (females: vs presurgery, p \u03fd 0.05; males: main effect of surgery; also at 2 dpi vs both presurgery and sham, p \u03fd 0.001; Fig. 2C ).\n\n Body temperature and activity are two prominent outputs of the circadian system that also help to entrain There were no significant sex differences in lesion size or the percentage of spared tissue. F, Moderate T9 SCI caused substantial immediate locomotor deficits in female and male rats that recovered over time, as assessed in an open field using the BBB scale. There were no significant differences in BBB scores between female and male SCI rats. Scale bar, 1 mm.\n\n circadian rhythms in cells throughout the body (Reebs and Mrosovsky, 1989; Buhr et al., 2010) . To measure these parameters, rats were implanted with a small transmitter and were studied before sham/SCI, and from acute-to-chronic times postsurgery.", "qa": [["21_57762033_3_1", "How does spinal cord injury affect plasma cortisol levels and rhythms?\n", "Spinal cord injury (SCI) disrupts typical rhythms and significantly increases cortisol (CORT) levels at acute post-injury times. Females with SCI had increased CORT at 7 days post-injury (dpi), while males with SCI showed significant CORT increases at 2 dpi and 7 dpi. Overall, SCI in both female and male rats caused significant increases in average CORT concentration at 2 dpi."], ["21_57762033_3_2", "What are the effects of spinal cord injury on tissue damage in male and female rats?\n", "Spinal cord injury (SCI) results in substantial tissue loss at the T8 lesion epicenter. Moving away from the epicenter, there is progressively more tissue sparing. However, there were no significant differences in lesion size or tissue sparing between females and males."], ["21_57762033_3_3", "How does spinal cord injury affect locomotor recovery in rats?\n", "After sham/SCI, locomotor recovery was assessed using the Basso, Beattie, and Bresnahan (BBB) scale. At 1 day post-injury (dpi), SCI rats had movement of one hindlimb joint. By 42 dpi, SCI rats recovered frequent hindlimb stepping with little coordination. There were no significant differences in BBB scores between female and male SCI rats."]]}, {"passage_id": "49_16857105_0", "passage": "Laparoscopic antireflux surgery (LARS) has shown to be effective in controlling gastroesophageal reflux [1, 2] . However, a universally accepted definition for treatment success/failure in gastroesophageal reflux disease (GERD) is not yet available: objective evaluation of symptoms, response to treatment, and definition of treatment failure are all still controversial. A substantial number of the patients after surgery still take antireflux medications (ARMs) [3] [4] [5] , with percentages ranging from 62% to 15-20% after 9 and 4-5 years of followup, respectively [6] [7] [8] [9] [10] [11] [12] . ARM use is performed on the assumption that foregut symptoms in a patient after fundoplication are consequent to a failed operation and based on the assumption that a diagnosis of recurrent reflux can be made confidently from the clinical findings [13, 14] . However, most patients taking acid suppressive medications after antireflux surgery do not reveal any abnormal esophageal acid exposure [15] , and the presence of symptoms alone may not seem to be a good reason to start an antacid treatment. Therefore, the prescription of ARM frequently seems inappropriate and does not always indicate that surgical therapy has failed.\n\n Reports dealing with the clinical outcome after LARS, either concentrate on symptomatic results, patient's satisfaction, and quality of life, on the percentage of patients taking ARM, or on the objective evaluation of the esophageal function and acid exposure. Yet, there is not agreement on how should a successful outcome be defined and how could the consequent therapeutic approach be directed.\n\n On this background, we felt worthwhile to analyze the recent literature, mainly focused on the efficacy and outcome of LARS. The purpose of this paper is therefore (i) to assess if and how the outcome variables used in the different studies could possibly lead, in spite of their complexity, to an homogeneous appraisal of the limits and indications of LARS in the management of GERD,\n\n (ii) how these outcome evaluations could be better interpreted in order to identify failures of treatment,\n\n (iii) to possibly extrapolate and suggest a flowchart for the postoperative evaluation after LARS.\n\n In order to evaluate criteria and definition of a successful clinical outcome after LARS, we analyzed studies, published after 2000, which were specifically performed to assess reflux symptoms, medication assumption, satisfaction to surgery, evaluation of quality of life, and objective esophageal tests after LARS. Specifically, for each study, it was taken into account:\n\n (i) parameters utilized to assess the clinical outcome, that is, clinical evaluation or interview, phone interview, symptoms questionnaire or others (QoL, GIQLI, HRQL, GSRS, PGWB), analysis of hospital data bases, level of satisfaction;\n\n (ii) incidence of GERD and not GERD-related symptoms;\n\n (iii) use of ARM (either continuous or occasional) for GERD-related and not GERD symptoms;\n\n (iv) response to medications and, when specified, the main prescriptor (family physician, gastroenterologist, surgeon);\n\n (v) objective esophageal tests (endoscopy, esophageal manometry, 24-hour esophageal pH-metry) when performed.\n\n Thirty-four papers [2-6, 8, 11, 14-40] concerning clinical outcome after LARS were evaluated. The total number of patients included in this review was 7599, with a followup ranging from a minimum of 6 months to 12 years. The first author was a gastroenterologist in 7 (21.8%) papers and a surgeon in 26. Twenty-five studies came from highly specialized or university hospitals, 2 from VA cooperative studies [6, 26] , 3 from cooperative studies between university hospitals [23, 36, 39] , and 3 from community hospitals [3, 26, 28] . Ten studies assessed the quality of life after surgery, either comparing it to preoperative values or to a group of medically treated patients. The results are showed in Table 2 . Quality of life scores improved after surgery but in only one study out of 4 the surgical group achieved a significantly better score than the medical group.\n\n GERD symptoms scores showed an improvement after surgery in all series. However, GERD-related symptoms (heartburn and/or regurgitation) were still reported in 18.2 \u00b112.3% of patients (range 4-47%) in 21 studies.", "qa": [["49_16857105_0_1", "How do the challenges in defining treatment success/failure in gastroesophageal reflux disease (GERD) impact the postoperative management of patients undergoing laparoscopic antireflux surgery (LARS)?", "The lack of a universally accepted definition for treatment success/failure in GERD complicates the evaluation of outcomes post LARS. This uncertainty influences decisions regarding the continuation of antireflux medications (ARMs) after surgery, as symptoms alone may not always indicate treatment failure. The assumption that foregut symptoms post-fundoplication signify a failed operation and recurrent reflux diagnosis may lead to inappropriate ARM prescriptions, highlighting the need for clearer criteria to guide postoperative management."], ["49_16857105_0_2", "How do studies on the clinical outcomes after laparoscopic antireflux surgery (LARS) contribute to the ongoing debate on defining a successful outcome and guiding postoperative evaluation strategies?", "Studies focusing on clinical outcomes post LARS provide insights into various aspects such as symptom improvement, patient satisfaction, quality of life, ARM usage, and objective esophageal tests. However, the lack of consensus on defining treatment success and the interpretation of outcome variables hinders the establishment of standardized evaluation criteria. These studies underscore the importance of refining outcome assessments to better identify treatment failures and guide postoperative care effectively."], ["49_16857105_0_3", "What role does the analysis of recent literature play in shaping the understanding of the efficacy and outcomes of laparoscopic antireflux surgery (LARS) in managing gastroesophageal reflux disease (GERD)?", "The analysis of recent literature on LARS efficacy and outcomes serves to consolidate existing knowledge and address gaps in defining treatment success/failure. By examining studies published after 2000 that assess reflux symptoms, medication use, quality of life, and objective esophageal tests post LARS, researchers aim to identify patterns, limitations, and indications of LARS in GERD management. This analysis aims to enhance the interpretation of outcome variables, potentially leading to the development of a standardized postoperative evaluation flowchart for LARS patients."]]}]